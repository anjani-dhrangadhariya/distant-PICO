{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Source statistics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-21 15:16:02.618669: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    }
   ],
   "source": [
    "from elasticsearch import Elasticsearch, helpers\n",
    "from elasticsearch_dsl import Search,  Q\n",
    "from datetime import datetime\n",
    "import sys, json, os\n",
    "import difflib \n",
    "import uuid\n",
    "import spacy\n",
    "import ast\n",
    "from statistics import mean, median\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "464037\n",
      "464037\n",
      "Longest outcome term:  68\n",
      "Longest outcome term:  1\n",
      "Mean outcome term:  10.124744363057257\n",
      "Median outcome term:  8\n",
      "####################################################################\n",
      "[('NOUN', 1589426), ('PROPN', 744440), ('ADP', 718375), ('PUNCT', 510399), ('ADJ', 389293), ('VERB', 212547), ('DET', 168427), ('NUM', 144452), ('CCONJ', 118636), ('PART', 49679), ('ADV', 19831), ('PRON', 11321), ('AUX', 6121), ('X', 5819), ('SCONJ', 5440), ('SYM', 3718), ('INTJ', 332)]\n",
      "####################################################################\n",
      "[('NN', 1332428), ('IN', 722014), ('NNP', 686128), ('JJ', 380177), ('NNS', 257011), ('-RRB-', 176226), ('-LRB-', 169869), ('DT', 164240), ('CD', 144452), ('CC', 118636), ('VBN', 89007), (',', 68176), ('NNPS', 58312), ('VBG', 47613), ('.', 44736), ('TO', 42760), ('VB', 38053), (':', 31667), ('RB', 17871), ('HYPH', 15538), ('VBD', 15028), ('VBP', 13895), ('VBZ', 8951), ('WP', 8099), ('MD', 6121), ('POS', 5858), ('JJR', 5088), ('JJS', 4028), ('WDT', 3841), ('SYM', 3605), ('FW', 3495), ('WRB', 2428), ('``', 2150), ('PRP$', 2077), (\"''\", 1809), ('RP', 1801), ('XX', 1477), ('PRP', 971), ('LS', 813), ('RBR', 442), ('UH', 332), ('WP$', 250), ('NFP', 228), ('EX', 161), ('RBS', 151), ('$', 113), ('PDT', 96), ('ADD', 34)]\n",
      "####################################################################\n",
      "Total number of tokens:  4698256\n",
      "of \t 251263\n",
      ") \t 168958\n",
      "( \t 165230\n",
      "in \t 125575\n",
      "the \t 125026\n",
      "and \t 88071\n",
      ", \t 68112\n",
      "change \t 66907\n",
      "to \t 64649\n",
      "with \t 55520\n"
     ]
    }
   ],
   "source": [
    "prim_outcomes = '/mnt/nas2/data/systematicReview/clinical_trials_gov/distant_pico_pre/primary_outcomes.txt'\n",
    "#prim_outcomes = '/mnt/nas2/data/systematicReview/clinical_trials_gov/distant_pico_pre/secondary_outcomes.txt'\n",
    "counter = 0\n",
    "\n",
    "outcome_names = []\n",
    "outcome_tokens = []\n",
    "pos_all = []\n",
    "posfine_all = []\n",
    "outcome_tokens_all = []\n",
    "\n",
    "with open(prim_outcomes, 'r') as pof:\n",
    "    try:\n",
    "        \n",
    "        for eachOutcome in pof:\n",
    "            counter = counter + 1\n",
    "            #rint(counter)\n",
    "            j = json.loads(eachOutcome)\n",
    "\n",
    "            if j:\n",
    "                for key, value in j.items():\n",
    "                    for eachOne in value:\n",
    "                        if 'text' in eachOne:\n",
    "                            outcome_names.append( eachOne['text'] )\n",
    "                        if 'tokens' in eachOne:\n",
    "                            outcome_tokens.append( eachOne['tokens'] )\n",
    "                            outcome_tokens_all.extend( list(map(lambda x: x.lower(), eachOne['tokens'])) ) \n",
    "                        if 'pos' in eachOne:\n",
    "                            pos_all.extend( eachOne['pos'] )\n",
    "                        if 'pos_fine' in eachOne:\n",
    "                            posfine_all.extend( eachOne['pos_fine'] )\n",
    "\n",
    "            #f counter == 10:\n",
    "            #  break\n",
    "    except:\n",
    "        print('something strange happened')\n",
    "\n",
    "print( len(outcome_names) )\n",
    "print( len(outcome_tokens) )\n",
    "\n",
    "\n",
    "longest_outcome = max(map(len, outcome_tokens))\n",
    "print('Longest outcome term: ', longest_outcome)\n",
    "\n",
    "shortest_outcome = min(map(len, outcome_tokens))\n",
    "print('Longest outcome term: ', shortest_outcome)\n",
    "\n",
    "mean_outcome = mean(map(len, outcome_tokens))\n",
    "print('Mean outcome term: ', mean_outcome)\n",
    "\n",
    "median_outcome = median(map(len, outcome_tokens))\n",
    "print('Median outcome term: ', median_outcome)\n",
    "print('####################################################################')\n",
    "pos_counter = Counter(pos_all)\n",
    "print( pos_counter.most_common(50) )\n",
    "print('####################################################################')\n",
    "posfine_counter = Counter(posfine_all)\n",
    "print( posfine_counter.most_common(50) )\n",
    "\n",
    "print('####################################################################')\n",
    "# Most common words\n",
    "print('Total number of tokens: ', len(outcome_tokens_all))\n",
    "outcometerms_counter = Counter(outcome_tokens_all)\n",
    "most_common_outcome_terms = outcometerms_counter.most_common(10)\n",
    "\n",
    "for tuple_i in most_common_outcome_terms:\n",
    "    print(tuple_i[0], '\\t', tuple_i[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine overlapping spans in PICOS weak annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception happened...\n"
     ]
    }
   ],
   "source": [
    "annotations_global = '/home/anjani/distant-PICO/CandidateGeneration/ResultInspection/label_overlap_inspection.txt'\n",
    "\n",
    "with open(annotations_global, 'r') as af:\n",
    "    try:\n",
    "        for annot in af:\n",
    "            j = json.loads(annot)\n",
    "            \n",
    "            for key, value in j.items():\n",
    "                for a_key, a_value in value.items():\n",
    "                    \n",
    "                    if len( a_value ) > 3: # more than two annotations including \"tokens\" list\n",
    "                        \n",
    "                        keys = []\n",
    "                        temp_list = []\n",
    "                        tokens = []\n",
    "                        for b_key, b_value in a_value.items():\n",
    "                            if 'tokens' not in b_key:\n",
    "                                temp_list.append( b_value )\n",
    "                                keys.append( b_key )\n",
    "                            else:\n",
    "                                tokens.extend( b_value )\n",
    "\n",
    "                        for i, (l1, l2, l3) in enumerate(zip( temp_list[0], temp_list[1], temp_list[2] )):\n",
    "                            if l1 !=0 and l2 != 0  and l3 != 0:\n",
    "                                print(keys , ' : ' ,tokens[i], ' - ', l1, l2, l3 )\n",
    "\n",
    "    except:\n",
    "        print('Exception happened...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Source statistics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-26 10:45:09.939133: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    }
   ],
   "source": [
    "from elasticsearch import Elasticsearch, helpers\n",
    "from elasticsearch_dsl import Search,  Q\n",
    "from datetime import datetime\n",
    "import sys, json, os\n",
    "import difflib \n",
    "import uuid\n",
    "import spacy\n",
    "import ast\n",
    "from statistics import mean, median\n",
    "from collections import Counter\n",
    "import itertools\n",
    "import traceback\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "464037\n",
      "464037\n",
      "Longest outcome term:  68\n",
      "Longest outcome term:  1\n",
      "Mean outcome term:  10.124744363057257\n",
      "Median outcome term:  8\n",
      "####################################################################\n",
      "[('NOUN', 1589426), ('PROPN', 744440), ('ADP', 718375), ('PUNCT', 510399), ('ADJ', 389293), ('VERB', 212547), ('DET', 168427), ('NUM', 144452), ('CCONJ', 118636), ('PART', 49679), ('ADV', 19831), ('PRON', 11321), ('AUX', 6121), ('X', 5819), ('SCONJ', 5440), ('SYM', 3718), ('INTJ', 332)]\n",
      "####################################################################\n",
      "[('NN', 1332428), ('IN', 722014), ('NNP', 686128), ('JJ', 380177), ('NNS', 257011), ('-RRB-', 176226), ('-LRB-', 169869), ('DT', 164240), ('CD', 144452), ('CC', 118636), ('VBN', 89007), (',', 68176), ('NNPS', 58312), ('VBG', 47613), ('.', 44736), ('TO', 42760), ('VB', 38053), (':', 31667), ('RB', 17871), ('HYPH', 15538), ('VBD', 15028), ('VBP', 13895), ('VBZ', 8951), ('WP', 8099), ('MD', 6121), ('POS', 5858), ('JJR', 5088), ('JJS', 4028), ('WDT', 3841), ('SYM', 3605), ('FW', 3495), ('WRB', 2428), ('``', 2150), ('PRP$', 2077), (\"''\", 1809), ('RP', 1801), ('XX', 1477), ('PRP', 971), ('LS', 813), ('RBR', 442), ('UH', 332), ('WP$', 250), ('NFP', 228), ('EX', 161), ('RBS', 151), ('$', 113), ('PDT', 96), ('ADD', 34)]\n",
      "####################################################################\n",
      "Total number of tokens:  4698256\n",
      "of \t 251263\n",
      ") \t 168958\n",
      "( \t 165230\n",
      "in \t 125575\n",
      "the \t 125026\n",
      "and \t 88071\n",
      ", \t 68112\n",
      "change \t 66907\n",
      "to \t 64649\n",
      "with \t 55520\n"
     ]
    }
   ],
   "source": [
    "prim_outcomes = '/mnt/nas2/data/systematicReview/clinical_trials_gov/distant_pico_pre/primary_outcomes.txt'\n",
    "#prim_outcomes = '/mnt/nas2/data/systematicReview/clinical_trials_gov/distant_pico_pre/secondary_outcomes.txt'\n",
    "counter = 0\n",
    "\n",
    "outcome_names = []\n",
    "outcome_tokens = []\n",
    "pos_all = []\n",
    "posfine_all = []\n",
    "outcome_tokens_all = []\n",
    "\n",
    "with open(prim_outcomes, 'r') as pof:\n",
    "    try:\n",
    "        \n",
    "        for eachOutcome in pof:\n",
    "            counter = counter + 1\n",
    "            #rint(counter)\n",
    "            j = json.loads(eachOutcome)\n",
    "\n",
    "            if j:\n",
    "                for key, value in j.items():\n",
    "                    for eachOne in value:\n",
    "                        if 'text' in eachOne:\n",
    "                            outcome_names.append( eachOne['text'] )\n",
    "                        if 'tokens' in eachOne:\n",
    "                            outcome_tokens.append( eachOne['tokens'] )\n",
    "                            outcome_tokens_all.extend( list(map(lambda x: x.lower(), eachOne['tokens'])) ) \n",
    "                        if 'pos' in eachOne:\n",
    "                            pos_all.extend( eachOne['pos'] )\n",
    "                        if 'pos_fine' in eachOne:\n",
    "                            posfine_all.extend( eachOne['pos_fine'] )\n",
    "\n",
    "            #f counter == 10:\n",
    "            #  break\n",
    "    except:\n",
    "        print('something strange happened')\n",
    "\n",
    "print( len(outcome_names) )\n",
    "print( len(outcome_tokens) )\n",
    "\n",
    "\n",
    "longest_outcome = max(map(len, outcome_tokens))\n",
    "print('Longest outcome term: ', longest_outcome)\n",
    "\n",
    "shortest_outcome = min(map(len, outcome_tokens))\n",
    "print('Longest outcome term: ', shortest_outcome)\n",
    "\n",
    "mean_outcome = mean(map(len, outcome_tokens))\n",
    "print('Mean outcome term: ', mean_outcome)\n",
    "\n",
    "median_outcome = median(map(len, outcome_tokens))\n",
    "print('Median outcome term: ', median_outcome)\n",
    "print('####################################################################')\n",
    "pos_counter = Counter(pos_all)\n",
    "print( pos_counter.most_common(50) )\n",
    "print('####################################################################')\n",
    "posfine_counter = Counter(posfine_all)\n",
    "print( posfine_counter.most_common(50) )\n",
    "\n",
    "print('####################################################################')\n",
    "# Most common words\n",
    "print('Total number of tokens: ', len(outcome_tokens_all))\n",
    "outcometerms_counter = Counter(outcome_tokens_all)\n",
    "most_common_outcome_terms = outcometerms_counter.most_common(10)\n",
    "\n",
    "for tuple_i in most_common_outcome_terms:\n",
    "    print(tuple_i[0], '\\t', tuple_i[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine overlapping spans in PICOS weak annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['p', 'ic', 'o', 's']\n",
    "label_combinations = itertools.combinations(labels, 2)\n",
    "label_combinations = list(label_combinations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('p', 'ic'), ('p', 'o'), ('p', 's'), ('ic', 'o'), ('ic', 's'), ('o', 's')]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage overlap between  p  and  o  is:  13.003077294394497\n"
     ]
    }
   ],
   "source": [
    "l1 = label_combinations[1][0]\n",
    "l2 =  label_combinations[1][1]\n",
    "\n",
    "overlaps = []\n",
    "non_overlaps = []\n",
    "\n",
    "annotations_global = '/home/anjani/distant-PICO/CandidateGeneration/ResultInspection/pico_multiclass.txt'\n",
    "#annotations_global = '/home/anjani/distant-PICO/CandidateGeneration/ResultInspection/label_overlap_inspection.txt'\n",
    "\n",
    "counter = 0\n",
    "with open(annotations_global, 'r', encoding='latin1') as af:\n",
    "\n",
    "        for annot in af: # Each annotation file\n",
    "            try:\n",
    "                counter = counter + 1\n",
    "                j = json.loads( annot )\n",
    "                for k,v in j.items(): # target\n",
    "                    if 'id' not in k:\n",
    "                        for k_i, v_i in v.items(): # each sentence\n",
    "                            if l1 in v_i and l2 in v_i:\n",
    "                                phrase = []\n",
    "                                non_o_phrase = []\n",
    "                                list1 = v_i[l1]\n",
    "                                list2 = v_i[l2]\n",
    "                                for n, (a1, a2) in enumerate( zip(list1, list2) ):\n",
    "                                    if a1 != 0 and a2 != 0:\n",
    "                                        phrase.append( v_i['tokens'][n] )\n",
    "                                    if a1 != 0 or a2 != 0:\n",
    "                                        non_o_phrase.append( v_i['tokens'][n] )\n",
    "                                if phrase:\n",
    "                                    overlaps.append( ' '.join(phrase) )\n",
    "                                if non_o_phrase:\n",
    "                                    non_overlaps.append( ' '.join(non_o_phrase) )\n",
    "            except Exception as ex:\n",
    "                pass\n",
    "                template = \"An exception of type {0} occurred. Arguments:{1!r}\"\n",
    "                message = template.format(type(ex).__name__, ex.args)\n",
    "                #print( message )\n",
    "\n",
    "                exc_type, exc_obj, exc_tb = sys.exc_info()\n",
    "                fname = os.path.split(exc_tb.tb_frame.f_code.co_filename)[1]\n",
    "                #print(exc_type, fname, exc_tb.tb_lineno)\n",
    "\n",
    "                #print(traceback.format_exc())\n",
    "\n",
    "print('Percentage overlap between ', l1, ' and ', l2, ' is: ', (len( set( overlaps ) ) / len( list(non_overlaps) ) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore \"outcome\" sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of non-null outcome sources retrieved 473893\n"
     ]
    }
   ],
   "source": [
    "outcomes_file = '/mnt/nas2/data/systematicReview/clinical_trials_gov/distant_pico_pre/temp.txt'\n",
    "\n",
    "outcomes = dict()\n",
    "\n",
    "\n",
    "with open(outcomes_file, 'r') as rf:\n",
    "    for i, eachOutcome in enumerate(rf):\n",
    "        j = json.loads( eachOutcome )\n",
    "        if j:\n",
    "            #print(type(j))\n",
    "            outcomes[i] = j\n",
    "            \n",
    "            \n",
    "print('The number of non-null outcome sources retrieved', len( outcomes ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

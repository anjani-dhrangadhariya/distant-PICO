{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6b3b4e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import enum\n",
    "import glob\n",
    "import os\n",
    "from hashlib import new\n",
    "from pathlib import Path\n",
    "import time\n",
    "from itertools import product\n",
    "\n",
    "import functools\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "#from snorkel.labeling.model import LabelModel\n",
    "from snorkel.labeling.model import LabelModel as LMsnorkel\n",
    "from snorkel.labeling import PandasLFApplier\n",
    "\n",
    "from snorkel.labeling.model import MajorityLabelVoter\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import itertools\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8562a8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "candgen_version = 'v4' # version = {v3, v4, ...}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0cd54fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import json\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7798c0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.exceptions import UndefinedMetricWarning\n",
    "\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5d1d2219",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list2Nested(l, nested_length):\n",
    "    return [l[i:i+nested_length] for i in range(0, len(l), nested_length)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "daaad8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1:1 positive to positive\n",
    "# -1:0 negative cand_gen to negative in label model\n",
    "# 0:-1 Abstain cand_gen to abstain in label model\n",
    "\n",
    "# In study type, abstain is actually a negative instance \n",
    "#labelModel_mapper_LF = {1:1, 0:0, -1:-1}\n",
    "labelModel_mapper_LF = {1:1, -1:0, 0:-1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0638a0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import LMutils\n",
    "\n",
    "train_file = f'/mnt/nas2/results/Results/systematicReview/distant_pico/EBM_PICO_GT/{candgen_version}/gt/train_ebm_labels_tui_pio3.tsv'\n",
    "training_data = pd.read_csv(train_file, sep='\\t', header=0)\n",
    "\n",
    "ebm_test_file = f'/mnt/nas2/results/Results/systematicReview/distant_pico/EBM_PICO_GT/{candgen_version}/gt/test_ebm_labels_tui_pio3.tsv'\n",
    "test_ebm_data = pd.read_csv(ebm_test_file, sep='\\t', header=0)\n",
    "test_ebm_data.rename( columns={'Unnamed: 0':'series'}, inplace=True )\n",
    "\n",
    "physio_test_file = f'/mnt/nas2/results/Results/systematicReview/distant_pico/EBM_PICO_GT/{candgen_version}/gt/test_physio_labels_tui_pio3.tsv'\n",
    "test_physio_data = pd.read_csv(physio_test_file, sep='\\t', header=0)\n",
    "test_physio_data.rename( columns={'Unnamed: 0':'series'}, inplace=True )\n",
    "\n",
    "ebm_test_corrected_file = f'/mnt/nas2/results/Results/systematicReview/distant_pico/EBM_PICO_GT/{candgen_version}/gt/test_ebm_correctedlabels_tui_pio3.tsv'\n",
    "test_ebm_corrected_data = pd.read_csv(ebm_test_corrected_file, sep='\\t', header=0)\n",
    "test_ebm_corrected_data.rename( columns={'Unnamed: 0':'series'}, inplace=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fff28521",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_df(df):\n",
    "\n",
    "    df_series = [ index for index, value in df.tokens.items() for word in ast.literal_eval(value) ]\n",
    "    df_tokens = [ word for index, value in df.tokens.items() for word in ast.literal_eval(value) ]\n",
    "    df_pos = [ word for index, value in df.pos.items() for word in ast.literal_eval(value) ]\n",
    "    df_offsets = [ word for index, value in df.offsets.items() for word in ast.literal_eval(value) ]\n",
    "\n",
    "\n",
    "    df_p = [ int(lab) for index, value in df.p.items() for lab in ast.literal_eval(value) ]\n",
    "    df_p_fine = [ int(lab) for index, value in df.p_f.items() for lab in ast.literal_eval(value) ]\n",
    "    df_i = [ int(lab) for index, value in df.i.items() for lab in ast.literal_eval(value) ]\n",
    "    df_i_fine = [ int(lab) for index, value in df.i_f.items() for lab in ast.literal_eval(value) ]\n",
    "    df_o = [ int(lab) for index, value in df.o.items() for lab in ast.literal_eval(value) ]\n",
    "    df_o_fine = [ int(lab) for index, value in df.o_f.items() for lab in ast.literal_eval(value) ]\n",
    "    df_s = [ int(lab) for index, value in df.s.items() for lab in ast.literal_eval(value) ]\n",
    "    df_s_fine = [ int(lab) for index, value in df.s_f.items() for lab in ast.literal_eval(value) ]\n",
    "    \n",
    "    df_flattened = pd.DataFrame({ 'series': df_series,\n",
    "                        'tokens' : df_tokens,\n",
    "                        'offsets': df_offsets,\n",
    "                        'pos': df_pos,\n",
    "                        'p' : df_p,\n",
    "                        'i' : df_i,\n",
    "                        'o' : df_o,\n",
    "                        's' : df_s,\n",
    "                        'p_f' : df_p_fine,\n",
    "                        'i_f' : df_i_fine,\n",
    "                        'o_f' : df_o_fine,\n",
    "                        's_f' : df_s_fine})\n",
    "    \n",
    "    return df_flattened"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4b8e07f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten the dataframes (currently only the training dataframe and test ebm dataframe with corrected labels can be flattened)\n",
    "data_df = flatten_df(training_data)\n",
    "test_ebm_data = flatten_df(test_ebm_data)\n",
    "test_ebm_corr_df = flatten_df(test_ebm_corrected_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f0c041c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "series = [\n",
    "    data_df.series.to_numpy() ,\n",
    "    test_ebm_data.series.to_numpy() ,\n",
    "    test_physio_data.series.to_numpy(),   \n",
    "    test_ebm_corr_df.series.to_numpy()\n",
    "]\n",
    "\n",
    "\n",
    "sents = [\n",
    "    data_df.tokens.to_numpy() ,\n",
    "    test_ebm_data.tokens.to_numpy() ,\n",
    "    test_physio_data.tokens.to_numpy(),   \n",
    "    test_ebm_corr_df.tokens.to_numpy()    \n",
    "]\n",
    "\n",
    "\n",
    "part_of_speech = [\n",
    "    data_df.pos.to_numpy() ,\n",
    "    test_ebm_data.pos.to_numpy() ,\n",
    "    test_physio_data.pos.to_numpy(),   \n",
    "    test_ebm_corr_df.pos.to_numpy()     \n",
    "]\n",
    "\n",
    "\n",
    "offsets = [\n",
    "    data_df.offsets.to_numpy() ,\n",
    "    test_ebm_data.offsets.to_numpy() ,\n",
    "    test_physio_data.offsets.to_numpy(),   \n",
    "    test_ebm_corr_df.offsets.to_numpy() \n",
    "]\n",
    "\n",
    "\n",
    "Y_p = [\n",
    "    data_df.p.to_numpy() , # 0 -7\n",
    "    data_df.p_f.to_numpy() , # 1 -6\n",
    "    test_ebm_data.p.to_numpy() , # 2 -5\n",
    "    test_ebm_data.p_f.to_numpy() , # 3 -4\n",
    "    test_physio_data.p.to_numpy(),  # 4 -3\n",
    "    test_ebm_corr_df.p.to_numpy(),   # 5 -2\n",
    "    test_ebm_corr_df.p_f.to_numpy() # 6 -1\n",
    "]\n",
    "\n",
    "\n",
    "Y_i = [\n",
    "    data_df.i.to_numpy() , # 0 -7\n",
    "    data_df.i_f.to_numpy() , # 1 -6\n",
    "    test_ebm_data.i.to_numpy() , # 2 -5\n",
    "    test_ebm_data.i_f.to_numpy() , # 3 -4\n",
    "    test_physio_data.i.to_numpy(),  # 4 -3\n",
    "    test_ebm_corr_df.i.to_numpy(),   # 5 -2\n",
    "    test_ebm_corr_df.i_f.to_numpy() # 6 -1\n",
    "]\n",
    "\n",
    "\n",
    "Y_o = [\n",
    "    data_df.o.to_numpy() ,\n",
    "    data_df.o_f.to_numpy() ,\n",
    "    test_ebm_data.o.to_numpy() ,\n",
    "    test_physio_data.o.to_numpy() \n",
    "]\n",
    "\n",
    "Y_s = [\n",
    "    data_df.s.to_numpy() , # 0 -7\n",
    "    data_df.s_f.to_numpy() , # 1 -6\n",
    "    test_ebm_data.s.to_numpy() , # 2 -5\n",
    "    test_ebm_data.s_f.to_numpy() , # 3 -4\n",
    "    test_physio_data.s.to_numpy(),  # 4 -3\n",
    "    test_ebm_corr_df.s.to_numpy(),   # 5 -2\n",
    "    test_ebm_corr_df.s_f.to_numpy() # 6 -1\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fd0f16cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write data for error analysis\n",
    "\n",
    "error_analysis_ebm_p = pd.DataFrame({'tokens' : test_ebm_data.tokens,\n",
    "                                'participant' : test_ebm_data.p,\n",
    "                                'participant_fine' : test_ebm_data.p_f }, \n",
    "                                columns=['tokens','participant', 'participant_fine'])\n",
    "\n",
    "#error_analysis_ebm_p.to_csv (r'/mnt/nas2/results/Results/systematicReview/distant_pico/EBM_PICO_GT/error_analysis/test_ebmgold_p', index = None, header=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c4c4068d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write data for error analysis\n",
    "\n",
    "error_analysis_ebmcorr_p = pd.DataFrame({'tokens' : test_ebm_corr_df.tokens,\n",
    "                                'participant' : test_ebm_corr_df.p,\n",
    "                                'participant_fine' : test_ebm_corr_df.p_f }, \n",
    "                                columns=['tokens','participant', 'participant_fine'])\n",
    "\n",
    "#error_analysis_ebmcorr_p.to_csv (r'/mnt/nas2/results/Results/systematicReview/distant_pico/EBM_PICO_GT/error_analysis/test_ebmgoldcorr_p', index = None, header=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0c7fe1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_list(data_column):\n",
    "    return [ word for index, value in data_column.items() for word in ast.literal_eval(value) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "35850d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_array(data_column):\n",
    "    return np.array( [ word for index, value in data_column.items() for word in ast.literal_eval(value) ] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a9f6e149",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_to_array(label_column):\n",
    "    return np.array( [ labelModel_mapper_LF[int(lab)] for index, value in label_column.items() for k, lab in ast.literal_eval(value).items() ] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b873406f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lfs(indir):\n",
    "    \n",
    "    pathlist = Path(indir).glob('**/*.tsv')\n",
    "\n",
    "    tokens = ''\n",
    "\n",
    "    lfs = dict()\n",
    "    lfs_lm = dict()\n",
    "\n",
    "    for counter, file in enumerate(pathlist):\n",
    "        \n",
    "        if '/S/' in str(file):\n",
    "\n",
    "            k = str( file ).split(f'/{candgen_version}/')[-1].replace('.tsv', '').replace('/', '_')\n",
    "            mypath = Path(file)\n",
    "            if mypath.stat().st_size != 0:\n",
    "                data = pd.read_csv(file, sep='\\t', header=0)\n",
    "\n",
    "                data_tokens = data.tokens\n",
    "                if len(tokens) < 5:\n",
    "                    tokens = df_to_array(data_tokens)\n",
    "\n",
    "                data_labels = data.labels\n",
    "                #print(data_labels[1:2])\n",
    "                labels = dict_to_array(data_labels)\n",
    "                #print(labels)\n",
    "                if len(labels) != len(tokens):\n",
    "                    print(k, len(labels) , len(tokens) )\n",
    "                #assert len(labels) == len(tokens)\n",
    "                lfs[k] = labels\n",
    "\n",
    "\n",
    "    print( 'Total number of tokens in validation set: ', len(tokens) )\n",
    "    print( 'Total number of LFs in the dictionary', len(lfs) )\n",
    "    \n",
    "    return lfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a1119c42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of tokens in validation set:  1303169\n",
      "Total number of LFs in the dictionary 6\n"
     ]
    }
   ],
   "source": [
    "indir = f'/mnt/nas2/results/Results/systematicReview/distant_pico/training_ebm_candidate_generation/{candgen_version}'\n",
    "train_ebm_lfs = get_lfs(indir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "456a19e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of tokens in validation set:  52582\n",
      "Total number of LFs in the dictionary 6\n"
     ]
    }
   ],
   "source": [
    "indir_test_ebm_corr = f'/mnt/nas2/results/Results/systematicReview/distant_pico/test_ebm_anjani_candidate_generation/{candgen_version}'\n",
    "test_ebm_corr_lfs = get_lfs(indir_test_ebm_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "58ac9849",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of tokens in validation set:  51784\n",
      "Total number of LFs in the dictionary 6\n"
     ]
    }
   ],
   "source": [
    "indir_test_ebm = f'/mnt/nas2/results/Results/systematicReview/distant_pico/test_ebm_candidate_generation/{candgen_version}'\n",
    "test_ebm_lfs = get_lfs(indir_test_ebm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "001d73ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lf_levels(umls_d:dict, pattern:str, picos:str):\n",
    "\n",
    "    umls_level = dict()\n",
    "\n",
    "    for key, value in umls_d.items():   # iter on both keys and values\n",
    "        search_pattern = pattern + picos\n",
    "        if key.startswith(search_pattern):\n",
    "            k = str(key).split('_')[-1]\n",
    "            umls_level[ k ] = value\n",
    "\n",
    "    return umls_level\n",
    "\n",
    "\n",
    "# Level 1: UMLS\n",
    "umls_p = [\n",
    "    lf_levels(train_ebm_lfs, name, 'P') \n",
    "    for i, name in enumerate(['UMLS_direct_', 'UMLS_fuzzy_'])\n",
    "]\n",
    "\n",
    "umls_p_testcorrected = [\n",
    "    lf_levels(test_ebm_corr_lfs, name, 'P') \n",
    "    for i, name in enumerate(['UMLS_direct_', 'UMLS_fuzzy_'])\n",
    "]\n",
    "\n",
    "umls_p_testebm = [\n",
    "    lf_levels(test_ebm_lfs, name, 'P') \n",
    "    for i, name in enumerate(['UMLS_direct_', 'UMLS_fuzzy_'])\n",
    "]\n",
    "\n",
    "# ------------------------------------------------------------------------\n",
    "\n",
    "umls_i = [\n",
    "    lf_levels(train_ebm_lfs, name, 'I') \n",
    "    for i, name in enumerate(['UMLS_direct_', 'UMLS_fuzzy_'])\n",
    "]\n",
    "\n",
    "umls_i_testcorrected = [\n",
    "    lf_levels(test_ebm_corr_lfs, name, 'I') \n",
    "    for i, name in enumerate(['UMLS_direct_', 'UMLS_fuzzy_'])\n",
    "]\n",
    "\n",
    "umls_i_testebm = [\n",
    "    lf_levels(test_ebm_lfs, name, 'I') \n",
    "    for i, name in enumerate(['UMLS_direct_', 'UMLS_fuzzy_'])\n",
    "]\n",
    "\n",
    "# ------------------------------------------------------------------------\n",
    "\n",
    "umls_o = [\n",
    "    lf_levels(train_ebm_lfs, name, 'O') \n",
    "    for i, name in enumerate(['UMLS_direct_', 'UMLS_fuzzy_'])\n",
    "]\n",
    "\n",
    "umls_o_testcorrected = [\n",
    "    lf_levels(test_ebm_corr_lfs, name, 'O') \n",
    "    for i, name in enumerate(['UMLS_direct_', 'UMLS_fuzzy_'])\n",
    "]\n",
    "\n",
    "umls_o_testebm = [\n",
    "    lf_levels(test_ebm_lfs, name, 'O') \n",
    "    for i, name in enumerate(['UMLS_direct_', 'UMLS_fuzzy_'])\n",
    "]\n",
    "\n",
    "# ------------------------------------------------------------------------\n",
    "# ------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "# Level 2: non UMLS\n",
    "nonumls_p = [\n",
    "    lf_levels(train_ebm_lfs, name, 'P') \n",
    "    for i, name in enumerate(['nonUMLS_direct_', 'nonUMLS_fuzzy_'])\n",
    "]\n",
    "\n",
    "nonumls_p_testcorrected = [\n",
    "    lf_levels(test_ebm_corr_lfs, name, 'P') \n",
    "    for i, name in enumerate(['nonUMLS_direct_', 'nonUMLS_fuzzy_'])\n",
    "]\n",
    "\n",
    "nonumls_p_testebm = [\n",
    "    lf_levels(test_ebm_lfs, name, 'P') \n",
    "    for i, name in enumerate(['nonUMLS_direct_', 'nonUMLS_fuzzy_'])\n",
    "]\n",
    "\n",
    "# ------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "nonumls_i = [\n",
    "    lf_levels(train_ebm_lfs, name, 'I') \n",
    "    for i, name in enumerate(['nonUMLS_direct_', 'nonUMLS_fuzzy_'])\n",
    "]\n",
    "\n",
    "nonumls_i_testcorrected = [\n",
    "    lf_levels(test_ebm_corr_lfs, name, 'I') \n",
    "    for i, name in enumerate(['nonUMLS_direct_', 'nonUMLS_fuzzy_'])\n",
    "]\n",
    "\n",
    "nonumls_i_testebm = [\n",
    "    lf_levels(test_ebm_lfs, name, 'I') \n",
    "    for i, name in enumerate(['nonUMLS_direct_', 'nonUMLS_fuzzy_'])\n",
    "]\n",
    "\n",
    "# ------------------------------------------------------------------------\n",
    "\n",
    "nonumls_o = [\n",
    "    lf_levels(train_ebm_lfs, name, 'O') \n",
    "    for i, name in enumerate(['nonUMLS_direct_', 'nonUMLS_fuzzy_'])\n",
    "]\n",
    "\n",
    "nonumls_o_testcorrected = [\n",
    "    lf_levels(test_ebm_corr_lfs, name, 'O') \n",
    "    for i, name in enumerate(['nonUMLS_direct_', 'nonUMLS_fuzzy_'])\n",
    "]\n",
    "\n",
    "nonumls_o_testebm = [\n",
    "    lf_levels(test_ebm_lfs, name, 'O') \n",
    "    for i, name in enumerate(['nonUMLS_direct_', 'nonUMLS_fuzzy_'])\n",
    "]\n",
    "\n",
    "# ------------------------------------------------------------------------\n",
    "# ------------------------------------------------------------------------\n",
    "\n",
    "# Level 3: DS\n",
    "ds_p = [\n",
    "    lf_levels(train_ebm_lfs, name, 'P') \n",
    "    for i, name in enumerate(['ds_direct_', 'ds_fuzzy_'])\n",
    "]\n",
    "\n",
    "ds_p_testcorrected = [\n",
    "    lf_levels(test_ebm_corr_lfs, name, 'P') \n",
    "    for i, name in enumerate(['ds_direct_', 'ds_fuzzy_'])\n",
    "]\n",
    "\n",
    "ds_p_testebm = [\n",
    "    lf_levels(test_ebm_lfs, name, 'P') \n",
    "    for i, name in enumerate(['ds_direct_', 'ds_fuzzy_'])\n",
    "]\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------------\n",
    "\n",
    "ds_i = [\n",
    "    lf_levels(train_ebm_lfs, name, 'I') \n",
    "    for i, name in enumerate(['ds_direct_', 'ds_fuzzy_'])\n",
    "]\n",
    "\n",
    "ds_i_testcorrected = [\n",
    "    lf_levels(test_ebm_corr_lfs, name, 'I') \n",
    "    for i, name in enumerate(['ds_direct_', 'ds_fuzzy_'])\n",
    "]\n",
    "\n",
    "ds_i_testebm = [\n",
    "    lf_levels(test_ebm_lfs, name, 'I') \n",
    "    for i, name in enumerate(['ds_direct_', 'ds_fuzzy_'])\n",
    "]\n",
    "\n",
    "# ------------------------------------------------------------------------\n",
    "\n",
    "ds_o = [\n",
    "    lf_levels(train_ebm_lfs, name, 'O') \n",
    "    for i, name in enumerate(['ds_direct_', 'ds_fuzzy_'])\n",
    "]\n",
    "\n",
    "ds_o_testcorrected = [\n",
    "    lf_levels(test_ebm_corr_lfs, name, 'O') \n",
    "    for i, name in enumerate(['ds_direct_', 'ds_fuzzy_'])\n",
    "]\n",
    "\n",
    "ds_o_testebm = [\n",
    "    lf_levels(test_ebm_lfs, name, 'O') \n",
    "    for i, name in enumerate(['ds_direct_', 'ds_fuzzy_'])\n",
    "]\n",
    "\n",
    "# ------------------------------------------------------------------------\n",
    "# ------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "# Level 4: dictionary, rules, heuristics\n",
    "heur_p = [\n",
    "    lf_levels(train_ebm_lfs, name, 'P') \n",
    "    for i, name in enumerate(['heuristics_direct_'])\n",
    "]\n",
    "\n",
    "heur_p_testcorrected = [\n",
    "    lf_levels(test_ebm_corr_lfs, name, 'P') \n",
    "    for i, name in enumerate(['heuristics_direct_'])\n",
    "]\n",
    "\n",
    "heur_p_testebm = [\n",
    "    lf_levels(test_ebm_lfs, name, 'P') \n",
    "    for i, name in enumerate(['heuristics_direct_'])\n",
    "]\n",
    "\n",
    "# ------------------------------------------------------------------------\n",
    "\n",
    "heur_i = [\n",
    "    lf_levels(train_ebm_lfs, name, 'I') \n",
    "    for i, name in enumerate(['heuristics_direct_'])\n",
    "]\n",
    "\n",
    "heur_i_testcorrected = [\n",
    "    lf_levels(test_ebm_corr_lfs, name, 'I') \n",
    "    for i, name in enumerate(['heuristics_direct_'])\n",
    "]\n",
    "\n",
    "heur_i_testebm = [\n",
    "    lf_levels(test_ebm_lfs, name, 'I') \n",
    "    for i, name in enumerate(['heuristics_direct_'])\n",
    "]\n",
    "\n",
    "# ------------------------------------------------------------------------\n",
    "\n",
    "heur_o = [\n",
    "    lf_levels(train_ebm_lfs, name, 'O') \n",
    "    for i, name in enumerate(['heuristics_direct_'])\n",
    "]\n",
    "\n",
    "heur_o_testcorrected = [\n",
    "    lf_levels(test_ebm_corr_lfs, name, 'O') \n",
    "    for i, name in enumerate(['heuristics_direct_'])\n",
    "]\n",
    "\n",
    "\n",
    "heur_o_testebm = [\n",
    "    lf_levels(test_ebm_lfs, name, 'O') \n",
    "    for i, name in enumerate(['heuristics_direct_'])\n",
    "]\n",
    "\n",
    "# ------------------------------------------------------------------------\n",
    "\n",
    "heur_s = [\n",
    "    lf_levels(train_ebm_lfs, name, 'S') \n",
    "    for i, name in enumerate(['heuristics_direct_'])\n",
    "]\n",
    "\n",
    "heur_s_testcorrected = [\n",
    "    lf_levels(test_ebm_corr_lfs, name, 'S') \n",
    "    for i, name in enumerate(['heuristics_direct_'])\n",
    "]\n",
    "\n",
    "\n",
    "heur_s_testebm = [\n",
    "    lf_levels(test_ebm_lfs, name, 'S') \n",
    "    for i, name in enumerate(['heuristics_direct_'])\n",
    "]\n",
    "\n",
    "# ------------------------------------------------------------------------\n",
    "# ------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "dict_p = [\n",
    "    lf_levels(train_ebm_lfs, name, 'P') \n",
    "    for i, name in enumerate(['dictionary_direct_', 'dictionary_fuzzy_'])\n",
    "]\n",
    "\n",
    "dict_p_testcorrected = [\n",
    "    lf_levels(test_ebm_corr_lfs, name, 'P') \n",
    "    for i, name in enumerate(['dictionary_direct_', 'dictionary_fuzzy_'])\n",
    "]\n",
    "\n",
    "dict_p_testebm = [\n",
    "    lf_levels(test_ebm_lfs, name, 'P') \n",
    "    for i, name in enumerate(['dictionary_direct_', 'dictionary_fuzzy_'])\n",
    "]\n",
    "\n",
    "# ------------------------------------------------------------------------\n",
    "\n",
    "dict_i = [\n",
    "    lf_levels(train_ebm_lfs, name, 'I') \n",
    "    for i, name in enumerate(['dictionary_direct_', 'dictionary_fuzzy_'])\n",
    "]\n",
    "\n",
    "dict_i_testcorrected = [\n",
    "    lf_levels(test_ebm_corr_lfs, name, 'I') \n",
    "    for i, name in enumerate(['dictionary_direct_', 'dictionary_fuzzy_'])\n",
    "]\n",
    "\n",
    "dict_i_testebm = [\n",
    "    lf_levels(test_ebm_lfs, name, 'I') \n",
    "    for i, name in enumerate(['dictionary_direct_', 'dictionary_fuzzy_'])\n",
    "]\n",
    "\n",
    "# ------------------------------------------------------------------------\n",
    "\n",
    "dict_o = [\n",
    "    lf_levels(train_ebm_lfs, name, 'O') \n",
    "    for i, name in enumerate(['dictionary_direct_', 'dictionary_fuzzy_'])\n",
    "]\n",
    "\n",
    "dict_o_testcorrected = [\n",
    "    lf_levels(test_ebm_corr_lfs, name, 'O') \n",
    "    for i, name in enumerate(['dictionary_direct_', 'dictionary_fuzzy_'])\n",
    "]\n",
    "\n",
    "dict_o_testebm = [\n",
    "    lf_levels(test_ebm_lfs, name, 'O') \n",
    "    for i, name in enumerate(['dictionary_direct_', 'dictionary_fuzzy_'])\n",
    "]\n",
    "\n",
    "# ------------------------------------------------------------------------\n",
    "\n",
    "dict_s = [\n",
    "    lf_levels(train_ebm_lfs, name, 'S') \n",
    "    for i, name in enumerate(['dictionary_direct_', 'dictionary_fuzzy_'])\n",
    "]\n",
    "\n",
    "dict_s_testcorrected = [\n",
    "    lf_levels(test_ebm_corr_lfs, name, 'S') \n",
    "    for i, name in enumerate(['dictionary_direct_', 'dictionary_fuzzy_'])\n",
    "]\n",
    "\n",
    "dict_s_testebm = [\n",
    "    lf_levels(test_ebm_lfs, name, 'S') \n",
    "    for i, name in enumerate(['dictionary_direct_', 'dictionary_fuzzy_'])\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "cdb4ad6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Study Type data\n",
    "\n",
    "train_s_candidates = [dict_s[1], heur_s[0]]\n",
    "test_s_ebm_corr_candidates = [dict_s_testcorrected[1], heur_s_testcorrected[0]]\n",
    "test_s_ebm_candidates = [dict_s_testebm[1], heur_s_testebm[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2c6e5471",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'lr': [0.001, 0.0001],\n",
    "    'l2': [0.001, 0.0001],\n",
    "    'n_epochs': [50, 100, 200, 600, 700, 1000, 2000],\n",
    "    'prec_init': [0.6, 0.7, 0.8, 0.9],\n",
    "    'optimizer': [\"adamax\", \"adam\", \"sgd\"],\n",
    "    'lr_scheduler': ['constant'],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3d083955",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_param_grid(param_grid, seed):\n",
    "    \"\"\" Sample parameter grid\n",
    "    :param param_grid:\n",
    "    :param seed:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    rstate = np.random.get_state()\n",
    "    np.random.seed(seed)\n",
    "    params = list(product(*[param_grid[name] for name in param_grid]))\n",
    "    np.random.shuffle(params)\n",
    "    np.random.set_state(rstate)\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "602295fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search(model_class,\n",
    "                model_class_init,\n",
    "                param_grid,\n",
    "                train=None,\n",
    "                dev=None,\n",
    "                other_train=None,\n",
    "                n_model_search=5,\n",
    "                val_metric='f1_macro',\n",
    "                seed=1234,\n",
    "                checkpoint_gt_mv=False,\n",
    "                tag_fmt_ckpnt='IO'):\n",
    "    \n",
    "    \n",
    "    \"\"\"Simple grid search helper function\n",
    "    Parameters\n",
    "    ----------\n",
    "    model_class\n",
    "    model_class_init\n",
    "    param_grid\n",
    "    train\n",
    "    dev\n",
    "    n_model_search\n",
    "    val_metric\n",
    "    seed\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    \"\"\"\n",
    "    \n",
    "    L_train, Y_train = train\n",
    "    L_dev, Y_dev = dev\n",
    "\n",
    "    # sample configs\n",
    "    params = sample_param_grid(param_grid, seed)[:n_model_search]\n",
    "\n",
    "    defaults = {'seed': seed}\n",
    "    best_score, best_config = 0.0, None\n",
    "    print(f\"Grid search over {len(params)} configs\")\n",
    "\n",
    "    for i, config in enumerate(params):\n",
    "        print(f'[{i}] Label Model')\n",
    "        config = dict(zip(param_grid.keys(), config))\n",
    "        config.update({param: value for param, value in defaults.items() if param not in config})\n",
    "\n",
    "        model = model_class(**model_class_init)\n",
    "        model.fit(L_train, Y_dev, **config)\n",
    "        \n",
    "        y_pred = model.predict(L_dev)\n",
    "        \n",
    "                \n",
    "        if -1 in y_pred:\n",
    "            print(\"Label model predicted -1 (TODO: this happens inconsistently)\")\n",
    "            continue\n",
    "    \n",
    "    \n",
    "    return model, best_config, best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "192e9fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_plus(cands, best_model, gt_labels, mode=None):\n",
    "    \n",
    "    combined_lf = []\n",
    "    combined_lf.extend( list(cands[0].values()) ) # Combine with level 4\n",
    "    combined_lf.extend( list(cands[1].values()) ) # combine with level 4\n",
    "\n",
    "\n",
    "    L = np.array( combined_lf )\n",
    "    L = np.transpose(L)\n",
    "    \n",
    "    if mode == 'only_pred':\n",
    "    \n",
    "        predictions_probablities = best_model.predict_proba(L)\n",
    "        predictions = best_model.predict(L)\n",
    "        \n",
    "        return predictions_probablities\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        predictions_probablities = best_model.predict_proba(L)\n",
    "        predictions = best_model.predict(L)\n",
    "    \n",
    "        groundtruth = np.array(gt_labels) \n",
    "\n",
    "        #groundtruth = [-1 if x == 0 else x for x in gt_labels] # XXX if \"test_ebm_correct\"\n",
    "        groundtruth = np.array(groundtruth)\n",
    "\n",
    "        groundtruth_ = []\n",
    "        predictions_ = []\n",
    "        for g, p in zip(groundtruth, np.array(predictions)):\n",
    "            if p == -1:\n",
    "                pass\n",
    "                #print( 'model predicts -1 inconsistently.' )\n",
    "            else:\n",
    "                groundtruth_.append(g)\n",
    "                predictions_.append(p)\n",
    "\n",
    "\n",
    "\n",
    "        cr = classification_report( groundtruth_, predictions_, digits=4, output_dict=True )\n",
    "        cr_ = classification_report( groundtruth_, predictions_, digits=4 )\n",
    "        print( cr_ )\n",
    "    \n",
    "        return predictions_probablities, cr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5b0f2f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for entities that do not have UMLS partitions\n",
    "\n",
    "def train_plus(train_cands, test_cands, test_corr_cands, Y_d, picos, paramgrid, mode):\n",
    "   \n",
    "    gold_labels = ''\n",
    "    gold_labels_fine = ''\n",
    "    \n",
    "    \n",
    "    model_class_init = {\n",
    "        'cardinality': 2, \n",
    "        'verbose': True\n",
    "    }\n",
    "\n",
    "    num_hyperparams = functools.reduce(lambda x,y:x*y, [len(x) for x in param_grid.values()])\n",
    "    print(\"Hyperparamater Search Space:\", num_hyperparams)\n",
    "    n_model_search = 50\n",
    "    \n",
    "\n",
    "    '''#########################################################################\n",
    "    # Choosing the number of LF's from UMLS all\n",
    "    #########################################################################'''\n",
    "\n",
    "\n",
    "    best_f1_macro = 0.0\n",
    "    best_overall_model = ''\n",
    "    best_overall_config = ''\n",
    "\n",
    "    combined_lf = []\n",
    "    combined_lf.extend( list(train_cands[0].values()) ) \n",
    "    combined_lf.extend( list(train_cands[1].values()) )\n",
    "    \n",
    "    L = np.array( combined_lf )\n",
    "    L = np.transpose(L)\n",
    "\n",
    "    # sample configs\n",
    "    params = sample_param_grid(param_grid, 0)[:n_model_search]\n",
    "    defaults = {'seed': 0}\n",
    "    print(f\"Grid search over {len(params)} configs\")\n",
    "\n",
    "    for i, config in enumerate(params):\n",
    "        print(f'[{i}] Label Model')\n",
    "        config = dict(zip(param_grid.keys(), config))\n",
    "        config.update({param: value for param, value in defaults.items() if param not in config})\n",
    "\n",
    "        #label_model = LabelModel(cardinality=2, verbose=True)\n",
    "        #label_model.fit(L_train=L, **config)\n",
    "        \n",
    "        label_model = LMsnorkel(**model_class_init)\n",
    "        label_model.fit(L, **config)\n",
    "\n",
    "        # Predict on the test ebm correct set\n",
    "        preds, class_report = test_corr_probas = predict_plus(test_corr_cands, label_model, Y_d[-2]) # test ebm correct   \n",
    "        \n",
    "        if class_report['macro avg']['f1-score'] > best_f1_macro:\n",
    "            best_f1_macro = class_report['macro avg']['f1-score']\n",
    "            best_overall_model = label_model\n",
    "            best_overall_config = config\n",
    "            \n",
    "    # Save the best label model\n",
    "    print('Save the best overall model, configuration and partition for this experiment level')\n",
    "    # Save your model or results\n",
    "    save_dir = f'/mnt/nas2/results/Results/systematicReview/distant_pico/models/LabelModels/{picos}/'\n",
    "    filename = 'stpartition_' + '_epoch_' + str(best_overall_config['n_epochs'])\n",
    "    joblib.dump(best_overall_model, f'{save_dir}/{filename}.pkl') \n",
    "    joblib.dump(best_overall_config, f'{save_dir}/{filename}.json')\n",
    "    \n",
    "    \n",
    "    #load your model for further usage\n",
    "    loaded_best_model = joblib.load(f'{save_dir}/{filename}.pkl')\n",
    "    \n",
    "    # Predict on the training set\n",
    "    train_probas = predict_plus(train_cands,loaded_best_model, Y_d[-6], mode= 'only_pred') # train \n",
    "    \n",
    "    # Write training predictions to file\n",
    "    # tokens\tpos\toffsets\tlabels\ttrue_labels\n",
    "    #print( train_probas.shape )\n",
    "    train_probas = train_probas.tolist()\n",
    "    #print( len(train_probas) )\n",
    "    #train_probas = [list(tp) for tp in train_probas]\n",
    "    #train_probas_series = pd.Series(list(train_probas))\n",
    "    train_probas_series = pd.Series(train_probas)\n",
    "    data_df['labels'] = train_probas_series.values\n",
    "\n",
    "    # Write predictions on the training data to the file\n",
    "    \n",
    "    write_df = data_df.groupby(['series'])[['series', 'tokens', 'pos', 'offsets', 'labels', str(picos), str(picos)+'_f']].agg(list)\n",
    "    write_file_path = f'/mnt/nas2/results/Results/systematicReview/distant_pico/predictions/LabelModels/{picos}/{filename}_bestmodel.tsv'\n",
    "    write_df.to_csv (write_file_path, index = None, sep = '\\t', header=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "04395d3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparamater Search Space: 336\n",
      "Grid search over 50 configs\n",
      "[0] Label Model\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9997    0.9992    0.9995     15547\n",
      "           1     0.9646    0.9879    0.9761       331\n",
      "\n",
      "    accuracy                         0.9990     15878\n",
      "   macro avg     0.9822    0.9936    0.9878     15878\n",
      "weighted avg     0.9990    0.9990    0.9990     15878\n",
      "\n",
      "[1] Label Model\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9997    0.9992    0.9995     15547\n",
      "           1     0.9646    0.9879    0.9761       331\n",
      "\n",
      "    accuracy                         0.9990     15878\n",
      "   macro avg     0.9822    0.9936    0.9878     15878\n",
      "weighted avg     0.9990    0.9990    0.9990     15878\n",
      "\n",
      "[2] Label Model\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9997    0.9992    0.9995     15547\n",
      "           1     0.9646    0.9879    0.9761       331\n",
      "\n",
      "    accuracy                         0.9990     15878\n",
      "   macro avg     0.9822    0.9936    0.9878     15878\n",
      "weighted avg     0.9990    0.9990    0.9990     15878\n",
      "\n",
      "[3] Label Model\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9997    0.9992    0.9995     15547\n",
      "           1     0.9646    0.9879    0.9761       331\n",
      "\n",
      "    accuracy                         0.9990     15878\n",
      "   macro avg     0.9822    0.9936    0.9878     15878\n",
      "weighted avg     0.9990    0.9990    0.9990     15878\n",
      "\n",
      "[4] Label Model\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9997    0.9992    0.9995     15547\n",
      "           1     0.9646    0.9879    0.9761       331\n",
      "\n",
      "    accuracy                         0.9990     15878\n",
      "   macro avg     0.9822    0.9936    0.9878     15878\n",
      "weighted avg     0.9990    0.9990    0.9990     15878\n",
      "\n",
      "[5] Label Model\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9997    0.9992    0.9995     15547\n",
      "           1     0.9646    0.9879    0.9761       331\n",
      "\n",
      "    accuracy                         0.9990     15878\n",
      "   macro avg     0.9822    0.9936    0.9878     15878\n",
      "weighted avg     0.9990    0.9990    0.9990     15878\n",
      "\n",
      "[6] Label Model\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9997    0.9992    0.9995     15547\n",
      "           1     0.9646    0.9879    0.9761       331\n",
      "\n",
      "    accuracy                         0.9990     15878\n",
      "   macro avg     0.9822    0.9936    0.9878     15878\n",
      "weighted avg     0.9990    0.9990    0.9990     15878\n",
      "\n",
      "[7] Label Model\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9997    0.9992    0.9995     15547\n",
      "           1     0.9646    0.9879    0.9761       331\n",
      "\n",
      "    accuracy                         0.9990     15878\n",
      "   macro avg     0.9822    0.9936    0.9878     15878\n",
      "weighted avg     0.9990    0.9990    0.9990     15878\n",
      "\n",
      "[8] Label Model\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9997    0.9992    0.9995     15547\n",
      "           1     0.9646    0.9879    0.9761       331\n",
      "\n",
      "    accuracy                         0.9990     15878\n",
      "   macro avg     0.9822    0.9936    0.9878     15878\n",
      "weighted avg     0.9990    0.9990    0.9990     15878\n",
      "\n",
      "[9] Label Model\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9997    0.9992    0.9995     15547\n",
      "           1     0.9646    0.9879    0.9761       331\n",
      "\n",
      "    accuracy                         0.9990     15878\n",
      "   macro avg     0.9822    0.9936    0.9878     15878\n",
      "weighted avg     0.9990    0.9990    0.9990     15878\n",
      "\n",
      "[10] Label Model\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9997    0.9992    0.9995     15547\n",
      "           1     0.9646    0.9879    0.9761       331\n",
      "\n",
      "    accuracy                         0.9990     15878\n",
      "   macro avg     0.9822    0.9936    0.9878     15878\n",
      "weighted avg     0.9990    0.9990    0.9990     15878\n",
      "\n",
      "[11] Label Model\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9997    0.9992    0.9995     15547\n",
      "           1     0.9646    0.9879    0.9761       331\n",
      "\n",
      "    accuracy                         0.9990     15878\n",
      "   macro avg     0.9822    0.9936    0.9878     15878\n",
      "weighted avg     0.9990    0.9990    0.9990     15878\n",
      "\n",
      "[12] Label Model\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9997    0.9992    0.9995     15547\n",
      "           1     0.9646    0.9879    0.9761       331\n",
      "\n",
      "    accuracy                         0.9990     15878\n",
      "   macro avg     0.9822    0.9936    0.9878     15878\n",
      "weighted avg     0.9990    0.9990    0.9990     15878\n",
      "\n",
      "[13] Label Model\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9997    0.9992    0.9995     15547\n",
      "           1     0.9646    0.9879    0.9761       331\n",
      "\n",
      "    accuracy                         0.9990     15878\n",
      "   macro avg     0.9822    0.9936    0.9878     15878\n",
      "weighted avg     0.9990    0.9990    0.9990     15878\n",
      "\n",
      "[14] Label Model\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9997    0.9992    0.9995     15547\n",
      "           1     0.9646    0.9879    0.9761       331\n",
      "\n",
      "    accuracy                         0.9990     15878\n",
      "   macro avg     0.9822    0.9936    0.9878     15878\n",
      "weighted avg     0.9990    0.9990    0.9990     15878\n",
      "\n",
      "[15] Label Model\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9997    0.9992    0.9995     15547\n",
      "           1     0.9646    0.9879    0.9761       331\n",
      "\n",
      "    accuracy                         0.9990     15878\n",
      "   macro avg     0.9822    0.9936    0.9878     15878\n",
      "weighted avg     0.9990    0.9990    0.9990     15878\n",
      "\n",
      "[16] Label Model\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9997    0.9992    0.9995     15547\n",
      "           1     0.9646    0.9879    0.9761       331\n",
      "\n",
      "    accuracy                         0.9990     15878\n",
      "   macro avg     0.9822    0.9936    0.9878     15878\n",
      "weighted avg     0.9990    0.9990    0.9990     15878\n",
      "\n",
      "[17] Label Model\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9997    0.9992    0.9995     15547\n",
      "           1     0.9646    0.9879    0.9761       331\n",
      "\n",
      "    accuracy                         0.9990     15878\n",
      "   macro avg     0.9822    0.9936    0.9878     15878\n",
      "weighted avg     0.9990    0.9990    0.9990     15878\n",
      "\n",
      "[18] Label Model\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9997    0.9992    0.9995     15547\n",
      "           1     0.9646    0.9879    0.9761       331\n",
      "\n",
      "    accuracy                         0.9990     15878\n",
      "   macro avg     0.9822    0.9936    0.9878     15878\n",
      "weighted avg     0.9990    0.9990    0.9990     15878\n",
      "\n",
      "[19] Label Model\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9997    0.9992    0.9995     15547\n",
      "           1     0.9646    0.9879    0.9761       331\n",
      "\n",
      "    accuracy                         0.9990     15878\n",
      "   macro avg     0.9822    0.9936    0.9878     15878\n",
      "weighted avg     0.9990    0.9990    0.9990     15878\n",
      "\n",
      "[20] Label Model\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9997    0.9992    0.9995     15547\n",
      "           1     0.9646    0.9879    0.9761       331\n",
      "\n",
      "    accuracy                         0.9990     15878\n",
      "   macro avg     0.9822    0.9936    0.9878     15878\n",
      "weighted avg     0.9990    0.9990    0.9990     15878\n",
      "\n",
      "[21] Label Model\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9997    0.9992    0.9995     15547\n",
      "           1     0.9646    0.9879    0.9761       331\n",
      "\n",
      "    accuracy                         0.9990     15878\n",
      "   macro avg     0.9822    0.9936    0.9878     15878\n",
      "weighted avg     0.9990    0.9990    0.9990     15878\n",
      "\n",
      "[22] Label Model\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9997    0.9992    0.9995     15547\n",
      "           1     0.9646    0.9879    0.9761       331\n",
      "\n",
      "    accuracy                         0.9990     15878\n",
      "   macro avg     0.9822    0.9936    0.9878     15878\n",
      "weighted avg     0.9990    0.9990    0.9990     15878\n",
      "\n",
      "[23] Label Model\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9997    0.9992    0.9995     15547\n",
      "           1     0.9646    0.9879    0.9761       331\n",
      "\n",
      "    accuracy                         0.9990     15878\n",
      "   macro avg     0.9822    0.9936    0.9878     15878\n",
      "weighted avg     0.9990    0.9990    0.9990     15878\n",
      "\n",
      "[24] Label Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9997    0.9992    0.9995     15547\n",
      "           1     0.9646    0.9879    0.9761       331\n",
      "\n",
      "    accuracy                         0.9990     15878\n",
      "   macro avg     0.9822    0.9936    0.9878     15878\n",
      "weighted avg     0.9990    0.9990    0.9990     15878\n",
      "\n",
      "[25] Label Model\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9997    0.9992    0.9995     15547\n",
      "           1     0.9646    0.9879    0.9761       331\n",
      "\n",
      "    accuracy                         0.9990     15878\n",
      "   macro avg     0.9822    0.9936    0.9878     15878\n",
      "weighted avg     0.9990    0.9990    0.9990     15878\n",
      "\n",
      "[26] Label Model\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9997    0.9992    0.9995     15547\n",
      "           1     0.9646    0.9879    0.9761       331\n",
      "\n",
      "    accuracy                         0.9990     15878\n",
      "   macro avg     0.9822    0.9936    0.9878     15878\n",
      "weighted avg     0.9990    0.9990    0.9990     15878\n",
      "\n",
      "[27] Label Model\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9997    0.9992    0.9995     15547\n",
      "           1     0.9646    0.9879    0.9761       331\n",
      "\n",
      "    accuracy                         0.9990     15878\n",
      "   macro avg     0.9822    0.9936    0.9878     15878\n",
      "weighted avg     0.9990    0.9990    0.9990     15878\n",
      "\n",
      "[28] Label Model\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9997    0.9992    0.9995     15547\n",
      "           1     0.9646    0.9879    0.9761       331\n",
      "\n",
      "    accuracy                         0.9990     15878\n",
      "   macro avg     0.9822    0.9936    0.9878     15878\n",
      "weighted avg     0.9990    0.9990    0.9990     15878\n",
      "\n",
      "[29] Label Model\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9997    0.9992    0.9995     15547\n",
      "           1     0.9646    0.9879    0.9761       331\n",
      "\n",
      "    accuracy                         0.9990     15878\n",
      "   macro avg     0.9822    0.9936    0.9878     15878\n",
      "weighted avg     0.9990    0.9990    0.9990     15878\n",
      "\n",
      "[30] Label Model\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9997    0.9992    0.9995     15547\n",
      "           1     0.9646    0.9879    0.9761       331\n",
      "\n",
      "    accuracy                         0.9990     15878\n",
      "   macro avg     0.9822    0.9936    0.9878     15878\n",
      "weighted avg     0.9990    0.9990    0.9990     15878\n",
      "\n",
      "[31] Label Model\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9997    0.9992    0.9995     15547\n",
      "           1     0.9646    0.9879    0.9761       331\n",
      "\n",
      "    accuracy                         0.9990     15878\n",
      "   macro avg     0.9822    0.9936    0.9878     15878\n",
      "weighted avg     0.9990    0.9990    0.9990     15878\n",
      "\n",
      "[32] Label Model\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9997    0.9992    0.9995     15547\n",
      "           1     0.9646    0.9879    0.9761       331\n",
      "\n",
      "    accuracy                         0.9990     15878\n",
      "   macro avg     0.9822    0.9936    0.9878     15878\n",
      "weighted avg     0.9990    0.9990    0.9990     15878\n",
      "\n",
      "[33] Label Model\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9997    0.9992    0.9995     15547\n",
      "           1     0.9646    0.9879    0.9761       331\n",
      "\n",
      "    accuracy                         0.9990     15878\n",
      "   macro avg     0.9822    0.9936    0.9878     15878\n",
      "weighted avg     0.9990    0.9990    0.9990     15878\n",
      "\n",
      "[34] Label Model\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9997    0.9992    0.9995     15547\n",
      "           1     0.9646    0.9879    0.9761       331\n",
      "\n",
      "    accuracy                         0.9990     15878\n",
      "   macro avg     0.9822    0.9936    0.9878     15878\n",
      "weighted avg     0.9990    0.9990    0.9990     15878\n",
      "\n",
      "[35] Label Model\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9997    0.9992    0.9995     15547\n",
      "           1     0.9646    0.9879    0.9761       331\n",
      "\n",
      "    accuracy                         0.9990     15878\n",
      "   macro avg     0.9822    0.9936    0.9878     15878\n",
      "weighted avg     0.9990    0.9990    0.9990     15878\n",
      "\n",
      "[36] Label Model\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9997    0.9992    0.9995     15547\n",
      "           1     0.9646    0.9879    0.9761       331\n",
      "\n",
      "    accuracy                         0.9990     15878\n",
      "   macro avg     0.9822    0.9936    0.9878     15878\n",
      "weighted avg     0.9990    0.9990    0.9990     15878\n",
      "\n",
      "[37] Label Model\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9997    0.9992    0.9995     15547\n",
      "           1     0.9646    0.9879    0.9761       331\n",
      "\n",
      "    accuracy                         0.9990     15878\n",
      "   macro avg     0.9822    0.9936    0.9878     15878\n",
      "weighted avg     0.9990    0.9990    0.9990     15878\n",
      "\n",
      "[38] Label Model\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9997    0.9992    0.9995     15547\n",
      "           1     0.9646    0.9879    0.9761       331\n",
      "\n",
      "    accuracy                         0.9990     15878\n",
      "   macro avg     0.9822    0.9936    0.9878     15878\n",
      "weighted avg     0.9990    0.9990    0.9990     15878\n",
      "\n",
      "[39] Label Model\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9997    0.9992    0.9995     15547\n",
      "           1     0.9646    0.9879    0.9761       331\n",
      "\n",
      "    accuracy                         0.9990     15878\n",
      "   macro avg     0.9822    0.9936    0.9878     15878\n",
      "weighted avg     0.9990    0.9990    0.9990     15878\n",
      "\n",
      "[40] Label Model\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9997    0.9992    0.9995     15547\n",
      "           1     0.9646    0.9879    0.9761       331\n",
      "\n",
      "    accuracy                         0.9990     15878\n",
      "   macro avg     0.9822    0.9936    0.9878     15878\n",
      "weighted avg     0.9990    0.9990    0.9990     15878\n",
      "\n",
      "[41] Label Model\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9997    0.9992    0.9995     15547\n",
      "           1     0.9646    0.9879    0.9761       331\n",
      "\n",
      "    accuracy                         0.9990     15878\n",
      "   macro avg     0.9822    0.9936    0.9878     15878\n",
      "weighted avg     0.9990    0.9990    0.9990     15878\n",
      "\n",
      "[42] Label Model\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9997    0.9992    0.9995     15547\n",
      "           1     0.9646    0.9879    0.9761       331\n",
      "\n",
      "    accuracy                         0.9990     15878\n",
      "   macro avg     0.9822    0.9936    0.9878     15878\n",
      "weighted avg     0.9990    0.9990    0.9990     15878\n",
      "\n",
      "[43] Label Model\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9997    0.9992    0.9995     15547\n",
      "           1     0.9646    0.9879    0.9761       331\n",
      "\n",
      "    accuracy                         0.9990     15878\n",
      "   macro avg     0.9822    0.9936    0.9878     15878\n",
      "weighted avg     0.9990    0.9990    0.9990     15878\n",
      "\n",
      "[44] Label Model\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9997    0.9992    0.9995     15547\n",
      "           1     0.9646    0.9879    0.9761       331\n",
      "\n",
      "    accuracy                         0.9990     15878\n",
      "   macro avg     0.9822    0.9936    0.9878     15878\n",
      "weighted avg     0.9990    0.9990    0.9990     15878\n",
      "\n",
      "[45] Label Model\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9997    0.9992    0.9995     15547\n",
      "           1     0.9646    0.9879    0.9761       331\n",
      "\n",
      "    accuracy                         0.9990     15878\n",
      "   macro avg     0.9822    0.9936    0.9878     15878\n",
      "weighted avg     0.9990    0.9990    0.9990     15878\n",
      "\n",
      "[46] Label Model\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9997    0.9992    0.9995     15547\n",
      "           1     0.9646    0.9879    0.9761       331\n",
      "\n",
      "    accuracy                         0.9990     15878\n",
      "   macro avg     0.9822    0.9936    0.9878     15878\n",
      "weighted avg     0.9990    0.9990    0.9990     15878\n",
      "\n",
      "[47] Label Model\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9997    0.9992    0.9995     15547\n",
      "           1     0.9646    0.9879    0.9761       331\n",
      "\n",
      "    accuracy                         0.9990     15878\n",
      "   macro avg     0.9822    0.9936    0.9878     15878\n",
      "weighted avg     0.9990    0.9990    0.9990     15878\n",
      "\n",
      "[48] Label Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9997    0.9992    0.9995     15547\n",
      "           1     0.9646    0.9879    0.9761       331\n",
      "\n",
      "    accuracy                         0.9990     15878\n",
      "   macro avg     0.9822    0.9936    0.9878     15878\n",
      "weighted avg     0.9990    0.9990    0.9990     15878\n",
      "\n",
      "[49] Label Model\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9997    0.9992    0.9995     15547\n",
      "           1     0.9646    0.9879    0.9761       331\n",
      "\n",
      "    accuracy                         0.9990     15878\n",
      "   macro avg     0.9822    0.9936    0.9878     15878\n",
      "weighted avg     0.9990    0.9990    0.9990     15878\n",
      "\n",
      "Save the best overall model, configuration and partition for this experiment level\n"
     ]
    }
   ],
   "source": [
    "# CandGen Version v3\n",
    "\n",
    "predicted_s = train_plus(train_s_candidates, test_s_ebm_candidates, test_s_ebm_corr_candidates, Y_s, 's', paramgrid = param_grid, mode = 'pred')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "05079643",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparamater Search Space: 336\n",
      "Grid search over 50 configs\n",
      "[0] Label Model\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000        12\n",
      "           1     0.9644    0.9939    0.9789       327\n",
      "\n",
      "    accuracy                         0.9587       339\n",
      "   macro avg     0.4822    0.4969    0.4895       339\n",
      "weighted avg     0.9303    0.9587    0.9443       339\n",
      "\n",
      "[1] Label Model\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000        12\n",
      "           1     0.9644    0.9939    0.9789       327\n",
      "\n",
      "    accuracy                         0.9587       339\n",
      "   macro avg     0.4822    0.4969    0.4895       339\n",
      "weighted avg     0.9303    0.9587    0.9443       339\n",
      "\n",
      "[2] Label Model\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000        12\n",
      "           1     0.9646    1.0000    0.9820       327\n",
      "\n",
      "    accuracy                         0.9646       339\n",
      "   macro avg     0.4823    0.5000    0.4910       339\n",
      "weighted avg     0.9305    0.9646    0.9472       339\n",
      "\n",
      "[3] Label Model\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000        12\n",
      "           1     0.9646    1.0000    0.9820       327\n",
      "\n",
      "    accuracy                         0.9646       339\n",
      "   macro avg     0.4823    0.5000    0.4910       339\n",
      "weighted avg     0.9305    0.9646    0.9472       339\n",
      "\n",
      "[4] Label Model\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000        12\n",
      "           1     0.9644    0.9939    0.9789       327\n",
      "\n",
      "    accuracy                         0.9587       339\n",
      "   macro avg     0.4822    0.4969    0.4895       339\n",
      "weighted avg     0.9303    0.9587    0.9443       339\n",
      "\n",
      "[5] Label Model\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000        12\n",
      "           1     0.9644    0.9939    0.9789       327\n",
      "\n",
      "    accuracy                         0.9587       339\n",
      "   macro avg     0.4822    0.4969    0.4895       339\n",
      "weighted avg     0.9303    0.9587    0.9443       339\n",
      "\n",
      "[6] Label Model\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000        12\n",
      "           1     0.9646    1.0000    0.9820       327\n",
      "\n",
      "    accuracy                         0.9646       339\n",
      "   macro avg     0.4823    0.5000    0.4910       339\n",
      "weighted avg     0.9305    0.9646    0.9472       339\n",
      "\n",
      "[7] Label Model\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000        12\n",
      "           1     0.9646    1.0000    0.9820       327\n",
      "\n",
      "    accuracy                         0.9646       339\n",
      "   macro avg     0.4823    0.5000    0.4910       339\n",
      "weighted avg     0.9305    0.9646    0.9472       339\n",
      "\n",
      "[8] Label Model\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000        12\n",
      "           1     0.9644    0.9939    0.9789       327\n",
      "\n",
      "    accuracy                         0.9587       339\n",
      "   macro avg     0.4822    0.4969    0.4895       339\n",
      "weighted avg     0.9303    0.9587    0.9443       339\n",
      "\n",
      "[9] Label Model\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000        12\n",
      "           1     0.9646    1.0000    0.9820       327\n",
      "\n",
      "    accuracy                         0.9646       339\n",
      "   macro avg     0.4823    0.5000    0.4910       339\n",
      "weighted avg     0.9305    0.9646    0.9472       339\n",
      "\n",
      "[10] Label Model\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000        12\n",
      "           1     0.9646    1.0000    0.9820       327\n",
      "\n",
      "    accuracy                         0.9646       339\n",
      "   macro avg     0.4823    0.5000    0.4910       339\n",
      "weighted avg     0.9305    0.9646    0.9472       339\n",
      "\n",
      "[11] Label Model\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000        12\n",
      "           1     0.9644    0.9939    0.9789       327\n",
      "\n",
      "    accuracy                         0.9587       339\n",
      "   macro avg     0.4822    0.4969    0.4895       339\n",
      "weighted avg     0.9303    0.9587    0.9443       339\n",
      "\n",
      "[12] Label Model\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000        12\n",
      "           1     0.9644    0.9939    0.9789       327\n",
      "\n",
      "    accuracy                         0.9587       339\n",
      "   macro avg     0.4822    0.4969    0.4895       339\n",
      "weighted avg     0.9303    0.9587    0.9443       339\n",
      "\n",
      "[13] Label Model\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000        12\n",
      "           1     0.9644    0.9939    0.9789       327\n",
      "\n",
      "    accuracy                         0.9587       339\n",
      "   macro avg     0.4822    0.4969    0.4895       339\n",
      "weighted avg     0.9303    0.9587    0.9443       339\n",
      "\n",
      "[14] Label Model\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000        12\n",
      "           1     0.9646    1.0000    0.9820       327\n",
      "\n",
      "    accuracy                         0.9646       339\n",
      "   macro avg     0.4823    0.5000    0.4910       339\n",
      "weighted avg     0.9305    0.9646    0.9472       339\n",
      "\n",
      "[15] Label Model\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000        12\n",
      "           1     0.9644    0.9939    0.9789       327\n",
      "\n",
      "    accuracy                         0.9587       339\n",
      "   macro avg     0.4822    0.4969    0.4895       339\n",
      "weighted avg     0.9303    0.9587    0.9443       339\n",
      "\n",
      "[16] Label Model\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000        12\n",
      "           1     0.9646    1.0000    0.9820       327\n",
      "\n",
      "    accuracy                         0.9646       339\n",
      "   macro avg     0.4823    0.5000    0.4910       339\n",
      "weighted avg     0.9305    0.9646    0.9472       339\n",
      "\n",
      "[17] Label Model\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000        12\n",
      "           1     0.9646    1.0000    0.9820       327\n",
      "\n",
      "    accuracy                         0.9646       339\n",
      "   macro avg     0.4823    0.5000    0.4910       339\n",
      "weighted avg     0.9305    0.9646    0.9472       339\n",
      "\n",
      "[18] Label Model\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000        12\n",
      "           1     0.9644    0.9939    0.9789       327\n",
      "\n",
      "    accuracy                         0.9587       339\n",
      "   macro avg     0.4822    0.4969    0.4895       339\n",
      "weighted avg     0.9303    0.9587    0.9443       339\n",
      "\n",
      "[19] Label Model\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000        12\n",
      "           1     0.9644    0.9939    0.9789       327\n",
      "\n",
      "    accuracy                         0.9587       339\n",
      "   macro avg     0.4822    0.4969    0.4895       339\n",
      "weighted avg     0.9303    0.9587    0.9443       339\n",
      "\n",
      "[20] Label Model\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000        12\n",
      "           1     0.9644    0.9939    0.9789       327\n",
      "\n",
      "    accuracy                         0.9587       339\n",
      "   macro avg     0.4822    0.4969    0.4895       339\n",
      "weighted avg     0.9303    0.9587    0.9443       339\n",
      "\n",
      "[21] Label Model\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000        12\n",
      "           1     0.9644    0.9939    0.9789       327\n",
      "\n",
      "    accuracy                         0.9587       339\n",
      "   macro avg     0.4822    0.4969    0.4895       339\n",
      "weighted avg     0.9303    0.9587    0.9443       339\n",
      "\n",
      "[22] Label Model\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000        12\n",
      "           1     0.9646    1.0000    0.9820       327\n",
      "\n",
      "    accuracy                         0.9646       339\n",
      "   macro avg     0.4823    0.5000    0.4910       339\n",
      "weighted avg     0.9305    0.9646    0.9472       339\n",
      "\n",
      "[23] Label Model\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000        12\n",
      "           1     0.9644    0.9939    0.9789       327\n",
      "\n",
      "    accuracy                         0.9587       339\n",
      "   macro avg     0.4822    0.4969    0.4895       339\n",
      "weighted avg     0.9303    0.9587    0.9443       339\n",
      "\n",
      "[24] Label Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000        12\n",
      "           1     0.9646    1.0000    0.9820       327\n",
      "\n",
      "    accuracy                         0.9646       339\n",
      "   macro avg     0.4823    0.5000    0.4910       339\n",
      "weighted avg     0.9305    0.9646    0.9472       339\n",
      "\n",
      "[25] Label Model\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000        12\n",
      "           1     0.9646    1.0000    0.9820       327\n",
      "\n",
      "    accuracy                         0.9646       339\n",
      "   macro avg     0.4823    0.5000    0.4910       339\n",
      "weighted avg     0.9305    0.9646    0.9472       339\n",
      "\n",
      "[26] Label Model\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000        12\n",
      "           1     0.9646    1.0000    0.9820       327\n",
      "\n",
      "    accuracy                         0.9646       339\n",
      "   macro avg     0.4823    0.5000    0.4910       339\n",
      "weighted avg     0.9305    0.9646    0.9472       339\n",
      "\n",
      "[27] Label Model\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000        12\n",
      "           1     0.9644    0.9939    0.9789       327\n",
      "\n",
      "    accuracy                         0.9587       339\n",
      "   macro avg     0.4822    0.4969    0.4895       339\n",
      "weighted avg     0.9303    0.9587    0.9443       339\n",
      "\n",
      "[28] Label Model\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000        12\n",
      "           1     0.9646    1.0000    0.9820       327\n",
      "\n",
      "    accuracy                         0.9646       339\n",
      "   macro avg     0.4823    0.5000    0.4910       339\n",
      "weighted avg     0.9305    0.9646    0.9472       339\n",
      "\n",
      "[29] Label Model\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000        12\n",
      "           1     0.9646    1.0000    0.9820       327\n",
      "\n",
      "    accuracy                         0.9646       339\n",
      "   macro avg     0.4823    0.5000    0.4910       339\n",
      "weighted avg     0.9305    0.9646    0.9472       339\n",
      "\n",
      "[30] Label Model\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000        12\n",
      "           1     0.9646    1.0000    0.9820       327\n",
      "\n",
      "    accuracy                         0.9646       339\n",
      "   macro avg     0.4823    0.5000    0.4910       339\n",
      "weighted avg     0.9305    0.9646    0.9472       339\n",
      "\n",
      "[31] Label Model\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000        12\n",
      "           1     0.9646    1.0000    0.9820       327\n",
      "\n",
      "    accuracy                         0.9646       339\n",
      "   macro avg     0.4823    0.5000    0.4910       339\n",
      "weighted avg     0.9305    0.9646    0.9472       339\n",
      "\n",
      "[32] Label Model\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000        12\n",
      "           1     0.9646    1.0000    0.9820       327\n",
      "\n",
      "    accuracy                         0.9646       339\n",
      "   macro avg     0.4823    0.5000    0.4910       339\n",
      "weighted avg     0.9305    0.9646    0.9472       339\n",
      "\n",
      "[33] Label Model\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000        12\n",
      "           1     0.9646    1.0000    0.9820       327\n",
      "\n",
      "    accuracy                         0.9646       339\n",
      "   macro avg     0.4823    0.5000    0.4910       339\n",
      "weighted avg     0.9305    0.9646    0.9472       339\n",
      "\n",
      "[34] Label Model\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000        12\n",
      "           1     0.9646    1.0000    0.9820       327\n",
      "\n",
      "    accuracy                         0.9646       339\n",
      "   macro avg     0.4823    0.5000    0.4910       339\n",
      "weighted avg     0.9305    0.9646    0.9472       339\n",
      "\n",
      "[35] Label Model\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000        12\n",
      "           1     0.9646    1.0000    0.9820       327\n",
      "\n",
      "    accuracy                         0.9646       339\n",
      "   macro avg     0.4823    0.5000    0.4910       339\n",
      "weighted avg     0.9305    0.9646    0.9472       339\n",
      "\n",
      "[36] Label Model\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000        12\n",
      "           1     0.9644    0.9939    0.9789       327\n",
      "\n",
      "    accuracy                         0.9587       339\n",
      "   macro avg     0.4822    0.4969    0.4895       339\n",
      "weighted avg     0.9303    0.9587    0.9443       339\n",
      "\n",
      "[37] Label Model\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000        12\n",
      "           1     0.9646    1.0000    0.9820       327\n",
      "\n",
      "    accuracy                         0.9646       339\n",
      "   macro avg     0.4823    0.5000    0.4910       339\n",
      "weighted avg     0.9305    0.9646    0.9472       339\n",
      "\n",
      "[38] Label Model\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000        12\n",
      "           1     0.9644    0.9939    0.9789       327\n",
      "\n",
      "    accuracy                         0.9587       339\n",
      "   macro avg     0.4822    0.4969    0.4895       339\n",
      "weighted avg     0.9303    0.9587    0.9443       339\n",
      "\n",
      "[39] Label Model\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000        12\n",
      "           1     0.9644    0.9939    0.9789       327\n",
      "\n",
      "    accuracy                         0.9587       339\n",
      "   macro avg     0.4822    0.4969    0.4895       339\n",
      "weighted avg     0.9303    0.9587    0.9443       339\n",
      "\n",
      "[40] Label Model\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000        12\n",
      "           1     0.9644    0.9939    0.9789       327\n",
      "\n",
      "    accuracy                         0.9587       339\n",
      "   macro avg     0.4822    0.4969    0.4895       339\n",
      "weighted avg     0.9303    0.9587    0.9443       339\n",
      "\n",
      "[41] Label Model\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000        12\n",
      "           1     0.9646    1.0000    0.9820       327\n",
      "\n",
      "    accuracy                         0.9646       339\n",
      "   macro avg     0.4823    0.5000    0.4910       339\n",
      "weighted avg     0.9305    0.9646    0.9472       339\n",
      "\n",
      "[42] Label Model\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000        12\n",
      "           1     0.9644    0.9939    0.9789       327\n",
      "\n",
      "    accuracy                         0.9587       339\n",
      "   macro avg     0.4822    0.4969    0.4895       339\n",
      "weighted avg     0.9303    0.9587    0.9443       339\n",
      "\n",
      "[43] Label Model\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000        12\n",
      "           1     0.9646    1.0000    0.9820       327\n",
      "\n",
      "    accuracy                         0.9646       339\n",
      "   macro avg     0.4823    0.5000    0.4910       339\n",
      "weighted avg     0.9305    0.9646    0.9472       339\n",
      "\n",
      "[44] Label Model\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000        12\n",
      "           1     0.9646    1.0000    0.9820       327\n",
      "\n",
      "    accuracy                         0.9646       339\n",
      "   macro avg     0.4823    0.5000    0.4910       339\n",
      "weighted avg     0.9305    0.9646    0.9472       339\n",
      "\n",
      "[45] Label Model\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000        12\n",
      "           1     0.9646    1.0000    0.9820       327\n",
      "\n",
      "    accuracy                         0.9646       339\n",
      "   macro avg     0.4823    0.5000    0.4910       339\n",
      "weighted avg     0.9305    0.9646    0.9472       339\n",
      "\n",
      "[46] Label Model\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000        12\n",
      "           1     0.9644    0.9939    0.9789       327\n",
      "\n",
      "    accuracy                         0.9587       339\n",
      "   macro avg     0.4822    0.4969    0.4895       339\n",
      "weighted avg     0.9303    0.9587    0.9443       339\n",
      "\n",
      "[47] Label Model\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000        12\n",
      "           1     0.9646    1.0000    0.9820       327\n",
      "\n",
      "    accuracy                         0.9646       339\n",
      "   macro avg     0.4823    0.5000    0.4910       339\n",
      "weighted avg     0.9305    0.9646    0.9472       339\n",
      "\n",
      "[48] Label Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000        12\n",
      "           1     0.9646    1.0000    0.9820       327\n",
      "\n",
      "    accuracy                         0.9646       339\n",
      "   macro avg     0.4823    0.5000    0.4910       339\n",
      "weighted avg     0.9305    0.9646    0.9472       339\n",
      "\n",
      "[49] Label Model\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000        12\n",
      "           1     0.9644    0.9939    0.9789       327\n",
      "\n",
      "    accuracy                         0.9587       339\n",
      "   macro avg     0.4822    0.4969    0.4895       339\n",
      "weighted avg     0.9303    0.9587    0.9443       339\n",
      "\n",
      "Save the best overall model, configuration and partition for this experiment level\n"
     ]
    }
   ],
   "source": [
    "# CandGen Version v4\n",
    "\n",
    "predicted_s = train_plus(train_s_candidates, test_s_ebm_candidates, test_s_ebm_corr_candidates, Y_s, 's', paramgrid = param_grid, mode = 'pred')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a260d6ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3768fb79",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

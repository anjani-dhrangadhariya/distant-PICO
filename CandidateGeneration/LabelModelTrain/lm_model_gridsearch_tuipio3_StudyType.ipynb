{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "6b3b4e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import enum\n",
    "import glob\n",
    "import os\n",
    "from hashlib import new\n",
    "from pathlib import Path\n",
    "import time\n",
    "from itertools import product\n",
    "\n",
    "import functools\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "#from snorkel.labeling.model import LabelModel\n",
    "from snorkel.labeling.model import LabelModel as LMsnorkel\n",
    "from snorkel.labeling import PandasLFApplier\n",
    "\n",
    "from snorkel.labeling.model import MajorityLabelVoter\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import itertools\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "8562a8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "candgen_version = 'v4' # version = {v3, v4, ...}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "0cd54fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import json\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "7798c0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.exceptions import UndefinedMetricWarning\n",
    "\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "5d1d2219",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list2Nested(l, nested_length):\n",
    "    return [l[i:i+nested_length] for i in range(0, len(l), nested_length)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "id": "daaad8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1:1 positive to positive\n",
    "# -1:0 negative cand_gen to negative in label model\n",
    "# 0:-1 Abstain cand_gen to abstain in label model\n",
    "\n",
    "# In study type, abstain is actually a negative instance \n",
    "#labelModel_mapper_LF = {1:1, 0:0, -1:-1}\n",
    "labelModel_mapper_LF = {1:1, -1:0, 0:-1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "0638a0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import LMutils\n",
    "\n",
    "train_file = f'/mnt/nas2/results/Results/systematicReview/distant_pico/EBM_PICO_GT/{candgen_version}/gt/train_ebm_labels_tui_pio3.tsv'\n",
    "training_data = pd.read_csv(train_file, sep='\\t', header=0)\n",
    "\n",
    "ebm_test_file = f'/mnt/nas2/results/Results/systematicReview/distant_pico/EBM_PICO_GT/{candgen_version}/gt/test_ebm_labels_tui_pio3.tsv'\n",
    "test_ebm_data = pd.read_csv(ebm_test_file, sep='\\t', header=0)\n",
    "test_ebm_data.rename( columns={'Unnamed: 0':'series'}, inplace=True )\n",
    "\n",
    "physio_test_file = f'/mnt/nas2/results/Results/systematicReview/distant_pico/EBM_PICO_GT/{candgen_version}/gt/test_physio_labels_tui_pio3.tsv'\n",
    "test_physio_data = pd.read_csv(physio_test_file, sep='\\t', header=0)\n",
    "test_physio_data.rename( columns={'Unnamed: 0':'series'}, inplace=True )\n",
    "\n",
    "ebm_test_corrected_file = f'/mnt/nas2/results/Results/systematicReview/distant_pico/EBM_PICO_GT/{candgen_version}/gt/test_ebm_correctedlabels_tui_pio3.tsv'\n",
    "test_ebm_corrected_data = pd.read_csv(ebm_test_corrected_file, sep='\\t', header=0)\n",
    "test_ebm_corrected_data.rename( columns={'Unnamed: 0':'series'}, inplace=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "fff28521",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_df(df):\n",
    "\n",
    "    df_series = [ index for index, value in df.tokens.items() for word in ast.literal_eval(value) ]\n",
    "    df_tokens = [ word for index, value in df.tokens.items() for word in ast.literal_eval(value) ]\n",
    "    df_pos = [ word for index, value in df.pos.items() for word in ast.literal_eval(value) ]\n",
    "    df_offsets = [ word for index, value in df.offsets.items() for word in ast.literal_eval(value) ]\n",
    "\n",
    "\n",
    "    df_p = [ int(lab) for index, value in df.p.items() for lab in ast.literal_eval(value) ]\n",
    "    df_p_fine = [ int(lab) for index, value in df.p_f.items() for lab in ast.literal_eval(value) ]\n",
    "    df_i = [ int(lab) for index, value in df.i.items() for lab in ast.literal_eval(value) ]\n",
    "    df_i_fine = [ int(lab) for index, value in df.i_f.items() for lab in ast.literal_eval(value) ]\n",
    "    df_o = [ int(lab) for index, value in df.o.items() for lab in ast.literal_eval(value) ]\n",
    "    df_o_fine = [ int(lab) for index, value in df.o_f.items() for lab in ast.literal_eval(value) ]\n",
    "    df_s = [ int(lab) for index, value in df.s.items() for lab in ast.literal_eval(value) ]\n",
    "    df_s_fine = [ int(lab) for index, value in df.s_f.items() for lab in ast.literal_eval(value) ]\n",
    "    \n",
    "    df_flattened = pd.DataFrame({ 'series': df_series,\n",
    "                        'tokens' : df_tokens,\n",
    "                        'offsets': df_offsets,\n",
    "                        'pos': df_pos,\n",
    "                        'p' : df_p,\n",
    "                        'i' : df_i,\n",
    "                        'o' : df_o,\n",
    "                        's' : df_s,\n",
    "                        'p_f' : df_p_fine,\n",
    "                        'i_f' : df_i_fine,\n",
    "                        'o_f' : df_o_fine,\n",
    "                        's_f' : df_s_fine})\n",
    "    \n",
    "    return df_flattened"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "4b8e07f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten the dataframes (currently only the training dataframe and test ebm dataframe with corrected labels can be flattened)\n",
    "data_df = flatten_df(training_data)\n",
    "test_ebm_data = flatten_df(test_ebm_data)\n",
    "test_ebm_corr_df = flatten_df(test_ebm_corrected_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "f0c041c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "series = [\n",
    "    data_df.series.to_numpy() ,\n",
    "    test_ebm_data.series.to_numpy() ,\n",
    "    test_physio_data.series.to_numpy(),   \n",
    "    test_ebm_corr_df.series.to_numpy()\n",
    "]\n",
    "\n",
    "\n",
    "sents = [\n",
    "    data_df.tokens.to_numpy() ,\n",
    "    test_ebm_data.tokens.to_numpy() ,\n",
    "    test_physio_data.tokens.to_numpy(),   \n",
    "    test_ebm_corr_df.tokens.to_numpy()    \n",
    "]\n",
    "\n",
    "\n",
    "part_of_speech = [\n",
    "    data_df.pos.to_numpy() ,\n",
    "    test_ebm_data.pos.to_numpy() ,\n",
    "    test_physio_data.pos.to_numpy(),   \n",
    "    test_ebm_corr_df.pos.to_numpy()     \n",
    "]\n",
    "\n",
    "\n",
    "offsets = [\n",
    "    data_df.offsets.to_numpy() ,\n",
    "    test_ebm_data.offsets.to_numpy() ,\n",
    "    test_physio_data.offsets.to_numpy(),   \n",
    "    test_ebm_corr_df.offsets.to_numpy() \n",
    "]\n",
    "\n",
    "\n",
    "Y_p = [\n",
    "    data_df.p.to_numpy() , # 0 -7\n",
    "    data_df.p_f.to_numpy() , # 1 -6\n",
    "    test_ebm_data.p.to_numpy() , # 2 -5\n",
    "    test_ebm_data.p_f.to_numpy() , # 3 -4\n",
    "    test_physio_data.p.to_numpy(),  # 4 -3\n",
    "    test_ebm_corr_df.p.to_numpy(),   # 5 -2\n",
    "    test_ebm_corr_df.p_f.to_numpy() # 6 -1\n",
    "]\n",
    "\n",
    "\n",
    "Y_i = [\n",
    "    data_df.i.to_numpy() , # 0 -7\n",
    "    data_df.i_f.to_numpy() , # 1 -6\n",
    "    test_ebm_data.i.to_numpy() , # 2 -5\n",
    "    test_ebm_data.i_f.to_numpy() , # 3 -4\n",
    "    test_physio_data.i.to_numpy(),  # 4 -3\n",
    "    test_ebm_corr_df.i.to_numpy(),   # 5 -2\n",
    "    test_ebm_corr_df.i_f.to_numpy() # 6 -1\n",
    "]\n",
    "\n",
    "\n",
    "Y_o = [\n",
    "    data_df.o.to_numpy() , # 0 -7\n",
    "    data_df.o_f.to_numpy() , # 1 -6\n",
    "    test_ebm_data.o.to_numpy() , # 2 -5\n",
    "    test_ebm_data.o_f.to_numpy() , # 3 -4\n",
    "    test_physio_data.o.to_numpy(),  # 4 -3\n",
    "    test_ebm_corr_df.o.to_numpy(),   # 5 -2\n",
    "    test_ebm_corr_df.o_f.to_numpy() # 6 -1\n",
    "]\n",
    "\n",
    "Y_s = [\n",
    "    data_df.s.to_numpy() , # 0 -7\n",
    "    data_df.s_f.to_numpy() , # 1 -6\n",
    "    test_ebm_data.s.to_numpy() , # 2 -5\n",
    "    test_ebm_data.s_f.to_numpy() , # 3 -4\n",
    "    test_physio_data.s.to_numpy(),  # 4 -3\n",
    "    test_ebm_corr_df.s.to_numpy(),   # 5 -2\n",
    "    test_ebm_corr_df.s_f.to_numpy() # 6 -1\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "fd0f16cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write data for error analysis\n",
    "\n",
    "error_analysis_ebm_p = pd.DataFrame({'tokens' : test_ebm_data.tokens,\n",
    "                                'participant' : test_ebm_data.p,\n",
    "                                'participant_fine' : test_ebm_data.p_f }, \n",
    "                                columns=['tokens','participant', 'participant_fine'])\n",
    "\n",
    "#error_analysis_ebm_p.to_csv (r'/mnt/nas2/results/Results/systematicReview/distant_pico/EBM_PICO_GT/error_analysis/test_ebmgold_p', index = None, header=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "id": "c4c4068d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write data for error analysis\n",
    "\n",
    "error_analysis_ebmcorr_p = pd.DataFrame({'tokens' : test_ebm_corr_df.tokens,\n",
    "                                'participant' : test_ebm_corr_df.p,\n",
    "                                'participant_fine' : test_ebm_corr_df.p_f }, \n",
    "                                columns=['tokens','participant', 'participant_fine'])\n",
    "\n",
    "#error_analysis_ebmcorr_p.to_csv (r'/mnt/nas2/results/Results/systematicReview/distant_pico/EBM_PICO_GT/error_analysis/test_ebmgoldcorr_p', index = None, header=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "0c7fe1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_list(data_column):\n",
    "    return [ word for index, value in data_column.items() for word in ast.literal_eval(value) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "35850d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_array(data_column):\n",
    "    return np.array( [ word for index, value in data_column.items() for word in ast.literal_eval(value) ] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "id": "a9f6e149",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_to_array(label_column):\n",
    "    return np.array( [ labelModel_mapper_LF[int(lab)] for index, value in label_column.items() for k, lab in ast.literal_eval(value).items() ] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "id": "b873406f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lfs(indir):\n",
    "    \n",
    "    pathlist = Path(indir).glob('**/*.tsv')\n",
    "\n",
    "    tokens = ''\n",
    "\n",
    "    lfs = dict()\n",
    "    lfs_lm = dict()\n",
    "\n",
    "    for counter, file in enumerate(pathlist):\n",
    "        \n",
    "        if '/S/' in str(file):\n",
    "\n",
    "            k = str( file ).split(f'/{candgen_version}/')[-1].replace('.tsv', '').replace('/', '_')\n",
    "            mypath = Path(file)\n",
    "            if mypath.stat().st_size != 0:\n",
    "                data = pd.read_csv(file, sep='\\t', header=0)\n",
    "\n",
    "                data_tokens = data.tokens\n",
    "                if len(tokens) < 5:\n",
    "                    tokens = df_to_array(data_tokens)\n",
    "\n",
    "                data_labels = data.labels\n",
    "                #print(data_labels[1:2])\n",
    "                labels = dict_to_array(data_labels)\n",
    "                #print(labels)\n",
    "                if len(labels) != len(tokens):\n",
    "                    print(k, len(labels) , len(tokens) )\n",
    "                #assert len(labels) == len(tokens)\n",
    "                lfs[k] = labels\n",
    "\n",
    "\n",
    "    print( 'Total number of tokens in validation set: ', len(tokens) )\n",
    "    print( 'Total number of LFs in the dictionary', len(lfs) )\n",
    "    \n",
    "    return lfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "id": "a1119c42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of tokens in validation set:  1303169\n",
      "Total number of LFs in the dictionary 32\n"
     ]
    }
   ],
   "source": [
    "indir = f'/mnt/nas2/results/Results/systematicReview/distant_pico/training_ebm_candidate_generation/{candgen_version}'\n",
    "train_ebm_lfs = get_lfs(indir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "id": "456a19e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of tokens in validation set:  52582\n",
      "Total number of LFs in the dictionary 32\n"
     ]
    }
   ],
   "source": [
    "indir_test_ebm_corr = f'/mnt/nas2/results/Results/systematicReview/distant_pico/test_ebm_anjani_candidate_generation/{candgen_version}'\n",
    "test_ebm_corr_lfs = get_lfs(indir_test_ebm_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "id": "58ac9849",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of tokens in validation set:  51784\n",
      "Total number of LFs in the dictionary 32\n"
     ]
    }
   ],
   "source": [
    "indir_test_ebm = f'/mnt/nas2/results/Results/systematicReview/distant_pico/test_ebm_candidate_generation/{candgen_version}'\n",
    "test_ebm_lfs = get_lfs(indir_test_ebm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "id": "1d01d849",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop some lfs\n",
    "def drop_nopositive(lfs_d):\n",
    "    \n",
    "    dropped_conditions = dict()\n",
    "\n",
    "    for k, v in lfs_d.items():\n",
    "        \n",
    "        dropped_conditions[k] = v\n",
    "        '''\n",
    "        if '_cto' not in str(k) and '_s_heurpattern_labels_2' not in str(k):\n",
    "            dropped_conditions[k] = v\n",
    "        else:\n",
    "            pass\n",
    "        '''\n",
    "            \n",
    "    return dropped_conditions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "id": "203e10e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ebm_lfs_dropped = drop_nopositive(train_ebm_lfs)\n",
    "test_ebm_corr_lfs_dropped = drop_nopositive(test_ebm_corr_lfs)\n",
    "test_ebm_lfs_dropped = drop_nopositive(test_ebm_lfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "id": "5149c931",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['dictionary_fuzzy_S_lf_dict_s_type', 'dictionary_fuzzy_S_lf_dict_s_comp_type', 'dictionary_fuzzy_S_lf_dict_s_type_negs', 'dictionary_fuzzy_S_lf_dict_s_comp_type_negs', 'dictionary_direct_S_lf_dict_s_type', 'dictionary_direct_S_lf_dict_s_comp_type', 'dictionary_direct_S_lf_dict_s_type_negs', 'dictionary_direct_S_lf_dict_s_comp_type_negs', 'nonUMLS_fuzzy_S_lf_s_cto', 'nonUMLS_fuzzy_S_lf_s_cto_syn', 'nonUMLS_direct_S_lf_s_cto', 'nonUMLS_direct_S_lf_s_cto_syn', 'heuristics_direct_S_lf_lf_lf_s_heurpattern_labels', 'heuristics_direct_S_lf_regex_stdtype', 'heuristics_direct_S_lf_regex_phase_negs', 'heuristics_direct_S_lf_regex_stdtype_negs', 'heuristics_direct_S_lf_dict_s_abb_negs', 'heuristics_direct_S_lf_regex_stdtype_types_negs', 'heuristics_direct_S_lf_regex_stdtype_basic_negs', 'heuristics_direct_S_lf_regex_stdtype_proc', 'heuristics_direct_S_lf_regex_phase', 'heuristics_direct_S_lf_regex_placebo_negs', 'heuristics_direct_S_lf_regex_stdtype_types', 'heuristics_direct_S_lf_regex_stdtype_basic', 'heuristics_direct_S_lf_regex_placebo', 'heuristics_direct_S_lf_regex_stdtype_proc_negs', 'heuristics_direct_S_lf_regex_blinding_negs', 'heuristics_direct_S_lf_regex_stdtype_basicplus_negs', 'heuristics_direct_S_lf_lf_lf_s_heurpattern_labels_2', 'heuristics_direct_S_lf_regex_blinding', 'heuristics_direct_S_lf_regex_stdtype_basicplus', 'heuristics_direct_S_lf_dict_s_abb'])"
      ]
     },
     "execution_count": 417,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ebm_lfs_dropped.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "id": "001d73ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lf_levels(umls_d:dict, pattern:str, picos:str):\n",
    "\n",
    "    umls_level = dict()\n",
    "\n",
    "    for key, value in umls_d.items():   # iter on both keys and values\n",
    "        search_pattern = pattern + picos\n",
    "        if key.startswith(search_pattern):\n",
    "            k = str(key).split('_')[-1]\n",
    "            umls_level[ k ] = value\n",
    "\n",
    "    return umls_level\n",
    "\n",
    "\n",
    "# Level 1: UMLS\n",
    "umls_p = [\n",
    "    lf_levels(train_ebm_lfs_dropped, name, 'P') \n",
    "    for i, name in enumerate(['UMLS_direct_', 'UMLS_fuzzy_'])\n",
    "]\n",
    "\n",
    "umls_p_testcorrected = [\n",
    "    lf_levels(test_ebm_corr_lfs_dropped, name, 'P') \n",
    "    for i, name in enumerate(['UMLS_direct_', 'UMLS_fuzzy_'])\n",
    "]\n",
    "\n",
    "umls_p_testebm = [\n",
    "    lf_levels(test_ebm_lfs_dropped, name, 'P') \n",
    "    for i, name in enumerate(['UMLS_direct_', 'UMLS_fuzzy_'])\n",
    "]\n",
    "\n",
    "# ------------------------------------------------------------------------\n",
    "\n",
    "umls_i = [\n",
    "    lf_levels(train_ebm_lfs_dropped, name, 'I') \n",
    "    for i, name in enumerate(['UMLS_direct_', 'UMLS_fuzzy_'])\n",
    "]\n",
    "\n",
    "umls_i_testcorrected = [\n",
    "    lf_levels(test_ebm_corr_lfs_dropped, name, 'I') \n",
    "    for i, name in enumerate(['UMLS_direct_', 'UMLS_fuzzy_'])\n",
    "]\n",
    "\n",
    "umls_i_testebm = [\n",
    "    lf_levels(test_ebm_lfs_dropped, name, 'I') \n",
    "    for i, name in enumerate(['UMLS_direct_', 'UMLS_fuzzy_'])\n",
    "]\n",
    "\n",
    "# ------------------------------------------------------------------------\n",
    "\n",
    "umls_o = [\n",
    "    lf_levels(train_ebm_lfs_dropped, name, 'O') \n",
    "    for i, name in enumerate(['UMLS_direct_', 'UMLS_fuzzy_'])\n",
    "]\n",
    "\n",
    "umls_o_testcorrected = [\n",
    "    lf_levels(test_ebm_corr_lfs_dropped, name, 'O') \n",
    "    for i, name in enumerate(['UMLS_direct_', 'UMLS_fuzzy_'])\n",
    "]\n",
    "\n",
    "umls_o_testebm = [\n",
    "    lf_levels(test_ebm_lfs_dropped, name, 'O') \n",
    "    for i, name in enumerate(['UMLS_direct_', 'UMLS_fuzzy_'])\n",
    "]\n",
    "\n",
    "# ------------------------------------------------------------------------\n",
    "# ------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "# Level 2: non UMLS\n",
    "nonumls_p = [\n",
    "    lf_levels(train_ebm_lfs_dropped, name, 'P') \n",
    "    for i, name in enumerate(['nonUMLS_direct_', 'nonUMLS_fuzzy_'])\n",
    "]\n",
    "\n",
    "nonumls_p_testcorrected = [\n",
    "    lf_levels(test_ebm_corr_lfs_dropped, name, 'P') \n",
    "    for i, name in enumerate(['nonUMLS_direct_', 'nonUMLS_fuzzy_'])\n",
    "]\n",
    "\n",
    "nonumls_p_testebm = [\n",
    "    lf_levels(test_ebm_lfs_dropped, name, 'P') \n",
    "    for i, name in enumerate(['nonUMLS_direct_', 'nonUMLS_fuzzy_'])\n",
    "]\n",
    "\n",
    "# ------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "nonumls_i = [\n",
    "    lf_levels(train_ebm_lfs_dropped, name, 'I') \n",
    "    for i, name in enumerate(['nonUMLS_direct_', 'nonUMLS_fuzzy_'])\n",
    "]\n",
    "\n",
    "nonumls_i_testcorrected = [\n",
    "    lf_levels(test_ebm_corr_lfs_dropped, name, 'I') \n",
    "    for i, name in enumerate(['nonUMLS_direct_', 'nonUMLS_fuzzy_'])\n",
    "]\n",
    "\n",
    "nonumls_i_testebm = [\n",
    "    lf_levels(test_ebm_lfs_dropped, name, 'I') \n",
    "    for i, name in enumerate(['nonUMLS_direct_', 'nonUMLS_fuzzy_'])\n",
    "]\n",
    "\n",
    "# ------------------------------------------------------------------------\n",
    "\n",
    "nonumls_o = [\n",
    "    lf_levels(train_ebm_lfs_dropped, name, 'O') \n",
    "    for i, name in enumerate(['nonUMLS_direct_', 'nonUMLS_fuzzy_'])\n",
    "]\n",
    "\n",
    "nonumls_o_testcorrected = [\n",
    "    lf_levels(test_ebm_corr_lfs_dropped, name, 'O') \n",
    "    for i, name in enumerate(['nonUMLS_direct_', 'nonUMLS_fuzzy_'])\n",
    "]\n",
    "\n",
    "nonumls_o_testebm = [\n",
    "    lf_levels(test_ebm_lfs_dropped, name, 'O') \n",
    "    for i, name in enumerate(['nonUMLS_direct_', 'nonUMLS_fuzzy_'])\n",
    "]\n",
    "\n",
    "# ------------------------------------------------------------------------\n",
    "\n",
    "nonumls_s = [\n",
    "    lf_levels(train_ebm_lfs_dropped, name, 'S') \n",
    "    for i, name in enumerate(['nonUMLS_direct_', 'nonUMLS_fuzzy_'])\n",
    "]\n",
    "\n",
    "nonumls_s_testcorrected = [\n",
    "    lf_levels(test_ebm_corr_lfs_dropped, name, 'S') \n",
    "    for i, name in enumerate(['nonUMLS_direct_', 'nonUMLS_fuzzy_'])\n",
    "]\n",
    "\n",
    "nonumls_s_testebm = [\n",
    "    lf_levels(test_ebm_lfs_dropped, name, 'S') \n",
    "    for i, name in enumerate(['nonUMLS_direct_', 'nonUMLS_fuzzy_'])\n",
    "]\n",
    "\n",
    "# ------------------------------------------------------------------------\n",
    "# ------------------------------------------------------------------------\n",
    "\n",
    "# Level 3: DS\n",
    "ds_p = [\n",
    "    lf_levels(train_ebm_lfs_dropped, name, 'P') \n",
    "    for i, name in enumerate(['ds_direct_', 'ds_fuzzy_'])\n",
    "]\n",
    "\n",
    "ds_p_testcorrected = [\n",
    "    lf_levels(test_ebm_corr_lfs_dropped, name, 'P') \n",
    "    for i, name in enumerate(['ds_direct_', 'ds_fuzzy_'])\n",
    "]\n",
    "\n",
    "ds_p_testebm = [\n",
    "    lf_levels(test_ebm_lfs_dropped, name, 'P') \n",
    "    for i, name in enumerate(['ds_direct_', 'ds_fuzzy_'])\n",
    "]\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------------\n",
    "\n",
    "ds_i = [\n",
    "    lf_levels(train_ebm_lfs_dropped, name, 'I') \n",
    "    for i, name in enumerate(['ds_direct_', 'ds_fuzzy_'])\n",
    "]\n",
    "\n",
    "ds_i_testcorrected = [\n",
    "    lf_levels(test_ebm_corr_lfs_dropped, name, 'I') \n",
    "    for i, name in enumerate(['ds_direct_', 'ds_fuzzy_'])\n",
    "]\n",
    "\n",
    "ds_i_testebm = [\n",
    "    lf_levels(test_ebm_lfs_dropped, name, 'I') \n",
    "    for i, name in enumerate(['ds_direct_', 'ds_fuzzy_'])\n",
    "]\n",
    "\n",
    "# ------------------------------------------------------------------------\n",
    "\n",
    "ds_o = [\n",
    "    lf_levels(train_ebm_lfs_dropped, name, 'O') \n",
    "    for i, name in enumerate(['ds_direct_', 'ds_fuzzy_'])\n",
    "]\n",
    "\n",
    "ds_o_testcorrected = [\n",
    "    lf_levels(test_ebm_corr_lfs_dropped, name, 'O') \n",
    "    for i, name in enumerate(['ds_direct_', 'ds_fuzzy_'])\n",
    "]\n",
    "\n",
    "ds_o_testebm = [\n",
    "    lf_levels(test_ebm_lfs_dropped, name, 'O') \n",
    "    for i, name in enumerate(['ds_direct_', 'ds_fuzzy_'])\n",
    "]\n",
    "\n",
    "# ------------------------------------------------------------------------\n",
    "# ------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "# Level 4: dictionary, rules, heuristics\n",
    "heur_p = [\n",
    "    lf_levels(train_ebm_lfs_dropped, name, 'P') \n",
    "    for i, name in enumerate(['heuristics_direct_'])\n",
    "]\n",
    "\n",
    "heur_p_testcorrected = [\n",
    "    lf_levels(test_ebm_corr_lfs_dropped, name, 'P') \n",
    "    for i, name in enumerate(['heuristics_direct_'])\n",
    "]\n",
    "\n",
    "heur_p_testebm = [\n",
    "    lf_levels(test_ebm_lfs_dropped, name, 'P') \n",
    "    for i, name in enumerate(['heuristics_direct_'])\n",
    "]\n",
    "\n",
    "# ------------------------------------------------------------------------\n",
    "\n",
    "heur_i = [\n",
    "    lf_levels(train_ebm_lfs_dropped, name, 'I') \n",
    "    for i, name in enumerate(['heuristics_direct_'])\n",
    "]\n",
    "\n",
    "heur_i_testcorrected = [\n",
    "    lf_levels(test_ebm_corr_lfs_dropped, name, 'I') \n",
    "    for i, name in enumerate(['heuristics_direct_'])\n",
    "]\n",
    "\n",
    "heur_i_testebm = [\n",
    "    lf_levels(test_ebm_lfs_dropped, name, 'I') \n",
    "    for i, name in enumerate(['heuristics_direct_'])\n",
    "]\n",
    "\n",
    "# ------------------------------------------------------------------------\n",
    "\n",
    "heur_o = [\n",
    "    lf_levels(train_ebm_lfs_dropped, name, 'O') \n",
    "    for i, name in enumerate(['heuristics_direct_'])\n",
    "]\n",
    "\n",
    "heur_o_testcorrected = [\n",
    "    lf_levels(test_ebm_corr_lfs_dropped, name, 'O') \n",
    "    for i, name in enumerate(['heuristics_direct_'])\n",
    "]\n",
    "\n",
    "\n",
    "heur_o_testebm = [\n",
    "    lf_levels(test_ebm_lfs_dropped, name, 'O') \n",
    "    for i, name in enumerate(['heuristics_direct_'])\n",
    "]\n",
    "\n",
    "# ------------------------------------------------------------------------\n",
    "\n",
    "heur_s = [\n",
    "    lf_levels(train_ebm_lfs_dropped, name, 'S') \n",
    "    for i, name in enumerate(['heuristics_direct_'])\n",
    "]\n",
    "\n",
    "heur_s_testcorrected = [\n",
    "    lf_levels(test_ebm_corr_lfs_dropped, name, 'S') \n",
    "    for i, name in enumerate(['heuristics_direct_'])\n",
    "]\n",
    "\n",
    "\n",
    "heur_s_testebm = [\n",
    "    lf_levels(test_ebm_lfs_dropped, name, 'S') \n",
    "    for i, name in enumerate(['heuristics_direct_'])\n",
    "]\n",
    "\n",
    "# ------------------------------------------------------------------------\n",
    "# ------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "dict_p = [\n",
    "    lf_levels(train_ebm_lfs_dropped, name, 'P') \n",
    "    for i, name in enumerate(['dictionary_direct_', 'dictionary_fuzzy_'])\n",
    "]\n",
    "\n",
    "dict_p_testcorrected = [\n",
    "    lf_levels(test_ebm_corr_lfs_dropped, name, 'P') \n",
    "    for i, name in enumerate(['dictionary_direct_', 'dictionary_fuzzy_'])\n",
    "]\n",
    "\n",
    "dict_p_testebm = [\n",
    "    lf_levels(test_ebm_lfs_dropped, name, 'P') \n",
    "    for i, name in enumerate(['dictionary_direct_', 'dictionary_fuzzy_'])\n",
    "]\n",
    "\n",
    "# ------------------------------------------------------------------------\n",
    "\n",
    "dict_i = [\n",
    "    lf_levels(train_ebm_lfs_dropped, name, 'I') \n",
    "    for i, name in enumerate(['dictionary_direct_', 'dictionary_fuzzy_'])\n",
    "]\n",
    "\n",
    "dict_i_testcorrected = [\n",
    "    lf_levels(test_ebm_corr_lfs_dropped, name, 'I') \n",
    "    for i, name in enumerate(['dictionary_direct_', 'dictionary_fuzzy_'])\n",
    "]\n",
    "\n",
    "dict_i_testebm = [\n",
    "    lf_levels(test_ebm_lfs_dropped, name, 'I') \n",
    "    for i, name in enumerate(['dictionary_direct_', 'dictionary_fuzzy_'])\n",
    "]\n",
    "\n",
    "# ------------------------------------------------------------------------\n",
    "\n",
    "dict_o = [\n",
    "    lf_levels(train_ebm_lfs_dropped, name, 'O') \n",
    "    for i, name in enumerate(['dictionary_direct_', 'dictionary_fuzzy_'])\n",
    "]\n",
    "\n",
    "dict_o_testcorrected = [\n",
    "    lf_levels(test_ebm_corr_lfs_dropped, name, 'O') \n",
    "    for i, name in enumerate(['dictionary_direct_', 'dictionary_fuzzy_'])\n",
    "]\n",
    "\n",
    "dict_o_testebm = [\n",
    "    lf_levels(test_ebm_lfs_dropped, name, 'O') \n",
    "    for i, name in enumerate(['dictionary_direct_', 'dictionary_fuzzy_'])\n",
    "]\n",
    "\n",
    "# ------------------------------------------------------------------------\n",
    "\n",
    "dict_s = [\n",
    "    lf_levels(train_ebm_lfs_dropped, name, 'S') \n",
    "    for i, name in enumerate(['dictionary_direct_', 'dictionary_fuzzy_'])\n",
    "]\n",
    "\n",
    "dict_s_testcorrected = [\n",
    "    lf_levels(test_ebm_corr_lfs_dropped, name, 'S') \n",
    "    for i, name in enumerate(['dictionary_direct_', 'dictionary_fuzzy_'])\n",
    "]\n",
    "\n",
    "dict_s_testebm = [\n",
    "    lf_levels(test_ebm_lfs_dropped, name, 'S') \n",
    "    for i, name in enumerate(['dictionary_direct_', 'dictionary_fuzzy_'])\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "id": "cdb4ad6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Study Type data\n",
    "\n",
    "#train_s_candidates = [nonumls_s[1], dict_s[1], heur_s[0]]\n",
    "#test_s_ebm_corr_candidates = [nonumls_s_testcorrected[1], dict_s_testcorrected[1], heur_s_testcorrected[0]]\n",
    "#test_s_ebm_candidates = [nonumls_s_testebm[1], dict_s_testebm[1], heur_s_testebm[0]]\n",
    "\n",
    "\n",
    "train_s_candidates = [dict_s[1], heur_s[0]]\n",
    "test_s_ebm_corr_candidates = [dict_s_testcorrected[1], heur_s_testcorrected[0]]\n",
    "test_s_ebm_candidates = [dict_s_testebm[1], heur_s_testebm[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "id": "2c6e5471",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'lr': [0.001, 0.0001],\n",
    "    'l2': [0.001, 0.0001],\n",
    "    'n_epochs': [50, 100, 200, 600, 700, 1000, 2000, 5000],\n",
    "    'prec_init': [0.6, 0.7, 0.8, 0.9],\n",
    "    'optimizer': [\"adamax\", \"adam\", \"sgd\"],\n",
    "    'lr_scheduler': ['constant'],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "id": "3d083955",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_param_grid(param_grid, seed):\n",
    "    \"\"\" Sample parameter grid\n",
    "    :param param_grid:\n",
    "    :param seed:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    rstate = np.random.get_state()\n",
    "    np.random.seed(seed)\n",
    "    params = list(product(*[param_grid[name] for name in param_grid]))\n",
    "    np.random.shuffle(params)\n",
    "    np.random.set_state(rstate)\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "id": "602295fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search(model_class,\n",
    "                model_class_init,\n",
    "                param_grid,\n",
    "                train=None,\n",
    "                dev=None,\n",
    "                other_train=None,\n",
    "                n_model_search=5,\n",
    "                val_metric='f1_macro',\n",
    "                seed=1234,\n",
    "                checkpoint_gt_mv=False,\n",
    "                tag_fmt_ckpnt='IO'):\n",
    "    \n",
    "    \n",
    "    \"\"\"Simple grid search helper function\n",
    "    Parameters\n",
    "    ----------\n",
    "    model_class\n",
    "    model_class_init\n",
    "    param_grid\n",
    "    train\n",
    "    dev\n",
    "    n_model_search\n",
    "    val_metric\n",
    "    seed\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    \"\"\"\n",
    "    \n",
    "    L_train, Y_train = train\n",
    "    L_dev, Y_dev = dev\n",
    "\n",
    "    # sample configs\n",
    "    params = sample_param_grid(param_grid, seed)[:n_model_search]\n",
    "\n",
    "    defaults = {'seed': seed}\n",
    "    best_score, best_config = 0.0, None\n",
    "    print(f\"Grid search over {len(params)} configs\")\n",
    "\n",
    "    for i, config in enumerate(params):\n",
    "        print(f'[{i}] Label Model')\n",
    "        config = dict(zip(param_grid.keys(), config))\n",
    "        config.update({param: value for param, value in defaults.items() if param not in config})\n",
    "\n",
    "        model = model_class(**model_class_init)\n",
    "        model.fit(L_train, Y_dev, **config)\n",
    "        \n",
    "        y_pred = model.predict(L_dev)\n",
    "        \n",
    "                \n",
    "        if -1 in y_pred:\n",
    "            print(\"Label model predicted -1 (TODO: this happens inconsistently)\")\n",
    "            continue\n",
    "    \n",
    "    \n",
    "    return model, best_config, best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "id": "192e9fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_plus(cands, best_model, gt_labels, mode=None):\n",
    "    \n",
    "    combined_lf = []\n",
    "    combined_lf.extend( list(cands[0].values()) ) # Combine with level 4\n",
    "    combined_lf.extend( list(cands[1].values()) ) # combine with level 4\n",
    "\n",
    "\n",
    "    L = np.array( combined_lf )\n",
    "    L = np.transpose(L)\n",
    "    \n",
    "    if mode == 'only_pred':\n",
    "    \n",
    "        predictions_probablities = best_model.predict_proba(L)\n",
    "        predictions = best_model.predict(L , tie_break_policy = \"abstain\")\n",
    "    \n",
    "        return predictions_probablities\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        counter = 0\n",
    "        \n",
    "        predictions_probablities = best_model.predict_proba(L)\n",
    "        predictions = best_model.predict(L , tie_break_policy = \"abstain\")\n",
    "    \n",
    "        groundtruth = np.array(gt_labels) \n",
    "\n",
    "        #groundtruth = [-1 if x == 0 else x for x in gt_labels] # XXX if \"test_ebm_correct\"\n",
    "        groundtruth = np.array(groundtruth)\n",
    "\n",
    "        groundtruth_ = []\n",
    "        predictions_ = []\n",
    "        for g, p in zip(groundtruth, np.array(predictions)):\n",
    "            #print( g, p )\n",
    "            if p == -1:\n",
    "                counter = counter + 1\n",
    "                pass\n",
    "                #print( 'model predicts -1 inconsistently.' )\n",
    "            else:\n",
    "                groundtruth_.append(g)\n",
    "                predictions_.append(p)\n",
    "\n",
    "        \n",
    "        print('Total number of tokens missed: ' , counter  )\n",
    "\n",
    "\n",
    "        cr = classification_report( groundtruth_, predictions_, digits=4, output_dict=True )\n",
    "        cr_ = classification_report( groundtruth_, predictions_, digits=4 )\n",
    "        print( cr_ )\n",
    "    \n",
    "        return predictions_probablities, cr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "id": "5b0f2f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for entities that do not have UMLS partitions\n",
    "\n",
    "def train_plus(train_cands, test_cands, test_corr_cands, Y_d, picos, paramgrid, mode):\n",
    "   \n",
    "    gold_labels = ''\n",
    "    gold_labels_fine = ''\n",
    "    \n",
    "    \n",
    "    model_class_init = {\n",
    "        'cardinality': 2, \n",
    "        'verbose': True\n",
    "    }\n",
    "\n",
    "    num_hyperparams = functools.reduce(lambda x,y:x*y, [len(x) for x in param_grid.values()])\n",
    "    print(\"Hyperparamater Search Space:\", num_hyperparams)\n",
    "    n_model_search = 50\n",
    "    \n",
    "\n",
    "    '''#########################################################################\n",
    "    # Choosing the number of LF's from UMLS all\n",
    "    #########################################################################'''\n",
    "\n",
    "\n",
    "    best_f1_macro = 0.0\n",
    "    best_overall_model = ''\n",
    "    best_overall_config = ''\n",
    "\n",
    "    combined_lf = []\n",
    "    combined_lf.extend( list(train_cands[0].values()) ) \n",
    "    combined_lf.extend( list(train_cands[1].values()) )\n",
    "    \n",
    "    L = np.array( combined_lf )\n",
    "    L = np.transpose(L)\n",
    "\n",
    "    # sample configs\n",
    "    params = sample_param_grid(param_grid, 0)[:n_model_search]\n",
    "    defaults = {'seed': 0}\n",
    "    print(f\"Grid search over {len(params)} configs\")\n",
    "\n",
    "    for i, config in enumerate(params):\n",
    "        print(f'[{i}] Label Model')\n",
    "        config = dict(zip(param_grid.keys(), config))\n",
    "        config.update({param: value for param, value in defaults.items() if param not in config})\n",
    "\n",
    "        #label_model = LabelModel(cardinality=2, verbose=True)\n",
    "        #label_model.fit(L_train=L, **config)\n",
    "        \n",
    "        label_model = LMsnorkel(**model_class_init)\n",
    "        label_model.fit(L, **config)\n",
    "\n",
    "        # Predict on the test ebm correct set\n",
    "        preds, class_report = test_corr_probas = predict_plus(test_corr_cands, label_model, Y_d[-2]) # test ebm correct   \n",
    "        \n",
    "        if class_report['macro avg']['f1-score'] > best_f1_macro:\n",
    "            best_f1_macro = class_report['macro avg']['f1-score']\n",
    "            best_overall_model = label_model\n",
    "            best_overall_config = config\n",
    "            \n",
    "    # Save the best label model\n",
    "    print('Save the best overall model, configuration and partition for this experiment level')\n",
    "    # Save your model or results\n",
    "    save_dir = f'/mnt/nas2/results/Results/systematicReview/distant_pico/models/LabelModels/{picos}/'\n",
    "    filename = 'stpartition_' + '_epoch_' + str(best_overall_config['n_epochs'])\n",
    "    joblib.dump(best_overall_model, f'{save_dir}/{filename}.pkl') \n",
    "    joblib.dump(best_overall_config, f'{save_dir}/{filename}.json')\n",
    "    \n",
    "    \n",
    "    #load your model for further usage\n",
    "    loaded_best_model = joblib.load(f'{save_dir}/{filename}.pkl')\n",
    "    \n",
    "    # Predict on the training set\n",
    "    train_probas = predict_plus(train_cands,loaded_best_model, Y_d[-6], mode= 'only_pred') # train \n",
    "    \n",
    "    # Write training predictions to file\n",
    "    # tokens\tpos\toffsets\tlabels\ttrue_labels\n",
    "    #print( train_probas.shape )\n",
    "    train_probas = train_probas.tolist()\n",
    "    #print( len(train_probas) )\n",
    "    #train_probas = [list(tp) for tp in train_probas]\n",
    "    #train_probas_series = pd.Series(list(train_probas))\n",
    "    train_probas_series = pd.Series(train_probas)\n",
    "    data_df['labels'] = train_probas_series.values\n",
    "\n",
    "    # Write predictions on the training data to the file\n",
    "    \n",
    "    write_df = data_df.groupby(['series'])[['series', 'tokens', 'pos', 'offsets', 'labels', str(picos), str(picos)+'_f']].agg(list)\n",
    "    write_file_path = f'/mnt/nas2/results/Results/systematicReview/distant_pico/predictions/LabelModels/{picos}/{filename}_bestmodel.tsv'\n",
    "    write_df.to_csv (write_file_path, index = None, sep = '\\t', header=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "id": "ab02a98c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparamater Search Space: 384\n",
      "Grid search over 50 configs\n",
      "[0] Label Model\n",
      "Total number of tokens missed:  25110\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9695    0.9923    0.9807     26258\n",
      "           1     0.6600    0.3245    0.4351      1214\n",
      "\n",
      "    accuracy                         0.9628     27472\n",
      "   macro avg     0.8147    0.6584    0.7079     27472\n",
      "weighted avg     0.9558    0.9628    0.9566     27472\n",
      "\n",
      "[1] Label Model\n",
      "Total number of tokens missed:  25110\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9726    0.9914    0.9819     26258\n",
      "           1     0.6813    0.3962    0.5010      1214\n",
      "\n",
      "    accuracy                         0.9651     27472\n",
      "   macro avg     0.8270    0.6938    0.7415     27472\n",
      "weighted avg     0.9597    0.9651    0.9607     27472\n",
      "\n",
      "[2] Label Model\n",
      "Total number of tokens missed:  25110\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9690    0.9923    0.9805     26258\n",
      "           1     0.6535    0.3138    0.4240      1214\n",
      "\n",
      "    accuracy                         0.9623     27472\n",
      "   macro avg     0.8113    0.6531    0.7023     27472\n",
      "weighted avg     0.9551    0.9623    0.9559     27472\n",
      "\n",
      "[3] Label Model\n",
      "Total number of tokens missed:  25110\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9726    0.9914    0.9819     26258\n",
      "           1     0.6813    0.3962    0.5010      1214\n",
      "\n",
      "    accuracy                         0.9651     27472\n",
      "   macro avg     0.8270    0.6938    0.7415     27472\n",
      "weighted avg     0.9597    0.9651    0.9607     27472\n",
      "\n",
      "[4] Label Model\n",
      "Total number of tokens missed:  25110\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9698    0.9920    0.9808     26258\n",
      "           1     0.6591    0.3328    0.4423      1214\n",
      "\n",
      "    accuracy                         0.9629     27472\n",
      "   macro avg     0.8144    0.6624    0.7115     27472\n",
      "weighted avg     0.9561    0.9629    0.9570     27472\n",
      "\n",
      "[5] Label Model\n",
      "Total number of tokens missed:  25110\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9688    0.9920    0.9803     26258\n",
      "           1     0.6415    0.3081    0.4162      1214\n",
      "\n",
      "    accuracy                         0.9618     27472\n",
      "   macro avg     0.8051    0.6501    0.6983     27472\n",
      "weighted avg     0.9543    0.9618    0.9553     27472\n",
      "\n",
      "[6] Label Model\n",
      "Total number of tokens missed:  25110\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9695    0.9923    0.9807     26258\n",
      "           1     0.6600    0.3245    0.4351      1214\n",
      "\n",
      "    accuracy                         0.9628     27472\n",
      "   macro avg     0.8147    0.6584    0.7079     27472\n",
      "weighted avg     0.9558    0.9628    0.9566     27472\n",
      "\n",
      "[7] Label Model\n",
      "Total number of tokens missed:  25110\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9690    0.9923    0.9805     26258\n",
      "           1     0.6535    0.3138    0.4240      1214\n",
      "\n",
      "    accuracy                         0.9623     27472\n",
      "   macro avg     0.8113    0.6531    0.7023     27472\n",
      "weighted avg     0.9551    0.9623    0.9559     27472\n",
      "\n",
      "[8] Label Model\n",
      "Total number of tokens missed:  25110\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9690    0.9923    0.9805     26258\n",
      "           1     0.6535    0.3138    0.4240      1214\n",
      "\n",
      "    accuracy                         0.9623     27472\n",
      "   macro avg     0.8113    0.6531    0.7023     27472\n",
      "weighted avg     0.9551    0.9623    0.9559     27472\n",
      "\n",
      "[9] Label Model\n",
      "Total number of tokens missed:  25110\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9695    0.9923    0.9807     26258\n",
      "           1     0.6594    0.3237    0.4343      1214\n",
      "\n",
      "    accuracy                         0.9627     27472\n",
      "   macro avg     0.8144    0.6580    0.7075     27472\n",
      "weighted avg     0.9558    0.9627    0.9566     27472\n",
      "\n",
      "[10] Label Model\n",
      "Total number of tokens missed:  25110\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9690    0.9923    0.9805     26258\n",
      "           1     0.6535    0.3138    0.4240      1214\n",
      "\n",
      "    accuracy                         0.9623     27472\n",
      "   macro avg     0.8113    0.6531    0.7023     27472\n",
      "weighted avg     0.9551    0.9623    0.9559     27472\n",
      "\n",
      "[11] Label Model\n",
      "Total number of tokens missed:  25110\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9690    0.9923    0.9805     26258\n",
      "           1     0.6535    0.3138    0.4240      1214\n",
      "\n",
      "    accuracy                         0.9623     27472\n",
      "   macro avg     0.8113    0.6531    0.7023     27472\n",
      "weighted avg     0.9551    0.9623    0.9559     27472\n",
      "\n",
      "[12] Label Model\n",
      "Total number of tokens missed:  25110\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9695    0.9923    0.9807     26258\n",
      "           1     0.6600    0.3245    0.4351      1214\n",
      "\n",
      "    accuracy                         0.9628     27472\n",
      "   macro avg     0.8147    0.6584    0.7079     27472\n",
      "weighted avg     0.9558    0.9628    0.9566     27472\n",
      "\n",
      "[13] Label Model\n",
      "Total number of tokens missed:  25110\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9695    0.9923    0.9807     26258\n",
      "           1     0.6600    0.3245    0.4351      1214\n",
      "\n",
      "    accuracy                         0.9628     27472\n",
      "   macro avg     0.8147    0.6584    0.7079     27472\n",
      "weighted avg     0.9558    0.9628    0.9566     27472\n",
      "\n",
      "[14] Label Model\n",
      "Total number of tokens missed:  25110\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9690    0.9923    0.9805     26258\n",
      "           1     0.6535    0.3138    0.4240      1214\n",
      "\n",
      "    accuracy                         0.9623     27472\n",
      "   macro avg     0.8113    0.6531    0.7023     27472\n",
      "weighted avg     0.9551    0.9623    0.9559     27472\n",
      "\n",
      "[15] Label Model\n",
      "Total number of tokens missed:  25110\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9690    0.9923    0.9805     26258\n",
      "           1     0.6535    0.3138    0.4240      1214\n",
      "\n",
      "    accuracy                         0.9623     27472\n",
      "   macro avg     0.8113    0.6531    0.7023     27472\n",
      "weighted avg     0.9551    0.9623    0.9559     27472\n",
      "\n",
      "[16] Label Model\n",
      "Total number of tokens missed:  25110\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9726    0.9914    0.9819     26258\n",
      "           1     0.6813    0.3962    0.5010      1214\n",
      "\n",
      "    accuracy                         0.9651     27472\n",
      "   macro avg     0.8270    0.6938    0.7415     27472\n",
      "weighted avg     0.9597    0.9651    0.9607     27472\n",
      "\n",
      "[17] Label Model\n",
      "Total number of tokens missed:  25110\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9726    0.9914    0.9819     26258\n",
      "           1     0.6813    0.3962    0.5010      1214\n",
      "\n",
      "    accuracy                         0.9651     27472\n",
      "   macro avg     0.8270    0.6938    0.7415     27472\n",
      "weighted avg     0.9597    0.9651    0.9607     27472\n",
      "\n",
      "[18] Label Model\n",
      "Total number of tokens missed:  25110\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9688    0.9920    0.9803     26258\n",
      "           1     0.6415    0.3081    0.4162      1214\n",
      "\n",
      "    accuracy                         0.9618     27472\n",
      "   macro avg     0.8051    0.6501    0.6983     27472\n",
      "weighted avg     0.9543    0.9618    0.9553     27472\n",
      "\n",
      "[19] Label Model\n",
      "Total number of tokens missed:  25110\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9695    0.9923    0.9807     26258\n",
      "           1     0.6600    0.3245    0.4351      1214\n",
      "\n",
      "    accuracy                         0.9628     27472\n",
      "   macro avg     0.8147    0.6584    0.7079     27472\n",
      "weighted avg     0.9558    0.9628    0.9566     27472\n",
      "\n",
      "[20] Label Model\n",
      "Total number of tokens missed:  25110\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9684    0.9923    0.9802     26258\n",
      "           1     0.6420    0.2998    0.4088      1214\n",
      "\n",
      "    accuracy                         0.9617     27472\n",
      "   macro avg     0.8052    0.6461    0.6945     27472\n",
      "weighted avg     0.9540    0.9617    0.9549     27472\n",
      "\n",
      "[21] Label Model\n",
      "Total number of tokens missed:  25110\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9698    0.9920    0.9808     26258\n",
      "           1     0.6591    0.3328    0.4423      1214\n",
      "\n",
      "    accuracy                         0.9629     27472\n",
      "   macro avg     0.8144    0.6624    0.7115     27472\n",
      "weighted avg     0.9561    0.9629    0.9570     27472\n",
      "\n",
      "[22] Label Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of tokens missed:  25110\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9698    0.9920    0.9808     26258\n",
      "           1     0.6591    0.3328    0.4423      1214\n",
      "\n",
      "    accuracy                         0.9629     27472\n",
      "   macro avg     0.8144    0.6624    0.7115     27472\n",
      "weighted avg     0.9561    0.9629    0.9570     27472\n",
      "\n",
      "[23] Label Model\n",
      "Total number of tokens missed:  25110\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9690    0.9923    0.9805     26258\n",
      "           1     0.6535    0.3138    0.4240      1214\n",
      "\n",
      "    accuracy                         0.9623     27472\n",
      "   macro avg     0.8113    0.6531    0.7023     27472\n",
      "weighted avg     0.9551    0.9623    0.9559     27472\n",
      "\n",
      "[24] Label Model\n",
      "Total number of tokens missed:  25110\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9690    0.9923    0.9805     26258\n",
      "           1     0.6535    0.3138    0.4240      1214\n",
      "\n",
      "    accuracy                         0.9623     27472\n",
      "   macro avg     0.8113    0.6531    0.7023     27472\n",
      "weighted avg     0.9551    0.9623    0.9559     27472\n",
      "\n",
      "[25] Label Model\n",
      "Total number of tokens missed:  25110\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9698    0.9920    0.9808     26258\n",
      "           1     0.6591    0.3328    0.4423      1214\n",
      "\n",
      "    accuracy                         0.9629     27472\n",
      "   macro avg     0.8144    0.6624    0.7115     27472\n",
      "weighted avg     0.9561    0.9629    0.9570     27472\n",
      "\n",
      "[26] Label Model\n",
      "Total number of tokens missed:  25110\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9688    0.9920    0.9803     26258\n",
      "           1     0.6415    0.3081    0.4162      1214\n",
      "\n",
      "    accuracy                         0.9618     27472\n",
      "   macro avg     0.8051    0.6501    0.6983     27472\n",
      "weighted avg     0.9543    0.9618    0.9553     27472\n",
      "\n",
      "[27] Label Model\n",
      "Total number of tokens missed:  25110\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9695    0.9923    0.9807     26258\n",
      "           1     0.6600    0.3245    0.4351      1214\n",
      "\n",
      "    accuracy                         0.9628     27472\n",
      "   macro avg     0.8147    0.6584    0.7079     27472\n",
      "weighted avg     0.9558    0.9628    0.9566     27472\n",
      "\n",
      "[28] Label Model\n",
      "Total number of tokens missed:  25110\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9688    0.9923    0.9804     26258\n",
      "           1     0.6482    0.3081    0.4176      1214\n",
      "\n",
      "    accuracy                         0.9620     27472\n",
      "   macro avg     0.8085    0.6502    0.6990     27472\n",
      "weighted avg     0.9546    0.9620    0.9555     27472\n",
      "\n",
      "[29] Label Model\n",
      "Total number of tokens missed:  25110\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9726    0.9914    0.9819     26258\n",
      "           1     0.6813    0.3962    0.5010      1214\n",
      "\n",
      "    accuracy                         0.9651     27472\n",
      "   macro avg     0.8270    0.6938    0.7415     27472\n",
      "weighted avg     0.9597    0.9651    0.9607     27472\n",
      "\n",
      "[30] Label Model\n",
      "Total number of tokens missed:  25110\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9688    0.9923    0.9804     26258\n",
      "           1     0.6482    0.3081    0.4176      1214\n",
      "\n",
      "    accuracy                         0.9620     27472\n",
      "   macro avg     0.8085    0.6502    0.6990     27472\n",
      "weighted avg     0.9546    0.9620    0.9555     27472\n",
      "\n",
      "[31] Label Model\n",
      "Total number of tokens missed:  25110\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9695    0.9923    0.9807     26258\n",
      "           1     0.6600    0.3245    0.4351      1214\n",
      "\n",
      "    accuracy                         0.9628     27472\n",
      "   macro avg     0.8147    0.6584    0.7079     27472\n",
      "weighted avg     0.9558    0.9628    0.9566     27472\n",
      "\n",
      "[32] Label Model\n",
      "Total number of tokens missed:  25110\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9726    0.9914    0.9819     26258\n",
      "           1     0.6813    0.3962    0.5010      1214\n",
      "\n",
      "    accuracy                         0.9651     27472\n",
      "   macro avg     0.8270    0.6938    0.7415     27472\n",
      "weighted avg     0.9597    0.9651    0.9607     27472\n",
      "\n",
      "[33] Label Model\n",
      "Total number of tokens missed:  25110\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9688    0.9920    0.9803     26258\n",
      "           1     0.6415    0.3081    0.4162      1214\n",
      "\n",
      "    accuracy                         0.9618     27472\n",
      "   macro avg     0.8051    0.6501    0.6983     27472\n",
      "weighted avg     0.9543    0.9618    0.9553     27472\n",
      "\n",
      "[34] Label Model\n",
      "Total number of tokens missed:  25110\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9688    0.9920    0.9803     26258\n",
      "           1     0.6415    0.3081    0.4162      1214\n",
      "\n",
      "    accuracy                         0.9618     27472\n",
      "   macro avg     0.8051    0.6501    0.6983     27472\n",
      "weighted avg     0.9543    0.9618    0.9553     27472\n",
      "\n",
      "[35] Label Model\n",
      "Total number of tokens missed:  25110\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9693    0.9923    0.9807     26258\n",
      "           1     0.6588    0.3213    0.4319      1214\n",
      "\n",
      "    accuracy                         0.9627     27472\n",
      "   macro avg     0.8141    0.6568    0.7063     27472\n",
      "weighted avg     0.9556    0.9627    0.9564     27472\n",
      "\n",
      "[36] Label Model\n",
      "Total number of tokens missed:  25110\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9726    0.9914    0.9819     26258\n",
      "           1     0.6813    0.3962    0.5010      1214\n",
      "\n",
      "    accuracy                         0.9651     27472\n",
      "   macro avg     0.8270    0.6938    0.7415     27472\n",
      "weighted avg     0.9597    0.9651    0.9607     27472\n",
      "\n",
      "[37] Label Model\n",
      "Total number of tokens missed:  25110\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9688    0.9920    0.9803     26258\n",
      "           1     0.6415    0.3081    0.4162      1214\n",
      "\n",
      "    accuracy                         0.9618     27472\n",
      "   macro avg     0.8051    0.6501    0.6983     27472\n",
      "weighted avg     0.9543    0.9618    0.9553     27472\n",
      "\n",
      "[38] Label Model\n",
      "Total number of tokens missed:  25110\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9726    0.9914    0.9819     26258\n",
      "           1     0.6813    0.3962    0.5010      1214\n",
      "\n",
      "    accuracy                         0.9651     27472\n",
      "   macro avg     0.8270    0.6938    0.7415     27472\n",
      "weighted avg     0.9597    0.9651    0.9607     27472\n",
      "\n",
      "[39] Label Model\n",
      "Total number of tokens missed:  25110\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9726    0.9914    0.9819     26258\n",
      "           1     0.6813    0.3962    0.5010      1214\n",
      "\n",
      "    accuracy                         0.9651     27472\n",
      "   macro avg     0.8270    0.6938    0.7415     27472\n",
      "weighted avg     0.9597    0.9651    0.9607     27472\n",
      "\n",
      "[40] Label Model\n",
      "Total number of tokens missed:  25110\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9695    0.9923    0.9807     26258\n",
      "           1     0.6600    0.3245    0.4351      1214\n",
      "\n",
      "    accuracy                         0.9628     27472\n",
      "   macro avg     0.8147    0.6584    0.7079     27472\n",
      "weighted avg     0.9558    0.9628    0.9566     27472\n",
      "\n",
      "[41] Label Model\n",
      "Total number of tokens missed:  25110\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9726    0.9914    0.9819     26258\n",
      "           1     0.6813    0.3962    0.5010      1214\n",
      "\n",
      "    accuracy                         0.9651     27472\n",
      "   macro avg     0.8270    0.6938    0.7415     27472\n",
      "weighted avg     0.9597    0.9651    0.9607     27472\n",
      "\n",
      "[42] Label Model\n",
      "Total number of tokens missed:  25110\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9688    0.9920    0.9803     26258\n",
      "           1     0.6415    0.3081    0.4162      1214\n",
      "\n",
      "    accuracy                         0.9618     27472\n",
      "   macro avg     0.8051    0.6501    0.6983     27472\n",
      "weighted avg     0.9543    0.9618    0.9553     27472\n",
      "\n",
      "[43] Label Model\n",
      "Total number of tokens missed:  25110\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9690    0.9923    0.9805     26258\n",
      "           1     0.6535    0.3138    0.4240      1214\n",
      "\n",
      "    accuracy                         0.9623     27472\n",
      "   macro avg     0.8113    0.6531    0.7023     27472\n",
      "weighted avg     0.9551    0.9623    0.9559     27472\n",
      "\n",
      "[44] Label Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of tokens missed:  25110\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9690    0.9923    0.9805     26258\n",
      "           1     0.6535    0.3138    0.4240      1214\n",
      "\n",
      "    accuracy                         0.9623     27472\n",
      "   macro avg     0.8113    0.6531    0.7023     27472\n",
      "weighted avg     0.9551    0.9623    0.9559     27472\n",
      "\n",
      "[45] Label Model\n",
      "Total number of tokens missed:  25110\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9690    0.9923    0.9805     26258\n",
      "           1     0.6535    0.3138    0.4240      1214\n",
      "\n",
      "    accuracy                         0.9623     27472\n",
      "   macro avg     0.8113    0.6531    0.7023     27472\n",
      "weighted avg     0.9551    0.9623    0.9559     27472\n",
      "\n",
      "[46] Label Model\n",
      "Total number of tokens missed:  25110\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9690    0.9923    0.9805     26258\n",
      "           1     0.6535    0.3138    0.4240      1214\n",
      "\n",
      "    accuracy                         0.9623     27472\n",
      "   macro avg     0.8113    0.6531    0.7023     27472\n",
      "weighted avg     0.9551    0.9623    0.9559     27472\n",
      "\n",
      "[47] Label Model\n",
      "Total number of tokens missed:  25110\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9690    0.9923    0.9805     26258\n",
      "           1     0.6535    0.3138    0.4240      1214\n",
      "\n",
      "    accuracy                         0.9623     27472\n",
      "   macro avg     0.8113    0.6531    0.7023     27472\n",
      "weighted avg     0.9551    0.9623    0.9559     27472\n",
      "\n",
      "[48] Label Model\n",
      "Total number of tokens missed:  25110\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9726    0.9914    0.9819     26258\n",
      "           1     0.6813    0.3962    0.5010      1214\n",
      "\n",
      "    accuracy                         0.9651     27472\n",
      "   macro avg     0.8270    0.6938    0.7415     27472\n",
      "weighted avg     0.9597    0.9651    0.9607     27472\n",
      "\n",
      "[49] Label Model\n",
      "Total number of tokens missed:  25110\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9688    0.9920    0.9803     26258\n",
      "           1     0.6415    0.3081    0.4162      1214\n",
      "\n",
      "    accuracy                         0.9618     27472\n",
      "   macro avg     0.8051    0.6501    0.6983     27472\n",
      "weighted avg     0.9543    0.9618    0.9553     27472\n",
      "\n",
      "Save the best overall model, configuration and partition for this experiment level\n"
     ]
    }
   ],
   "source": [
    "# CandGen Version v4 all (with extra specified negatives - all UMLS, non-UMLS, dd, dicts, abbreviation NOT the ReGeX)\n",
    "\n",
    "predicted_s = train_plus(train_s_candidates, test_s_ebm_candidates, test_s_ebm_corr_candidates, Y_s, 's', paramgrid = param_grid, mode = 'pred')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "f00eebb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparamater Search Space: 384\n",
      "Grid search over 50 configs\n",
      "[0] Label Model\n",
      "Total number of tokens missed:  25110\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9698    0.9923    0.9809     26258\n",
      "           1     0.6656    0.3328    0.4437      1214\n",
      "\n",
      "    accuracy                         0.9631     27472\n",
      "   macro avg     0.8177    0.6625    0.7123     27472\n",
      "weighted avg     0.9564    0.9631    0.9572     27472\n",
      "\n",
      "[1] Label Model\n",
      "Total number of tokens missed:  25110\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9726    0.9914    0.9819     26258\n",
      "           1     0.6813    0.3962    0.5010      1214\n",
      "\n",
      "    accuracy                         0.9651     27472\n",
      "   macro avg     0.8270    0.6938    0.7415     27472\n",
      "weighted avg     0.9597    0.9651    0.9607     27472\n",
      "\n",
      "[2] Label Model\n",
      "Total number of tokens missed:  25110\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9690    0.9923    0.9805     26258\n",
      "           1     0.6535    0.3138    0.4240      1214\n",
      "\n",
      "    accuracy                         0.9623     27472\n",
      "   macro avg     0.8113    0.6531    0.7023     27472\n",
      "weighted avg     0.9551    0.9623    0.9559     27472\n",
      "\n",
      "[3] Label Model\n",
      "Total number of tokens missed:  25110\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9726    0.9914    0.9819     26258\n",
      "           1     0.6813    0.3962    0.5010      1214\n",
      "\n",
      "    accuracy                         0.9651     27472\n",
      "   macro avg     0.8270    0.6938    0.7415     27472\n",
      "weighted avg     0.9597    0.9651    0.9607     27472\n",
      "\n",
      "[4] Label Model\n",
      "Total number of tokens missed:  25110\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9698    0.9920    0.9808     26258\n",
      "           1     0.6591    0.3328    0.4423      1214\n",
      "\n",
      "    accuracy                         0.9629     27472\n",
      "   macro avg     0.8144    0.6624    0.7115     27472\n",
      "weighted avg     0.9561    0.9629    0.9570     27472\n",
      "\n",
      "[5] Label Model\n",
      "Total number of tokens missed:  25110\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9688    0.9920    0.9803     26258\n",
      "           1     0.6415    0.3081    0.4162      1214\n",
      "\n",
      "    accuracy                         0.9618     27472\n",
      "   macro avg     0.8051    0.6501    0.6983     27472\n",
      "weighted avg     0.9543    0.9618    0.9553     27472\n",
      "\n",
      "[6] Label Model\n",
      "Total number of tokens missed:  25110\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9695    0.9923    0.9807     26258\n",
      "           1     0.6600    0.3245    0.4351      1214\n",
      "\n",
      "    accuracy                         0.9628     27472\n",
      "   macro avg     0.8147    0.6584    0.7079     27472\n",
      "weighted avg     0.9558    0.9628    0.9566     27472\n",
      "\n",
      "[7] Label Model\n",
      "Total number of tokens missed:  25110\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9690    0.9923    0.9805     26258\n",
      "           1     0.6535    0.3138    0.4240      1214\n",
      "\n",
      "    accuracy                         0.9623     27472\n",
      "   macro avg     0.8113    0.6531    0.7023     27472\n",
      "weighted avg     0.9551    0.9623    0.9559     27472\n",
      "\n",
      "[8] Label Model\n",
      "Total number of tokens missed:  25110\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9690    0.9923    0.9805     26258\n",
      "           1     0.6535    0.3138    0.4240      1214\n",
      "\n",
      "    accuracy                         0.9623     27472\n",
      "   macro avg     0.8113    0.6531    0.7023     27472\n",
      "weighted avg     0.9551    0.9623    0.9559     27472\n",
      "\n",
      "[9] Label Model\n",
      "Total number of tokens missed:  25110\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9695    0.9923    0.9807     26258\n",
      "           1     0.6600    0.3245    0.4351      1214\n",
      "\n",
      "    accuracy                         0.9628     27472\n",
      "   macro avg     0.8147    0.6584    0.7079     27472\n",
      "weighted avg     0.9558    0.9628    0.9566     27472\n",
      "\n",
      "[10] Label Model\n",
      "Total number of tokens missed:  25110\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9690    0.9923    0.9805     26258\n",
      "           1     0.6535    0.3138    0.4240      1214\n",
      "\n",
      "    accuracy                         0.9623     27472\n",
      "   macro avg     0.8113    0.6531    0.7023     27472\n",
      "weighted avg     0.9551    0.9623    0.9559     27472\n",
      "\n",
      "[11] Label Model\n",
      "Total number of tokens missed:  25110\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9690    0.9923    0.9805     26258\n",
      "           1     0.6535    0.3138    0.4240      1214\n",
      "\n",
      "    accuracy                         0.9623     27472\n",
      "   macro avg     0.8113    0.6531    0.7023     27472\n",
      "weighted avg     0.9551    0.9623    0.9559     27472\n",
      "\n",
      "[12] Label Model\n",
      "Total number of tokens missed:  25110\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9695    0.9923    0.9807     26258\n",
      "           1     0.6600    0.3245    0.4351      1214\n",
      "\n",
      "    accuracy                         0.9628     27472\n",
      "   macro avg     0.8147    0.6584    0.7079     27472\n",
      "weighted avg     0.9558    0.9628    0.9566     27472\n",
      "\n",
      "[13] Label Model\n",
      "Total number of tokens missed:  25110\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9695    0.9923    0.9807     26258\n",
      "           1     0.6600    0.3245    0.4351      1214\n",
      "\n",
      "    accuracy                         0.9628     27472\n",
      "   macro avg     0.8147    0.6584    0.7079     27472\n",
      "weighted avg     0.9558    0.9628    0.9566     27472\n",
      "\n",
      "[14] Label Model\n",
      "Total number of tokens missed:  25110\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9690    0.9923    0.9805     26258\n",
      "           1     0.6535    0.3138    0.4240      1214\n",
      "\n",
      "    accuracy                         0.9623     27472\n",
      "   macro avg     0.8113    0.6531    0.7023     27472\n",
      "weighted avg     0.9551    0.9623    0.9559     27472\n",
      "\n",
      "[15] Label Model\n",
      "Total number of tokens missed:  25110\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9690    0.9923    0.9805     26258\n",
      "           1     0.6535    0.3138    0.4240      1214\n",
      "\n",
      "    accuracy                         0.9623     27472\n",
      "   macro avg     0.8113    0.6531    0.7023     27472\n",
      "weighted avg     0.9551    0.9623    0.9559     27472\n",
      "\n",
      "[16] Label Model\n",
      "Total number of tokens missed:  25110\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9726    0.9914    0.9819     26258\n",
      "           1     0.6813    0.3962    0.5010      1214\n",
      "\n",
      "    accuracy                         0.9651     27472\n",
      "   macro avg     0.8270    0.6938    0.7415     27472\n",
      "weighted avg     0.9597    0.9651    0.9607     27472\n",
      "\n",
      "[17] Label Model\n",
      "Total number of tokens missed:  25110\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9726    0.9914    0.9819     26258\n",
      "           1     0.6813    0.3962    0.5010      1214\n",
      "\n",
      "    accuracy                         0.9651     27472\n",
      "   macro avg     0.8270    0.6938    0.7415     27472\n",
      "weighted avg     0.9597    0.9651    0.9607     27472\n",
      "\n",
      "[18] Label Model\n",
      "Total number of tokens missed:  25110\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9688    0.9920    0.9803     26258\n",
      "           1     0.6415    0.3081    0.4162      1214\n",
      "\n",
      "    accuracy                         0.9618     27472\n",
      "   macro avg     0.8051    0.6501    0.6983     27472\n",
      "weighted avg     0.9543    0.9618    0.9553     27472\n",
      "\n",
      "[19] Label Model\n",
      "Total number of tokens missed:  25110\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9695    0.9923    0.9807     26258\n",
      "           1     0.6600    0.3245    0.4351      1214\n",
      "\n",
      "    accuracy                         0.9628     27472\n",
      "   macro avg     0.8147    0.6584    0.7079     27472\n",
      "weighted avg     0.9558    0.9628    0.9566     27472\n",
      "\n",
      "[20] Label Model\n",
      "Total number of tokens missed:  25110\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9688    0.9923    0.9804     26258\n",
      "           1     0.6482    0.3081    0.4176      1214\n",
      "\n",
      "    accuracy                         0.9620     27472\n",
      "   macro avg     0.8085    0.6502    0.6990     27472\n",
      "weighted avg     0.9546    0.9620    0.9555     27472\n",
      "\n",
      "[21] Label Model\n",
      "Total number of tokens missed:  25110\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9698    0.9920    0.9808     26258\n",
      "           1     0.6591    0.3328    0.4423      1214\n",
      "\n",
      "    accuracy                         0.9629     27472\n",
      "   macro avg     0.8144    0.6624    0.7115     27472\n",
      "weighted avg     0.9561    0.9629    0.9570     27472\n",
      "\n",
      "[22] Label Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of tokens missed:  25110\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9698    0.9920    0.9808     26258\n",
      "           1     0.6591    0.3328    0.4423      1214\n",
      "\n",
      "    accuracy                         0.9629     27472\n",
      "   macro avg     0.8144    0.6624    0.7115     27472\n",
      "weighted avg     0.9561    0.9629    0.9570     27472\n",
      "\n",
      "[23] Label Model\n",
      "Total number of tokens missed:  25110\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9690    0.9923    0.9805     26258\n",
      "           1     0.6535    0.3138    0.4240      1214\n",
      "\n",
      "    accuracy                         0.9623     27472\n",
      "   macro avg     0.8113    0.6531    0.7023     27472\n",
      "weighted avg     0.9551    0.9623    0.9559     27472\n",
      "\n",
      "[24] Label Model\n",
      "Total number of tokens missed:  25110\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9690    0.9923    0.9805     26258\n",
      "           1     0.6535    0.3138    0.4240      1214\n",
      "\n",
      "    accuracy                         0.9623     27472\n",
      "   macro avg     0.8113    0.6531    0.7023     27472\n",
      "weighted avg     0.9551    0.9623    0.9559     27472\n",
      "\n",
      "[25] Label Model\n",
      "Total number of tokens missed:  25110\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9698    0.9920    0.9808     26258\n",
      "           1     0.6591    0.3328    0.4423      1214\n",
      "\n",
      "    accuracy                         0.9629     27472\n",
      "   macro avg     0.8144    0.6624    0.7115     27472\n",
      "weighted avg     0.9561    0.9629    0.9570     27472\n",
      "\n",
      "[26] Label Model\n",
      "Total number of tokens missed:  25110\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9688    0.9920    0.9803     26258\n",
      "           1     0.6415    0.3081    0.4162      1214\n",
      "\n",
      "    accuracy                         0.9618     27472\n",
      "   macro avg     0.8051    0.6501    0.6983     27472\n",
      "weighted avg     0.9543    0.9618    0.9553     27472\n",
      "\n",
      "[27] Label Model\n",
      "Total number of tokens missed:  25110\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9695    0.9923    0.9807     26258\n",
      "           1     0.6600    0.3245    0.4351      1214\n",
      "\n",
      "    accuracy                         0.9628     27472\n",
      "   macro avg     0.8147    0.6584    0.7079     27472\n",
      "weighted avg     0.9558    0.9628    0.9566     27472\n",
      "\n",
      "[28] Label Model\n",
      "Total number of tokens missed:  25110\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9688    0.9923    0.9804     26258\n",
      "           1     0.6482    0.3081    0.4176      1214\n",
      "\n",
      "    accuracy                         0.9620     27472\n",
      "   macro avg     0.8085    0.6502    0.6990     27472\n",
      "weighted avg     0.9546    0.9620    0.9555     27472\n",
      "\n",
      "[29] Label Model\n",
      "Total number of tokens missed:  25110\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9726    0.9914    0.9819     26258\n",
      "           1     0.6813    0.3962    0.5010      1214\n",
      "\n",
      "    accuracy                         0.9651     27472\n",
      "   macro avg     0.8270    0.6938    0.7415     27472\n",
      "weighted avg     0.9597    0.9651    0.9607     27472\n",
      "\n",
      "[30] Label Model\n",
      "Total number of tokens missed:  25110\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9688    0.9920    0.9803     26258\n",
      "           1     0.6415    0.3081    0.4162      1214\n",
      "\n",
      "    accuracy                         0.9618     27472\n",
      "   macro avg     0.8051    0.6501    0.6983     27472\n",
      "weighted avg     0.9543    0.9618    0.9553     27472\n",
      "\n",
      "[31] Label Model\n",
      "Total number of tokens missed:  25110\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9695    0.9923    0.9807     26258\n",
      "           1     0.6600    0.3245    0.4351      1214\n",
      "\n",
      "    accuracy                         0.9628     27472\n",
      "   macro avg     0.8147    0.6584    0.7079     27472\n",
      "weighted avg     0.9558    0.9628    0.9566     27472\n",
      "\n",
      "[32] Label Model\n",
      "Total number of tokens missed:  25110\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9726    0.9914    0.9819     26258\n",
      "           1     0.6813    0.3962    0.5010      1214\n",
      "\n",
      "    accuracy                         0.9651     27472\n",
      "   macro avg     0.8270    0.6938    0.7415     27472\n",
      "weighted avg     0.9597    0.9651    0.9607     27472\n",
      "\n",
      "[33] Label Model\n",
      "Total number of tokens missed:  25110\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9688    0.9920    0.9803     26258\n",
      "           1     0.6415    0.3081    0.4162      1214\n",
      "\n",
      "    accuracy                         0.9618     27472\n",
      "   macro avg     0.8051    0.6501    0.6983     27472\n",
      "weighted avg     0.9543    0.9618    0.9553     27472\n",
      "\n",
      "[34] Label Model\n",
      "Total number of tokens missed:  25110\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9688    0.9920    0.9803     26258\n",
      "           1     0.6415    0.3081    0.4162      1214\n",
      "\n",
      "    accuracy                         0.9618     27472\n",
      "   macro avg     0.8051    0.6501    0.6983     27472\n",
      "weighted avg     0.9543    0.9618    0.9553     27472\n",
      "\n",
      "[35] Label Model\n",
      "Total number of tokens missed:  25110\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9690    0.9923    0.9805     26258\n",
      "           1     0.6535    0.3138    0.4240      1214\n",
      "\n",
      "    accuracy                         0.9623     27472\n",
      "   macro avg     0.8113    0.6531    0.7023     27472\n",
      "weighted avg     0.9551    0.9623    0.9559     27472\n",
      "\n",
      "[36] Label Model\n",
      "Total number of tokens missed:  25110\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9726    0.9914    0.9819     26258\n",
      "           1     0.6813    0.3962    0.5010      1214\n",
      "\n",
      "    accuracy                         0.9651     27472\n",
      "   macro avg     0.8270    0.6938    0.7415     27472\n",
      "weighted avg     0.9597    0.9651    0.9607     27472\n",
      "\n",
      "[37] Label Model\n",
      "Total number of tokens missed:  25110\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9688    0.9920    0.9803     26258\n",
      "           1     0.6415    0.3081    0.4162      1214\n",
      "\n",
      "    accuracy                         0.9618     27472\n",
      "   macro avg     0.8051    0.6501    0.6983     27472\n",
      "weighted avg     0.9543    0.9618    0.9553     27472\n",
      "\n",
      "[38] Label Model\n",
      "Total number of tokens missed:  25110\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9726    0.9914    0.9819     26258\n",
      "           1     0.6813    0.3962    0.5010      1214\n",
      "\n",
      "    accuracy                         0.9651     27472\n",
      "   macro avg     0.8270    0.6938    0.7415     27472\n",
      "weighted avg     0.9597    0.9651    0.9607     27472\n",
      "\n",
      "[39] Label Model\n",
      "Total number of tokens missed:  25110\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9726    0.9914    0.9819     26258\n",
      "           1     0.6813    0.3962    0.5010      1214\n",
      "\n",
      "    accuracy                         0.9651     27472\n",
      "   macro avg     0.8270    0.6938    0.7415     27472\n",
      "weighted avg     0.9597    0.9651    0.9607     27472\n",
      "\n",
      "[40] Label Model\n",
      "Total number of tokens missed:  25110\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9695    0.9923    0.9807     26258\n",
      "           1     0.6600    0.3245    0.4351      1214\n",
      "\n",
      "    accuracy                         0.9628     27472\n",
      "   macro avg     0.8147    0.6584    0.7079     27472\n",
      "weighted avg     0.9558    0.9628    0.9566     27472\n",
      "\n",
      "[41] Label Model\n",
      "Total number of tokens missed:  25110\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9726    0.9914    0.9819     26258\n",
      "           1     0.6813    0.3962    0.5010      1214\n",
      "\n",
      "    accuracy                         0.9651     27472\n",
      "   macro avg     0.8270    0.6938    0.7415     27472\n",
      "weighted avg     0.9597    0.9651    0.9607     27472\n",
      "\n",
      "[42] Label Model\n",
      "Total number of tokens missed:  25110\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9698    0.9920    0.9808     26258\n",
      "           1     0.6591    0.3328    0.4423      1214\n",
      "\n",
      "    accuracy                         0.9629     27472\n",
      "   macro avg     0.8144    0.6624    0.7115     27472\n",
      "weighted avg     0.9561    0.9629    0.9570     27472\n",
      "\n",
      "[43] Label Model\n",
      "Total number of tokens missed:  25110\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9690    0.9923    0.9805     26258\n",
      "           1     0.6535    0.3138    0.4240      1214\n",
      "\n",
      "    accuracy                         0.9623     27472\n",
      "   macro avg     0.8113    0.6531    0.7023     27472\n",
      "weighted avg     0.9551    0.9623    0.9559     27472\n",
      "\n",
      "[44] Label Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of tokens missed:  25110\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9690    0.9923    0.9805     26258\n",
      "           1     0.6535    0.3138    0.4240      1214\n",
      "\n",
      "    accuracy                         0.9623     27472\n",
      "   macro avg     0.8113    0.6531    0.7023     27472\n",
      "weighted avg     0.9551    0.9623    0.9559     27472\n",
      "\n",
      "[45] Label Model\n",
      "Total number of tokens missed:  25110\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9690    0.9923    0.9805     26258\n",
      "           1     0.6535    0.3138    0.4240      1214\n",
      "\n",
      "    accuracy                         0.9623     27472\n",
      "   macro avg     0.8113    0.6531    0.7023     27472\n",
      "weighted avg     0.9551    0.9623    0.9559     27472\n",
      "\n",
      "[46] Label Model\n",
      "Total number of tokens missed:  25110\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9690    0.9923    0.9805     26258\n",
      "           1     0.6535    0.3138    0.4240      1214\n",
      "\n",
      "    accuracy                         0.9623     27472\n",
      "   macro avg     0.8113    0.6531    0.7023     27472\n",
      "weighted avg     0.9551    0.9623    0.9559     27472\n",
      "\n",
      "[47] Label Model\n",
      "Total number of tokens missed:  25110\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9690    0.9923    0.9805     26258\n",
      "           1     0.6535    0.3138    0.4240      1214\n",
      "\n",
      "    accuracy                         0.9623     27472\n",
      "   macro avg     0.8113    0.6531    0.7023     27472\n",
      "weighted avg     0.9551    0.9623    0.9559     27472\n",
      "\n",
      "[48] Label Model\n",
      "Total number of tokens missed:  25110\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9726    0.9914    0.9819     26258\n",
      "           1     0.6813    0.3962    0.5010      1214\n",
      "\n",
      "    accuracy                         0.9651     27472\n",
      "   macro avg     0.8270    0.6938    0.7415     27472\n",
      "weighted avg     0.9597    0.9651    0.9607     27472\n",
      "\n",
      "[49] Label Model\n",
      "Total number of tokens missed:  25110\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9688    0.9920    0.9803     26258\n",
      "           1     0.6415    0.3081    0.4162      1214\n",
      "\n",
      "    accuracy                         0.9618     27472\n",
      "   macro avg     0.8051    0.6501    0.6983     27472\n",
      "weighted avg     0.9543    0.9618    0.9553     27472\n",
      "\n",
      "Save the best overall model, configuration and partition for this experiment level\n"
     ]
    }
   ],
   "source": [
    "# CandGen Version v4 all (with extra specified negatives - all UMLS, non-UMLS, dd, dicts, abbreviation NOT the ReGeX)\n",
    "\n",
    "predicted_s = train_plus(train_s_candidates, test_s_ebm_candidates, test_s_ebm_corr_candidates, Y_s, 's', paramgrid = param_grid, mode = 'pred')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "8d3310cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparamater Search Space: 384\n",
      "Grid search over 50 configs\n",
      "[0] Label Model\n",
      "Total number of tokens missed:  25470\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9695    0.9919    0.9806     25898\n",
      "           1     0.6596    0.3336    0.4431      1214\n",
      "\n",
      "    accuracy                         0.9625     27112\n",
      "   macro avg     0.8145    0.6628    0.7118     27112\n",
      "weighted avg     0.9556    0.9625    0.9565     27112\n",
      "\n",
      "[1] Label Model\n",
      "Total number of tokens missed:  25470\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9695    0.9919    0.9806     25898\n",
      "           1     0.6596    0.3336    0.4431      1214\n",
      "\n",
      "    accuracy                         0.9625     27112\n",
      "   macro avg     0.8145    0.6628    0.7118     27112\n",
      "weighted avg     0.9556    0.9625    0.9565     27112\n",
      "\n",
      "[2] Label Model\n",
      "Total number of tokens missed:  25470\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9695    0.9919    0.9806     25898\n",
      "           1     0.6596    0.3336    0.4431      1214\n",
      "\n",
      "    accuracy                         0.9625     27112\n",
      "   macro avg     0.8145    0.6628    0.7118     27112\n",
      "weighted avg     0.9556    0.9625    0.9565     27112\n",
      "\n",
      "[3] Label Model\n",
      "Total number of tokens missed:  25470\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9722    0.9913    0.9817     25898\n",
      "           1     0.6813    0.3962    0.5010      1214\n",
      "\n",
      "    accuracy                         0.9647     27112\n",
      "   macro avg     0.8268    0.6938    0.7414     27112\n",
      "weighted avg     0.9592    0.9647    0.9602     27112\n",
      "\n",
      "[4] Label Model\n",
      "Total number of tokens missed:  25470\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9683    0.9919    0.9800     25898\n",
      "           1     0.6415    0.3081    0.4162      1214\n",
      "\n",
      "    accuracy                         0.9613     27112\n",
      "   macro avg     0.8049    0.6500    0.6981     27112\n",
      "weighted avg     0.9537    0.9613    0.9547     27112\n",
      "\n",
      "[5] Label Model\n",
      "Total number of tokens missed:  25470\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9683    0.9919    0.9800     25898\n",
      "           1     0.6415    0.3081    0.4162      1214\n",
      "\n",
      "    accuracy                         0.9613     27112\n",
      "   macro avg     0.8049    0.6500    0.6981     27112\n",
      "weighted avg     0.9537    0.9613    0.9547     27112\n",
      "\n",
      "[6] Label Model\n",
      "Total number of tokens missed:  25470\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9695    0.9919    0.9806     25898\n",
      "           1     0.6596    0.3336    0.4431      1214\n",
      "\n",
      "    accuracy                         0.9625     27112\n",
      "   macro avg     0.8145    0.6628    0.7118     27112\n",
      "weighted avg     0.9556    0.9625    0.9565     27112\n",
      "\n",
      "[7] Label Model\n",
      "Total number of tokens missed:  25470\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9695    0.9919    0.9806     25898\n",
      "           1     0.6596    0.3336    0.4431      1214\n",
      "\n",
      "    accuracy                         0.9625     27112\n",
      "   macro avg     0.8145    0.6628    0.7118     27112\n",
      "weighted avg     0.9556    0.9625    0.9565     27112\n",
      "\n",
      "[8] Label Model\n",
      "Total number of tokens missed:  25470\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9695    0.9919    0.9806     25898\n",
      "           1     0.6596    0.3336    0.4431      1214\n",
      "\n",
      "    accuracy                         0.9625     27112\n",
      "   macro avg     0.8145    0.6628    0.7118     27112\n",
      "weighted avg     0.9556    0.9625    0.9565     27112\n",
      "\n",
      "[9] Label Model\n",
      "Total number of tokens missed:  25470\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9695    0.9919    0.9806     25898\n",
      "           1     0.6596    0.3336    0.4431      1214\n",
      "\n",
      "    accuracy                         0.9625     27112\n",
      "   macro avg     0.8145    0.6628    0.7118     27112\n",
      "weighted avg     0.9556    0.9625    0.9565     27112\n",
      "\n",
      "[10] Label Model\n",
      "Total number of tokens missed:  25470\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9695    0.9919    0.9806     25898\n",
      "           1     0.6596    0.3336    0.4431      1214\n",
      "\n",
      "    accuracy                         0.9625     27112\n",
      "   macro avg     0.8145    0.6628    0.7118     27112\n",
      "weighted avg     0.9556    0.9625    0.9565     27112\n",
      "\n",
      "[11] Label Model\n",
      "Total number of tokens missed:  25470\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9695    0.9919    0.9806     25898\n",
      "           1     0.6596    0.3336    0.4431      1214\n",
      "\n",
      "    accuracy                         0.9625     27112\n",
      "   macro avg     0.8145    0.6628    0.7118     27112\n",
      "weighted avg     0.9556    0.9625    0.9565     27112\n",
      "\n",
      "[12] Label Model\n",
      "Total number of tokens missed:  25470\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9695    0.9919    0.9806     25898\n",
      "           1     0.6596    0.3336    0.4431      1214\n",
      "\n",
      "    accuracy                         0.9625     27112\n",
      "   macro avg     0.8145    0.6628    0.7118     27112\n",
      "weighted avg     0.9556    0.9625    0.9565     27112\n",
      "\n",
      "[13] Label Model\n",
      "Total number of tokens missed:  25470\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9695    0.9919    0.9806     25898\n",
      "           1     0.6596    0.3336    0.4431      1214\n",
      "\n",
      "    accuracy                         0.9625     27112\n",
      "   macro avg     0.8145    0.6628    0.7118     27112\n",
      "weighted avg     0.9556    0.9625    0.9565     27112\n",
      "\n",
      "[14] Label Model\n",
      "Total number of tokens missed:  25470\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9695    0.9919    0.9806     25898\n",
      "           1     0.6596    0.3336    0.4431      1214\n",
      "\n",
      "    accuracy                         0.9625     27112\n",
      "   macro avg     0.8145    0.6628    0.7118     27112\n",
      "weighted avg     0.9556    0.9625    0.9565     27112\n",
      "\n",
      "[15] Label Model\n",
      "Total number of tokens missed:  25470\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9695    0.9919    0.9806     25898\n",
      "           1     0.6596    0.3336    0.4431      1214\n",
      "\n",
      "    accuracy                         0.9625     27112\n",
      "   macro avg     0.8145    0.6628    0.7118     27112\n",
      "weighted avg     0.9556    0.9625    0.9565     27112\n",
      "\n",
      "[16] Label Model\n",
      "Total number of tokens missed:  25470\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9722    0.9913    0.9817     25898\n",
      "           1     0.6813    0.3962    0.5010      1214\n",
      "\n",
      "    accuracy                         0.9647     27112\n",
      "   macro avg     0.8268    0.6938    0.7414     27112\n",
      "weighted avg     0.9592    0.9647    0.9602     27112\n",
      "\n",
      "[17] Label Model\n",
      "Total number of tokens missed:  25470\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9695    0.9919    0.9806     25898\n",
      "           1     0.6596    0.3336    0.4431      1214\n",
      "\n",
      "    accuracy                         0.9625     27112\n",
      "   macro avg     0.8145    0.6628    0.7118     27112\n",
      "weighted avg     0.9556    0.9625    0.9565     27112\n",
      "\n",
      "[18] Label Model\n",
      "Total number of tokens missed:  25470\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9683    0.9919    0.9800     25898\n",
      "           1     0.6415    0.3081    0.4162      1214\n",
      "\n",
      "    accuracy                         0.9613     27112\n",
      "   macro avg     0.8049    0.6500    0.6981     27112\n",
      "weighted avg     0.9537    0.9613    0.9547     27112\n",
      "\n",
      "[19] Label Model\n",
      "Total number of tokens missed:  25470\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9695    0.9919    0.9806     25898\n",
      "           1     0.6596    0.3336    0.4431      1214\n",
      "\n",
      "    accuracy                         0.9625     27112\n",
      "   macro avg     0.8145    0.6628    0.7118     27112\n",
      "weighted avg     0.9556    0.9625    0.9565     27112\n",
      "\n",
      "[20] Label Model\n",
      "Total number of tokens missed:  25470\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9683    0.9919    0.9800     25898\n",
      "           1     0.6415    0.3081    0.4162      1214\n",
      "\n",
      "    accuracy                         0.9613     27112\n",
      "   macro avg     0.8049    0.6500    0.6981     27112\n",
      "weighted avg     0.9537    0.9613    0.9547     27112\n",
      "\n",
      "[21] Label Model\n",
      "Total number of tokens missed:  25470\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9695    0.9919    0.9806     25898\n",
      "           1     0.6596    0.3336    0.4431      1214\n",
      "\n",
      "    accuracy                         0.9625     27112\n",
      "   macro avg     0.8145    0.6628    0.7118     27112\n",
      "weighted avg     0.9556    0.9625    0.9565     27112\n",
      "\n",
      "[22] Label Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of tokens missed:  25470\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9695    0.9919    0.9806     25898\n",
      "           1     0.6596    0.3336    0.4431      1214\n",
      "\n",
      "    accuracy                         0.9625     27112\n",
      "   macro avg     0.8145    0.6628    0.7118     27112\n",
      "weighted avg     0.9556    0.9625    0.9565     27112\n",
      "\n",
      "[23] Label Model\n",
      "Total number of tokens missed:  25470\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9695    0.9919    0.9806     25898\n",
      "           1     0.6596    0.3336    0.4431      1214\n",
      "\n",
      "    accuracy                         0.9625     27112\n",
      "   macro avg     0.8145    0.6628    0.7118     27112\n",
      "weighted avg     0.9556    0.9625    0.9565     27112\n",
      "\n",
      "[24] Label Model\n",
      "Total number of tokens missed:  25470\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9695    0.9919    0.9806     25898\n",
      "           1     0.6596    0.3336    0.4431      1214\n",
      "\n",
      "    accuracy                         0.9625     27112\n",
      "   macro avg     0.8145    0.6628    0.7118     27112\n",
      "weighted avg     0.9556    0.9625    0.9565     27112\n",
      "\n",
      "[25] Label Model\n",
      "Total number of tokens missed:  25470\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9683    0.9919    0.9800     25898\n",
      "           1     0.6415    0.3081    0.4162      1214\n",
      "\n",
      "    accuracy                         0.9613     27112\n",
      "   macro avg     0.8049    0.6500    0.6981     27112\n",
      "weighted avg     0.9537    0.9613    0.9547     27112\n",
      "\n",
      "[26] Label Model\n",
      "Total number of tokens missed:  25470\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9683    0.9919    0.9800     25898\n",
      "           1     0.6415    0.3081    0.4162      1214\n",
      "\n",
      "    accuracy                         0.9613     27112\n",
      "   macro avg     0.8049    0.6500    0.6981     27112\n",
      "weighted avg     0.9537    0.9613    0.9547     27112\n",
      "\n",
      "[27] Label Model\n",
      "Total number of tokens missed:  25470\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9695    0.9919    0.9806     25898\n",
      "           1     0.6596    0.3336    0.4431      1214\n",
      "\n",
      "    accuracy                         0.9625     27112\n",
      "   macro avg     0.8145    0.6628    0.7118     27112\n",
      "weighted avg     0.9556    0.9625    0.9565     27112\n",
      "\n",
      "[28] Label Model\n",
      "Total number of tokens missed:  25470\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9683    0.9919    0.9800     25898\n",
      "           1     0.6415    0.3081    0.4162      1214\n",
      "\n",
      "    accuracy                         0.9613     27112\n",
      "   macro avg     0.8049    0.6500    0.6981     27112\n",
      "weighted avg     0.9537    0.9613    0.9547     27112\n",
      "\n",
      "[29] Label Model\n",
      "Total number of tokens missed:  25470\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9695    0.9919    0.9806     25898\n",
      "           1     0.6596    0.3336    0.4431      1214\n",
      "\n",
      "    accuracy                         0.9625     27112\n",
      "   macro avg     0.8145    0.6628    0.7118     27112\n",
      "weighted avg     0.9556    0.9625    0.9565     27112\n",
      "\n",
      "[30] Label Model\n",
      "Total number of tokens missed:  25470\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9683    0.9919    0.9800     25898\n",
      "           1     0.6415    0.3081    0.4162      1214\n",
      "\n",
      "    accuracy                         0.9613     27112\n",
      "   macro avg     0.8049    0.6500    0.6981     27112\n",
      "weighted avg     0.9537    0.9613    0.9547     27112\n",
      "\n",
      "[31] Label Model\n",
      "Total number of tokens missed:  25470\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9695    0.9919    0.9806     25898\n",
      "           1     0.6596    0.3336    0.4431      1214\n",
      "\n",
      "    accuracy                         0.9625     27112\n",
      "   macro avg     0.8145    0.6628    0.7118     27112\n",
      "weighted avg     0.9556    0.9625    0.9565     27112\n",
      "\n",
      "[32] Label Model\n",
      "Total number of tokens missed:  25470\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9722    0.9913    0.9817     25898\n",
      "           1     0.6813    0.3962    0.5010      1214\n",
      "\n",
      "    accuracy                         0.9647     27112\n",
      "   macro avg     0.8268    0.6938    0.7414     27112\n",
      "weighted avg     0.9592    0.9647    0.9602     27112\n",
      "\n",
      "[33] Label Model\n",
      "Total number of tokens missed:  25470\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9683    0.9919    0.9800     25898\n",
      "           1     0.6415    0.3081    0.4162      1214\n",
      "\n",
      "    accuracy                         0.9613     27112\n",
      "   macro avg     0.8049    0.6500    0.6981     27112\n",
      "weighted avg     0.9537    0.9613    0.9547     27112\n",
      "\n",
      "[34] Label Model\n",
      "Total number of tokens missed:  25470\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9683    0.9919    0.9800     25898\n",
      "           1     0.6415    0.3081    0.4162      1214\n",
      "\n",
      "    accuracy                         0.9613     27112\n",
      "   macro avg     0.8049    0.6500    0.6981     27112\n",
      "weighted avg     0.9537    0.9613    0.9547     27112\n",
      "\n",
      "[35] Label Model\n",
      "Total number of tokens missed:  25470\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9695    0.9919    0.9806     25898\n",
      "           1     0.6596    0.3336    0.4431      1214\n",
      "\n",
      "    accuracy                         0.9625     27112\n",
      "   macro avg     0.8145    0.6628    0.7118     27112\n",
      "weighted avg     0.9556    0.9625    0.9565     27112\n",
      "\n",
      "[36] Label Model\n",
      "Total number of tokens missed:  25470\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9722    0.9913    0.9817     25898\n",
      "           1     0.6813    0.3962    0.5010      1214\n",
      "\n",
      "    accuracy                         0.9647     27112\n",
      "   macro avg     0.8268    0.6938    0.7414     27112\n",
      "weighted avg     0.9592    0.9647    0.9602     27112\n",
      "\n",
      "[37] Label Model\n",
      "Total number of tokens missed:  25470\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9683    0.9919    0.9800     25898\n",
      "           1     0.6415    0.3081    0.4162      1214\n",
      "\n",
      "    accuracy                         0.9613     27112\n",
      "   macro avg     0.8049    0.6500    0.6981     27112\n",
      "weighted avg     0.9537    0.9613    0.9547     27112\n",
      "\n",
      "[38] Label Model\n",
      "Total number of tokens missed:  25470\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9722    0.9913    0.9817     25898\n",
      "           1     0.6813    0.3962    0.5010      1214\n",
      "\n",
      "    accuracy                         0.9647     27112\n",
      "   macro avg     0.8268    0.6938    0.7414     27112\n",
      "weighted avg     0.9592    0.9647    0.9602     27112\n",
      "\n",
      "[39] Label Model\n",
      "Total number of tokens missed:  25470\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9722    0.9913    0.9817     25898\n",
      "           1     0.6813    0.3962    0.5010      1214\n",
      "\n",
      "    accuracy                         0.9647     27112\n",
      "   macro avg     0.8268    0.6938    0.7414     27112\n",
      "weighted avg     0.9592    0.9647    0.9602     27112\n",
      "\n",
      "[40] Label Model\n",
      "Total number of tokens missed:  25470\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9695    0.9919    0.9806     25898\n",
      "           1     0.6596    0.3336    0.4431      1214\n",
      "\n",
      "    accuracy                         0.9625     27112\n",
      "   macro avg     0.8145    0.6628    0.7118     27112\n",
      "weighted avg     0.9556    0.9625    0.9565     27112\n",
      "\n",
      "[41] Label Model\n",
      "Total number of tokens missed:  25470\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9722    0.9913    0.9817     25898\n",
      "           1     0.6813    0.3962    0.5010      1214\n",
      "\n",
      "    accuracy                         0.9647     27112\n",
      "   macro avg     0.8268    0.6938    0.7414     27112\n",
      "weighted avg     0.9592    0.9647    0.9602     27112\n",
      "\n",
      "[42] Label Model\n",
      "Total number of tokens missed:  25470\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9683    0.9919    0.9800     25898\n",
      "           1     0.6415    0.3081    0.4162      1214\n",
      "\n",
      "    accuracy                         0.9613     27112\n",
      "   macro avg     0.8049    0.6500    0.6981     27112\n",
      "weighted avg     0.9537    0.9613    0.9547     27112\n",
      "\n",
      "[43] Label Model\n",
      "Total number of tokens missed:  25470\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9695    0.9919    0.9806     25898\n",
      "           1     0.6596    0.3336    0.4431      1214\n",
      "\n",
      "    accuracy                         0.9625     27112\n",
      "   macro avg     0.8145    0.6628    0.7118     27112\n",
      "weighted avg     0.9556    0.9625    0.9565     27112\n",
      "\n",
      "[44] Label Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of tokens missed:  25470\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9695    0.9919    0.9806     25898\n",
      "           1     0.6596    0.3336    0.4431      1214\n",
      "\n",
      "    accuracy                         0.9625     27112\n",
      "   macro avg     0.8145    0.6628    0.7118     27112\n",
      "weighted avg     0.9556    0.9625    0.9565     27112\n",
      "\n",
      "[45] Label Model\n",
      "Total number of tokens missed:  25470\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9695    0.9919    0.9806     25898\n",
      "           1     0.6596    0.3336    0.4431      1214\n",
      "\n",
      "    accuracy                         0.9625     27112\n",
      "   macro avg     0.8145    0.6628    0.7118     27112\n",
      "weighted avg     0.9556    0.9625    0.9565     27112\n",
      "\n",
      "[46] Label Model\n",
      "Total number of tokens missed:  25470\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9695    0.9919    0.9806     25898\n",
      "           1     0.6596    0.3336    0.4431      1214\n",
      "\n",
      "    accuracy                         0.9625     27112\n",
      "   macro avg     0.8145    0.6628    0.7118     27112\n",
      "weighted avg     0.9556    0.9625    0.9565     27112\n",
      "\n",
      "[47] Label Model\n",
      "Total number of tokens missed:  25470\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9695    0.9919    0.9806     25898\n",
      "           1     0.6596    0.3336    0.4431      1214\n",
      "\n",
      "    accuracy                         0.9625     27112\n",
      "   macro avg     0.8145    0.6628    0.7118     27112\n",
      "weighted avg     0.9556    0.9625    0.9565     27112\n",
      "\n",
      "[48] Label Model\n",
      "Total number of tokens missed:  25470\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9722    0.9913    0.9817     25898\n",
      "           1     0.6813    0.3962    0.5010      1214\n",
      "\n",
      "    accuracy                         0.9647     27112\n",
      "   macro avg     0.8268    0.6938    0.7414     27112\n",
      "weighted avg     0.9592    0.9647    0.9602     27112\n",
      "\n",
      "[49] Label Model\n",
      "Total number of tokens missed:  25470\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9683    0.9919    0.9800     25898\n",
      "           1     0.6415    0.3081    0.4162      1214\n",
      "\n",
      "    accuracy                         0.9613     27112\n",
      "   macro avg     0.8049    0.6500    0.6981     27112\n",
      "weighted avg     0.9537    0.9613    0.9547     27112\n",
      "\n",
      "Save the best overall model, configuration and partition for this experiment level\n"
     ]
    }
   ],
   "source": [
    "# CandGen Version v4 all (with extra specified negatives - all UMLS, non-UMLS, dd, dicts, abbreviation NOT the ReGeX)\n",
    "\n",
    "predicted_s = train_plus(train_s_candidates, test_s_ebm_candidates, test_s_ebm_corr_candidates, Y_s, 's', paramgrid = param_grid, mode = 'pred')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "290f03e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparamater Search Space: 384\n",
      "Grid search over 50 configs\n",
      "[0] Label Model\n",
      "Total number of tokens missed:  25565\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9694    0.9919    0.9805     25804\n",
      "           1     0.6596    0.3339    0.4433      1213\n",
      "\n",
      "    accuracy                         0.9624     27017\n",
      "   macro avg     0.8145    0.6629    0.7119     27017\n",
      "weighted avg     0.9555    0.9624    0.9564     27017\n",
      "\n",
      "[1] Label Model\n",
      "Total number of tokens missed:  25565\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9694    0.9919    0.9805     25804\n",
      "           1     0.6596    0.3339    0.4433      1213\n",
      "\n",
      "    accuracy                         0.9624     27017\n",
      "   macro avg     0.8145    0.6629    0.7119     27017\n",
      "weighted avg     0.9555    0.9624    0.9564     27017\n",
      "\n",
      "[2] Label Model\n",
      "Total number of tokens missed:  25565\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9694    0.9919    0.9805     25804\n",
      "           1     0.6596    0.3339    0.4433      1213\n",
      "\n",
      "    accuracy                         0.9624     27017\n",
      "   macro avg     0.8145    0.6629    0.7119     27017\n",
      "weighted avg     0.9555    0.9624    0.9564     27017\n",
      "\n",
      "[3] Label Model\n",
      "Total number of tokens missed:  25565\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9722    0.9913    0.9816     25804\n",
      "           1     0.6813    0.3965    0.5013      1213\n",
      "\n",
      "    accuracy                         0.9646     27017\n",
      "   macro avg     0.8267    0.6939    0.7415     27017\n",
      "weighted avg     0.9591    0.9646    0.9601     27017\n",
      "\n",
      "[4] Label Model\n",
      "Total number of tokens missed:  25565\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9683    0.9919    0.9799     25804\n",
      "           1     0.6415    0.3083    0.4165      1213\n",
      "\n",
      "    accuracy                         0.9612     27017\n",
      "   macro avg     0.8049    0.6501    0.6982     27017\n",
      "weighted avg     0.9536    0.9612    0.9546     27017\n",
      "\n",
      "[5] Label Model\n",
      "Total number of tokens missed:  25565\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9683    0.9919    0.9799     25804\n",
      "           1     0.6415    0.3083    0.4165      1213\n",
      "\n",
      "    accuracy                         0.9612     27017\n",
      "   macro avg     0.8049    0.6501    0.6982     27017\n",
      "weighted avg     0.9536    0.9612    0.9546     27017\n",
      "\n",
      "[6] Label Model\n",
      "Total number of tokens missed:  25565\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9694    0.9919    0.9805     25804\n",
      "           1     0.6596    0.3339    0.4433      1213\n",
      "\n",
      "    accuracy                         0.9624     27017\n",
      "   macro avg     0.8145    0.6629    0.7119     27017\n",
      "weighted avg     0.9555    0.9624    0.9564     27017\n",
      "\n",
      "[7] Label Model\n",
      "Total number of tokens missed:  25565\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9694    0.9919    0.9805     25804\n",
      "           1     0.6596    0.3339    0.4433      1213\n",
      "\n",
      "    accuracy                         0.9624     27017\n",
      "   macro avg     0.8145    0.6629    0.7119     27017\n",
      "weighted avg     0.9555    0.9624    0.9564     27017\n",
      "\n",
      "[8] Label Model\n",
      "Total number of tokens missed:  25565\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9694    0.9919    0.9805     25804\n",
      "           1     0.6596    0.3339    0.4433      1213\n",
      "\n",
      "    accuracy                         0.9624     27017\n",
      "   macro avg     0.8145    0.6629    0.7119     27017\n",
      "weighted avg     0.9555    0.9624    0.9564     27017\n",
      "\n",
      "[9] Label Model\n",
      "Total number of tokens missed:  25565\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9694    0.9919    0.9805     25804\n",
      "           1     0.6596    0.3339    0.4433      1213\n",
      "\n",
      "    accuracy                         0.9624     27017\n",
      "   macro avg     0.8145    0.6629    0.7119     27017\n",
      "weighted avg     0.9555    0.9624    0.9564     27017\n",
      "\n",
      "[10] Label Model\n",
      "Total number of tokens missed:  25565\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9694    0.9919    0.9805     25804\n",
      "           1     0.6596    0.3339    0.4433      1213\n",
      "\n",
      "    accuracy                         0.9624     27017\n",
      "   macro avg     0.8145    0.6629    0.7119     27017\n",
      "weighted avg     0.9555    0.9624    0.9564     27017\n",
      "\n",
      "[11] Label Model\n",
      "Total number of tokens missed:  25565\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9694    0.9919    0.9805     25804\n",
      "           1     0.6596    0.3339    0.4433      1213\n",
      "\n",
      "    accuracy                         0.9624     27017\n",
      "   macro avg     0.8145    0.6629    0.7119     27017\n",
      "weighted avg     0.9555    0.9624    0.9564     27017\n",
      "\n",
      "[12] Label Model\n",
      "Total number of tokens missed:  25565\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9694    0.9919    0.9805     25804\n",
      "           1     0.6596    0.3339    0.4433      1213\n",
      "\n",
      "    accuracy                         0.9624     27017\n",
      "   macro avg     0.8145    0.6629    0.7119     27017\n",
      "weighted avg     0.9555    0.9624    0.9564     27017\n",
      "\n",
      "[13] Label Model\n",
      "Total number of tokens missed:  25565\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9694    0.9919    0.9805     25804\n",
      "           1     0.6596    0.3339    0.4433      1213\n",
      "\n",
      "    accuracy                         0.9624     27017\n",
      "   macro avg     0.8145    0.6629    0.7119     27017\n",
      "weighted avg     0.9555    0.9624    0.9564     27017\n",
      "\n",
      "[14] Label Model\n",
      "Total number of tokens missed:  25565\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9694    0.9919    0.9805     25804\n",
      "           1     0.6596    0.3339    0.4433      1213\n",
      "\n",
      "    accuracy                         0.9624     27017\n",
      "   macro avg     0.8145    0.6629    0.7119     27017\n",
      "weighted avg     0.9555    0.9624    0.9564     27017\n",
      "\n",
      "[15] Label Model\n",
      "Total number of tokens missed:  25565\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9694    0.9919    0.9805     25804\n",
      "           1     0.6596    0.3339    0.4433      1213\n",
      "\n",
      "    accuracy                         0.9624     27017\n",
      "   macro avg     0.8145    0.6629    0.7119     27017\n",
      "weighted avg     0.9555    0.9624    0.9564     27017\n",
      "\n",
      "[16] Label Model\n",
      "Total number of tokens missed:  25565\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9722    0.9913    0.9816     25804\n",
      "           1     0.6813    0.3965    0.5013      1213\n",
      "\n",
      "    accuracy                         0.9646     27017\n",
      "   macro avg     0.8267    0.6939    0.7415     27017\n",
      "weighted avg     0.9591    0.9646    0.9601     27017\n",
      "\n",
      "[17] Label Model\n",
      "Total number of tokens missed:  25565\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9694    0.9919    0.9805     25804\n",
      "           1     0.6596    0.3339    0.4433      1213\n",
      "\n",
      "    accuracy                         0.9624     27017\n",
      "   macro avg     0.8145    0.6629    0.7119     27017\n",
      "weighted avg     0.9555    0.9624    0.9564     27017\n",
      "\n",
      "[18] Label Model\n",
      "Total number of tokens missed:  25565\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9683    0.9919    0.9799     25804\n",
      "           1     0.6415    0.3083    0.4165      1213\n",
      "\n",
      "    accuracy                         0.9612     27017\n",
      "   macro avg     0.8049    0.6501    0.6982     27017\n",
      "weighted avg     0.9536    0.9612    0.9546     27017\n",
      "\n",
      "[19] Label Model\n",
      "Total number of tokens missed:  25565\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9694    0.9919    0.9805     25804\n",
      "           1     0.6596    0.3339    0.4433      1213\n",
      "\n",
      "    accuracy                         0.9624     27017\n",
      "   macro avg     0.8145    0.6629    0.7119     27017\n",
      "weighted avg     0.9555    0.9624    0.9564     27017\n",
      "\n",
      "[20] Label Model\n",
      "Total number of tokens missed:  25565\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9683    0.9919    0.9799     25804\n",
      "           1     0.6415    0.3083    0.4165      1213\n",
      "\n",
      "    accuracy                         0.9612     27017\n",
      "   macro avg     0.8049    0.6501    0.6982     27017\n",
      "weighted avg     0.9536    0.9612    0.9546     27017\n",
      "\n",
      "[21] Label Model\n",
      "Total number of tokens missed:  25565\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9694    0.9919    0.9805     25804\n",
      "           1     0.6596    0.3339    0.4433      1213\n",
      "\n",
      "    accuracy                         0.9624     27017\n",
      "   macro avg     0.8145    0.6629    0.7119     27017\n",
      "weighted avg     0.9555    0.9624    0.9564     27017\n",
      "\n",
      "[22] Label Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of tokens missed:  25565\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9694    0.9919    0.9805     25804\n",
      "           1     0.6596    0.3339    0.4433      1213\n",
      "\n",
      "    accuracy                         0.9624     27017\n",
      "   macro avg     0.8145    0.6629    0.7119     27017\n",
      "weighted avg     0.9555    0.9624    0.9564     27017\n",
      "\n",
      "[23] Label Model\n",
      "Total number of tokens missed:  25565\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9694    0.9919    0.9805     25804\n",
      "           1     0.6596    0.3339    0.4433      1213\n",
      "\n",
      "    accuracy                         0.9624     27017\n",
      "   macro avg     0.8145    0.6629    0.7119     27017\n",
      "weighted avg     0.9555    0.9624    0.9564     27017\n",
      "\n",
      "[24] Label Model\n",
      "Total number of tokens missed:  25565\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9694    0.9919    0.9805     25804\n",
      "           1     0.6596    0.3339    0.4433      1213\n",
      "\n",
      "    accuracy                         0.9624     27017\n",
      "   macro avg     0.8145    0.6629    0.7119     27017\n",
      "weighted avg     0.9555    0.9624    0.9564     27017\n",
      "\n",
      "[25] Label Model\n",
      "Total number of tokens missed:  25565\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9683    0.9919    0.9799     25804\n",
      "           1     0.6415    0.3083    0.4165      1213\n",
      "\n",
      "    accuracy                         0.9612     27017\n",
      "   macro avg     0.8049    0.6501    0.6982     27017\n",
      "weighted avg     0.9536    0.9612    0.9546     27017\n",
      "\n",
      "[26] Label Model\n",
      "Total number of tokens missed:  25565\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9683    0.9919    0.9799     25804\n",
      "           1     0.6415    0.3083    0.4165      1213\n",
      "\n",
      "    accuracy                         0.9612     27017\n",
      "   macro avg     0.8049    0.6501    0.6982     27017\n",
      "weighted avg     0.9536    0.9612    0.9546     27017\n",
      "\n",
      "[27] Label Model\n",
      "Total number of tokens missed:  25565\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9694    0.9919    0.9805     25804\n",
      "           1     0.6596    0.3339    0.4433      1213\n",
      "\n",
      "    accuracy                         0.9624     27017\n",
      "   macro avg     0.8145    0.6629    0.7119     27017\n",
      "weighted avg     0.9555    0.9624    0.9564     27017\n",
      "\n",
      "[28] Label Model\n",
      "Total number of tokens missed:  25565\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9683    0.9919    0.9799     25804\n",
      "           1     0.6415    0.3083    0.4165      1213\n",
      "\n",
      "    accuracy                         0.9612     27017\n",
      "   macro avg     0.8049    0.6501    0.6982     27017\n",
      "weighted avg     0.9536    0.9612    0.9546     27017\n",
      "\n",
      "[29] Label Model\n",
      "Total number of tokens missed:  25565\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9694    0.9919    0.9805     25804\n",
      "           1     0.6596    0.3339    0.4433      1213\n",
      "\n",
      "    accuracy                         0.9624     27017\n",
      "   macro avg     0.8145    0.6629    0.7119     27017\n",
      "weighted avg     0.9555    0.9624    0.9564     27017\n",
      "\n",
      "[30] Label Model\n",
      "Total number of tokens missed:  25565\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9683    0.9919    0.9799     25804\n",
      "           1     0.6415    0.3083    0.4165      1213\n",
      "\n",
      "    accuracy                         0.9612     27017\n",
      "   macro avg     0.8049    0.6501    0.6982     27017\n",
      "weighted avg     0.9536    0.9612    0.9546     27017\n",
      "\n",
      "[31] Label Model\n",
      "Total number of tokens missed:  25565\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9694    0.9919    0.9805     25804\n",
      "           1     0.6596    0.3339    0.4433      1213\n",
      "\n",
      "    accuracy                         0.9624     27017\n",
      "   macro avg     0.8145    0.6629    0.7119     27017\n",
      "weighted avg     0.9555    0.9624    0.9564     27017\n",
      "\n",
      "[32] Label Model\n",
      "Total number of tokens missed:  25565\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9722    0.9913    0.9816     25804\n",
      "           1     0.6813    0.3965    0.5013      1213\n",
      "\n",
      "    accuracy                         0.9646     27017\n",
      "   macro avg     0.8267    0.6939    0.7415     27017\n",
      "weighted avg     0.9591    0.9646    0.9601     27017\n",
      "\n",
      "[33] Label Model\n",
      "Total number of tokens missed:  25565\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9683    0.9919    0.9799     25804\n",
      "           1     0.6415    0.3083    0.4165      1213\n",
      "\n",
      "    accuracy                         0.9612     27017\n",
      "   macro avg     0.8049    0.6501    0.6982     27017\n",
      "weighted avg     0.9536    0.9612    0.9546     27017\n",
      "\n",
      "[34] Label Model\n",
      "Total number of tokens missed:  25565\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9683    0.9919    0.9799     25804\n",
      "           1     0.6415    0.3083    0.4165      1213\n",
      "\n",
      "    accuracy                         0.9612     27017\n",
      "   macro avg     0.8049    0.6501    0.6982     27017\n",
      "weighted avg     0.9536    0.9612    0.9546     27017\n",
      "\n",
      "[35] Label Model\n",
      "Total number of tokens missed:  25565\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9694    0.9919    0.9805     25804\n",
      "           1     0.6596    0.3339    0.4433      1213\n",
      "\n",
      "    accuracy                         0.9624     27017\n",
      "   macro avg     0.8145    0.6629    0.7119     27017\n",
      "weighted avg     0.9555    0.9624    0.9564     27017\n",
      "\n",
      "[36] Label Model\n",
      "Total number of tokens missed:  25565\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9722    0.9913    0.9816     25804\n",
      "           1     0.6813    0.3965    0.5013      1213\n",
      "\n",
      "    accuracy                         0.9646     27017\n",
      "   macro avg     0.8267    0.6939    0.7415     27017\n",
      "weighted avg     0.9591    0.9646    0.9601     27017\n",
      "\n",
      "[37] Label Model\n",
      "Total number of tokens missed:  25565\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9683    0.9919    0.9799     25804\n",
      "           1     0.6415    0.3083    0.4165      1213\n",
      "\n",
      "    accuracy                         0.9612     27017\n",
      "   macro avg     0.8049    0.6501    0.6982     27017\n",
      "weighted avg     0.9536    0.9612    0.9546     27017\n",
      "\n",
      "[38] Label Model\n",
      "Total number of tokens missed:  25565\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9722    0.9913    0.9816     25804\n",
      "           1     0.6813    0.3965    0.5013      1213\n",
      "\n",
      "    accuracy                         0.9646     27017\n",
      "   macro avg     0.8267    0.6939    0.7415     27017\n",
      "weighted avg     0.9591    0.9646    0.9601     27017\n",
      "\n",
      "[39] Label Model\n",
      "Total number of tokens missed:  25565\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9722    0.9913    0.9816     25804\n",
      "           1     0.6813    0.3965    0.5013      1213\n",
      "\n",
      "    accuracy                         0.9646     27017\n",
      "   macro avg     0.8267    0.6939    0.7415     27017\n",
      "weighted avg     0.9591    0.9646    0.9601     27017\n",
      "\n",
      "[40] Label Model\n",
      "Total number of tokens missed:  25565\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9694    0.9919    0.9805     25804\n",
      "           1     0.6596    0.3339    0.4433      1213\n",
      "\n",
      "    accuracy                         0.9624     27017\n",
      "   macro avg     0.8145    0.6629    0.7119     27017\n",
      "weighted avg     0.9555    0.9624    0.9564     27017\n",
      "\n",
      "[41] Label Model\n",
      "Total number of tokens missed:  25565\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9722    0.9913    0.9816     25804\n",
      "           1     0.6813    0.3965    0.5013      1213\n",
      "\n",
      "    accuracy                         0.9646     27017\n",
      "   macro avg     0.8267    0.6939    0.7415     27017\n",
      "weighted avg     0.9591    0.9646    0.9601     27017\n",
      "\n",
      "[42] Label Model\n",
      "Total number of tokens missed:  25565\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9683    0.9919    0.9799     25804\n",
      "           1     0.6415    0.3083    0.4165      1213\n",
      "\n",
      "    accuracy                         0.9612     27017\n",
      "   macro avg     0.8049    0.6501    0.6982     27017\n",
      "weighted avg     0.9536    0.9612    0.9546     27017\n",
      "\n",
      "[43] Label Model\n",
      "Total number of tokens missed:  25565\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9694    0.9919    0.9805     25804\n",
      "           1     0.6596    0.3339    0.4433      1213\n",
      "\n",
      "    accuracy                         0.9624     27017\n",
      "   macro avg     0.8145    0.6629    0.7119     27017\n",
      "weighted avg     0.9555    0.9624    0.9564     27017\n",
      "\n",
      "[44] Label Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of tokens missed:  25565\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9694    0.9919    0.9805     25804\n",
      "           1     0.6596    0.3339    0.4433      1213\n",
      "\n",
      "    accuracy                         0.9624     27017\n",
      "   macro avg     0.8145    0.6629    0.7119     27017\n",
      "weighted avg     0.9555    0.9624    0.9564     27017\n",
      "\n",
      "[45] Label Model\n",
      "Total number of tokens missed:  25565\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9694    0.9919    0.9805     25804\n",
      "           1     0.6596    0.3339    0.4433      1213\n",
      "\n",
      "    accuracy                         0.9624     27017\n",
      "   macro avg     0.8145    0.6629    0.7119     27017\n",
      "weighted avg     0.9555    0.9624    0.9564     27017\n",
      "\n",
      "[46] Label Model\n",
      "Total number of tokens missed:  25565\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9694    0.9919    0.9805     25804\n",
      "           1     0.6596    0.3339    0.4433      1213\n",
      "\n",
      "    accuracy                         0.9624     27017\n",
      "   macro avg     0.8145    0.6629    0.7119     27017\n",
      "weighted avg     0.9555    0.9624    0.9564     27017\n",
      "\n",
      "[47] Label Model\n",
      "Total number of tokens missed:  25565\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9694    0.9919    0.9805     25804\n",
      "           1     0.6596    0.3339    0.4433      1213\n",
      "\n",
      "    accuracy                         0.9624     27017\n",
      "   macro avg     0.8145    0.6629    0.7119     27017\n",
      "weighted avg     0.9555    0.9624    0.9564     27017\n",
      "\n",
      "[48] Label Model\n",
      "Total number of tokens missed:  25565\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9722    0.9913    0.9816     25804\n",
      "           1     0.6813    0.3965    0.5013      1213\n",
      "\n",
      "    accuracy                         0.9646     27017\n",
      "   macro avg     0.8267    0.6939    0.7415     27017\n",
      "weighted avg     0.9591    0.9646    0.9601     27017\n",
      "\n",
      "[49] Label Model\n",
      "Total number of tokens missed:  25565\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9683    0.9919    0.9799     25804\n",
      "           1     0.6415    0.3083    0.4165      1213\n",
      "\n",
      "    accuracy                         0.9612     27017\n",
      "   macro avg     0.8049    0.6501    0.6982     27017\n",
      "weighted avg     0.9536    0.9612    0.9546     27017\n",
      "\n",
      "Save the best overall model, configuration and partition for this experiment level\n"
     ]
    }
   ],
   "source": [
    "# CandGen Version v4 all (with extra specified negatives - all UMLS, non-UMLS, dd, dicts, NOT the ReGeX)\n",
    "\n",
    "predicted_s = train_plus(train_s_candidates, test_s_ebm_candidates, test_s_ebm_corr_candidates, Y_s, 's', paramgrid = param_grid, mode = 'pred')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1339ce33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "20ea460a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparamater Search Space: 384\n",
      "Grid search over 50 configs\n",
      "[0] Label Model\n",
      "Total number of tokens missed:  35764\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9998    0.9447    0.9715     16442\n",
      "           1     0.2910    0.9920    0.4499       376\n",
      "\n",
      "    accuracy                         0.9458     16818\n",
      "   macro avg     0.6454    0.9684    0.7107     16818\n",
      "weighted avg     0.9840    0.9458    0.9598     16818\n",
      "\n",
      "[1] Label Model\n",
      "Total number of tokens missed:  35764\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9998    0.9443    0.9713     16442\n",
      "           1     0.2894    0.9920    0.4480       376\n",
      "\n",
      "    accuracy                         0.9454     16818\n",
      "   macro avg     0.6446    0.9682    0.7097     16818\n",
      "weighted avg     0.9839    0.9454    0.9596     16818\n",
      "\n",
      "[2] Label Model\n",
      "Total number of tokens missed:  35764\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9997    0.9448    0.9715     16442\n",
      "           1     0.2909    0.9894    0.4495       376\n",
      "\n",
      "    accuracy                         0.9458     16818\n",
      "   macro avg     0.6453    0.9671    0.7105     16818\n",
      "weighted avg     0.9839    0.9458    0.9598     16818\n",
      "\n",
      "[3] Label Model\n",
      "Total number of tokens missed:  35764\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9998    0.9443    0.9713     16442\n",
      "           1     0.2894    0.9920    0.4480       376\n",
      "\n",
      "    accuracy                         0.9454     16818\n",
      "   macro avg     0.6446    0.9682    0.7097     16818\n",
      "weighted avg     0.9839    0.9454    0.9596     16818\n",
      "\n",
      "[4] Label Model\n",
      "Total number of tokens missed:  35764\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9998    0.9447    0.9715     16442\n",
      "           1     0.2910    0.9920    0.4499       376\n",
      "\n",
      "    accuracy                         0.9458     16818\n",
      "   macro avg     0.6454    0.9684    0.7107     16818\n",
      "weighted avg     0.9840    0.9458    0.9598     16818\n",
      "\n",
      "[5] Label Model\n",
      "Total number of tokens missed:  35764\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9998    0.9447    0.9715     16442\n",
      "           1     0.2910    0.9920    0.4499       376\n",
      "\n",
      "    accuracy                         0.9458     16818\n",
      "   macro avg     0.6454    0.9684    0.7107     16818\n",
      "weighted avg     0.9840    0.9458    0.9598     16818\n",
      "\n",
      "[6] Label Model\n",
      "Total number of tokens missed:  35764\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9997    0.9448    0.9715     16442\n",
      "           1     0.2909    0.9894    0.4495       376\n",
      "\n",
      "    accuracy                         0.9458     16818\n",
      "   macro avg     0.6453    0.9671    0.7105     16818\n",
      "weighted avg     0.9839    0.9458    0.9598     16818\n",
      "\n",
      "[7] Label Model\n",
      "Total number of tokens missed:  35764\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9997    0.9448    0.9715     16442\n",
      "           1     0.2909    0.9894    0.4495       376\n",
      "\n",
      "    accuracy                         0.9458     16818\n",
      "   macro avg     0.6453    0.9671    0.7105     16818\n",
      "weighted avg     0.9839    0.9458    0.9598     16818\n",
      "\n",
      "[8] Label Model\n",
      "Total number of tokens missed:  35764\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9997    0.9448    0.9715     16442\n",
      "           1     0.2909    0.9894    0.4495       376\n",
      "\n",
      "    accuracy                         0.9458     16818\n",
      "   macro avg     0.6453    0.9671    0.7105     16818\n",
      "weighted avg     0.9839    0.9458    0.9598     16818\n",
      "\n",
      "[9] Label Model\n",
      "Total number of tokens missed:  35764\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9997    0.9448    0.9715     16442\n",
      "           1     0.2909    0.9894    0.4495       376\n",
      "\n",
      "    accuracy                         0.9458     16818\n",
      "   macro avg     0.6453    0.9671    0.7105     16818\n",
      "weighted avg     0.9839    0.9458    0.9598     16818\n",
      "\n",
      "[10] Label Model\n",
      "Total number of tokens missed:  35764\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9997    0.9448    0.9715     16442\n",
      "           1     0.2909    0.9894    0.4495       376\n",
      "\n",
      "    accuracy                         0.9458     16818\n",
      "   macro avg     0.6453    0.9671    0.7105     16818\n",
      "weighted avg     0.9839    0.9458    0.9598     16818\n",
      "\n",
      "[11] Label Model\n",
      "Total number of tokens missed:  35764\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9997    0.9448    0.9715     16442\n",
      "           1     0.2909    0.9894    0.4495       376\n",
      "\n",
      "    accuracy                         0.9458     16818\n",
      "   macro avg     0.6453    0.9671    0.7105     16818\n",
      "weighted avg     0.9839    0.9458    0.9598     16818\n",
      "\n",
      "[12] Label Model\n",
      "Total number of tokens missed:  35764\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9997    0.9448    0.9715     16442\n",
      "           1     0.2909    0.9894    0.4495       376\n",
      "\n",
      "    accuracy                         0.9458     16818\n",
      "   macro avg     0.6453    0.9671    0.7105     16818\n",
      "weighted avg     0.9839    0.9458    0.9598     16818\n",
      "\n",
      "[13] Label Model\n",
      "Total number of tokens missed:  35764\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9997    0.9448    0.9715     16442\n",
      "           1     0.2909    0.9894    0.4495       376\n",
      "\n",
      "    accuracy                         0.9458     16818\n",
      "   macro avg     0.6453    0.9671    0.7105     16818\n",
      "weighted avg     0.9839    0.9458    0.9598     16818\n",
      "\n",
      "[14] Label Model\n",
      "Total number of tokens missed:  35764\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9997    0.9448    0.9715     16442\n",
      "           1     0.2909    0.9894    0.4495       376\n",
      "\n",
      "    accuracy                         0.9458     16818\n",
      "   macro avg     0.6453    0.9671    0.7105     16818\n",
      "weighted avg     0.9839    0.9458    0.9598     16818\n",
      "\n",
      "[15] Label Model\n",
      "Total number of tokens missed:  35764\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9997    0.9448    0.9715     16442\n",
      "           1     0.2909    0.9894    0.4495       376\n",
      "\n",
      "    accuracy                         0.9458     16818\n",
      "   macro avg     0.6453    0.9671    0.7105     16818\n",
      "weighted avg     0.9839    0.9458    0.9598     16818\n",
      "\n",
      "[16] Label Model\n",
      "Total number of tokens missed:  35764\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9998    0.9443    0.9713     16442\n",
      "           1     0.2894    0.9920    0.4480       376\n",
      "\n",
      "    accuracy                         0.9454     16818\n",
      "   macro avg     0.6446    0.9682    0.7097     16818\n",
      "weighted avg     0.9839    0.9454    0.9596     16818\n",
      "\n",
      "[17] Label Model\n",
      "Total number of tokens missed:  35764\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9998    0.9443    0.9713     16442\n",
      "           1     0.2894    0.9920    0.4480       376\n",
      "\n",
      "    accuracy                         0.9454     16818\n",
      "   macro avg     0.6446    0.9682    0.7097     16818\n",
      "weighted avg     0.9839    0.9454    0.9596     16818\n",
      "\n",
      "[18] Label Model\n",
      "Total number of tokens missed:  35764\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9998    0.9447    0.9715     16442\n",
      "           1     0.2910    0.9920    0.4499       376\n",
      "\n",
      "    accuracy                         0.9458     16818\n",
      "   macro avg     0.6454    0.9684    0.7107     16818\n",
      "weighted avg     0.9840    0.9458    0.9598     16818\n",
      "\n",
      "[19] Label Model\n",
      "Total number of tokens missed:  35764\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9997    0.9448    0.9715     16442\n",
      "           1     0.2909    0.9894    0.4495       376\n",
      "\n",
      "    accuracy                         0.9458     16818\n",
      "   macro avg     0.6453    0.9671    0.7105     16818\n",
      "weighted avg     0.9839    0.9458    0.9598     16818\n",
      "\n",
      "[20] Label Model\n",
      "Total number of tokens missed:  35764\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9998    0.9447    0.9715     16442\n",
      "           1     0.2910    0.9920    0.4499       376\n",
      "\n",
      "    accuracy                         0.9458     16818\n",
      "   macro avg     0.6454    0.9684    0.7107     16818\n",
      "weighted avg     0.9840    0.9458    0.9598     16818\n",
      "\n",
      "[21] Label Model\n",
      "Total number of tokens missed:  35764\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9997    0.9448    0.9715     16442\n",
      "           1     0.2909    0.9894    0.4495       376\n",
      "\n",
      "    accuracy                         0.9458     16818\n",
      "   macro avg     0.6453    0.9671    0.7105     16818\n",
      "weighted avg     0.9839    0.9458    0.9598     16818\n",
      "\n",
      "[22] Label Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of tokens missed:  35764\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9998    0.9443    0.9713     16442\n",
      "           1     0.2894    0.9920    0.4480       376\n",
      "\n",
      "    accuracy                         0.9454     16818\n",
      "   macro avg     0.6446    0.9682    0.7097     16818\n",
      "weighted avg     0.9839    0.9454    0.9596     16818\n",
      "\n",
      "[23] Label Model\n",
      "Total number of tokens missed:  35764\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9997    0.9448    0.9715     16442\n",
      "           1     0.2909    0.9894    0.4495       376\n",
      "\n",
      "    accuracy                         0.9458     16818\n",
      "   macro avg     0.6453    0.9671    0.7105     16818\n",
      "weighted avg     0.9839    0.9458    0.9598     16818\n",
      "\n",
      "[24] Label Model\n",
      "Total number of tokens missed:  35764\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9997    0.9448    0.9715     16442\n",
      "           1     0.2909    0.9894    0.4495       376\n",
      "\n",
      "    accuracy                         0.9458     16818\n",
      "   macro avg     0.6453    0.9671    0.7105     16818\n",
      "weighted avg     0.9839    0.9458    0.9598     16818\n",
      "\n",
      "[25] Label Model\n",
      "Total number of tokens missed:  35764\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9998    0.9447    0.9715     16442\n",
      "           1     0.2910    0.9920    0.4499       376\n",
      "\n",
      "    accuracy                         0.9458     16818\n",
      "   macro avg     0.6454    0.9684    0.7107     16818\n",
      "weighted avg     0.9840    0.9458    0.9598     16818\n",
      "\n",
      "[26] Label Model\n",
      "Total number of tokens missed:  35764\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9998    0.9443    0.9713     16442\n",
      "           1     0.2894    0.9920    0.4480       376\n",
      "\n",
      "    accuracy                         0.9454     16818\n",
      "   macro avg     0.6446    0.9682    0.7097     16818\n",
      "weighted avg     0.9839    0.9454    0.9596     16818\n",
      "\n",
      "[27] Label Model\n",
      "Total number of tokens missed:  35764\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9997    0.9448    0.9715     16442\n",
      "           1     0.2909    0.9894    0.4495       376\n",
      "\n",
      "    accuracy                         0.9458     16818\n",
      "   macro avg     0.6453    0.9671    0.7105     16818\n",
      "weighted avg     0.9839    0.9458    0.9598     16818\n",
      "\n",
      "[28] Label Model\n",
      "Total number of tokens missed:  35764\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9998    0.9447    0.9715     16442\n",
      "           1     0.2910    0.9920    0.4499       376\n",
      "\n",
      "    accuracy                         0.9458     16818\n",
      "   macro avg     0.6454    0.9684    0.7107     16818\n",
      "weighted avg     0.9840    0.9458    0.9598     16818\n",
      "\n",
      "[29] Label Model\n",
      "Total number of tokens missed:  35764\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9998    0.9443    0.9713     16442\n",
      "           1     0.2894    0.9920    0.4480       376\n",
      "\n",
      "    accuracy                         0.9454     16818\n",
      "   macro avg     0.6446    0.9682    0.7097     16818\n",
      "weighted avg     0.9839    0.9454    0.9596     16818\n",
      "\n",
      "[30] Label Model\n",
      "Total number of tokens missed:  35764\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9998    0.9447    0.9715     16442\n",
      "           1     0.2910    0.9920    0.4499       376\n",
      "\n",
      "    accuracy                         0.9458     16818\n",
      "   macro avg     0.6454    0.9684    0.7107     16818\n",
      "weighted avg     0.9840    0.9458    0.9598     16818\n",
      "\n",
      "[31] Label Model\n",
      "Total number of tokens missed:  35764\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9997    0.9448    0.9715     16442\n",
      "           1     0.2909    0.9894    0.4495       376\n",
      "\n",
      "    accuracy                         0.9458     16818\n",
      "   macro avg     0.6453    0.9671    0.7105     16818\n",
      "weighted avg     0.9839    0.9458    0.9598     16818\n",
      "\n",
      "[32] Label Model\n",
      "Total number of tokens missed:  35764\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9998    0.9443    0.9713     16442\n",
      "           1     0.2894    0.9920    0.4480       376\n",
      "\n",
      "    accuracy                         0.9454     16818\n",
      "   macro avg     0.6446    0.9682    0.7097     16818\n",
      "weighted avg     0.9839    0.9454    0.9596     16818\n",
      "\n",
      "[33] Label Model\n",
      "Total number of tokens missed:  35764\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9998    0.9447    0.9715     16442\n",
      "           1     0.2910    0.9920    0.4499       376\n",
      "\n",
      "    accuracy                         0.9458     16818\n",
      "   macro avg     0.6454    0.9684    0.7107     16818\n",
      "weighted avg     0.9840    0.9458    0.9598     16818\n",
      "\n",
      "[34] Label Model\n",
      "Total number of tokens missed:  35764\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9998    0.9447    0.9715     16442\n",
      "           1     0.2910    0.9920    0.4499       376\n",
      "\n",
      "    accuracy                         0.9458     16818\n",
      "   macro avg     0.6454    0.9684    0.7107     16818\n",
      "weighted avg     0.9840    0.9458    0.9598     16818\n",
      "\n",
      "[35] Label Model\n",
      "Total number of tokens missed:  35764\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9997    0.9448    0.9715     16442\n",
      "           1     0.2909    0.9894    0.4495       376\n",
      "\n",
      "    accuracy                         0.9458     16818\n",
      "   macro avg     0.6453    0.9671    0.7105     16818\n",
      "weighted avg     0.9839    0.9458    0.9598     16818\n",
      "\n",
      "[36] Label Model\n",
      "Total number of tokens missed:  35764\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9998    0.9443    0.9713     16442\n",
      "           1     0.2894    0.9920    0.4480       376\n",
      "\n",
      "    accuracy                         0.9454     16818\n",
      "   macro avg     0.6446    0.9682    0.7097     16818\n",
      "weighted avg     0.9839    0.9454    0.9596     16818\n",
      "\n",
      "[37] Label Model\n",
      "Total number of tokens missed:  35764\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9998    0.9446    0.9714     16442\n",
      "           1     0.2905    0.9920    0.4494       376\n",
      "\n",
      "    accuracy                         0.9457     16818\n",
      "   macro avg     0.6452    0.9683    0.7104     16818\n",
      "weighted avg     0.9839    0.9457    0.9597     16818\n",
      "\n",
      "[38] Label Model\n",
      "Total number of tokens missed:  35764\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9998    0.9443    0.9713     16442\n",
      "           1     0.2894    0.9920    0.4480       376\n",
      "\n",
      "    accuracy                         0.9454     16818\n",
      "   macro avg     0.6446    0.9682    0.7097     16818\n",
      "weighted avg     0.9839    0.9454    0.9596     16818\n",
      "\n",
      "[39] Label Model\n",
      "Total number of tokens missed:  35764\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9998    0.9443    0.9713     16442\n",
      "           1     0.2894    0.9920    0.4480       376\n",
      "\n",
      "    accuracy                         0.9454     16818\n",
      "   macro avg     0.6446    0.9682    0.7097     16818\n",
      "weighted avg     0.9839    0.9454    0.9596     16818\n",
      "\n",
      "[40] Label Model\n",
      "Total number of tokens missed:  35764\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9997    0.9448    0.9715     16442\n",
      "           1     0.2909    0.9894    0.4495       376\n",
      "\n",
      "    accuracy                         0.9458     16818\n",
      "   macro avg     0.6453    0.9671    0.7105     16818\n",
      "weighted avg     0.9839    0.9458    0.9598     16818\n",
      "\n",
      "[41] Label Model\n",
      "Total number of tokens missed:  35764\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9998    0.9443    0.9713     16442\n",
      "           1     0.2894    0.9920    0.4480       376\n",
      "\n",
      "    accuracy                         0.9454     16818\n",
      "   macro avg     0.6446    0.9682    0.7097     16818\n",
      "weighted avg     0.9839    0.9454    0.9596     16818\n",
      "\n",
      "[42] Label Model\n",
      "Total number of tokens missed:  35764\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9998    0.9447    0.9715     16442\n",
      "           1     0.2910    0.9920    0.4499       376\n",
      "\n",
      "    accuracy                         0.9458     16818\n",
      "   macro avg     0.6454    0.9684    0.7107     16818\n",
      "weighted avg     0.9840    0.9458    0.9598     16818\n",
      "\n",
      "[43] Label Model\n",
      "Total number of tokens missed:  35764\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9997    0.9448    0.9715     16442\n",
      "           1     0.2909    0.9894    0.4495       376\n",
      "\n",
      "    accuracy                         0.9458     16818\n",
      "   macro avg     0.6453    0.9671    0.7105     16818\n",
      "weighted avg     0.9839    0.9458    0.9598     16818\n",
      "\n",
      "[44] Label Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of tokens missed:  35764\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9997    0.9448    0.9715     16442\n",
      "           1     0.2909    0.9894    0.4495       376\n",
      "\n",
      "    accuracy                         0.9458     16818\n",
      "   macro avg     0.6453    0.9671    0.7105     16818\n",
      "weighted avg     0.9839    0.9458    0.9598     16818\n",
      "\n",
      "[45] Label Model\n",
      "Total number of tokens missed:  35764\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9997    0.9448    0.9715     16442\n",
      "           1     0.2909    0.9894    0.4495       376\n",
      "\n",
      "    accuracy                         0.9458     16818\n",
      "   macro avg     0.6453    0.9671    0.7105     16818\n",
      "weighted avg     0.9839    0.9458    0.9598     16818\n",
      "\n",
      "[46] Label Model\n",
      "Total number of tokens missed:  35764\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9997    0.9448    0.9715     16442\n",
      "           1     0.2909    0.9894    0.4495       376\n",
      "\n",
      "    accuracy                         0.9458     16818\n",
      "   macro avg     0.6453    0.9671    0.7105     16818\n",
      "weighted avg     0.9839    0.9458    0.9598     16818\n",
      "\n",
      "[47] Label Model\n",
      "Total number of tokens missed:  35764\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9997    0.9448    0.9715     16442\n",
      "           1     0.2909    0.9894    0.4495       376\n",
      "\n",
      "    accuracy                         0.9458     16818\n",
      "   macro avg     0.6453    0.9671    0.7105     16818\n",
      "weighted avg     0.9839    0.9458    0.9598     16818\n",
      "\n",
      "[48] Label Model\n",
      "Total number of tokens missed:  35764\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9998    0.9443    0.9713     16442\n",
      "           1     0.2894    0.9920    0.4480       376\n",
      "\n",
      "    accuracy                         0.9454     16818\n",
      "   macro avg     0.6446    0.9682    0.7097     16818\n",
      "weighted avg     0.9839    0.9454    0.9596     16818\n",
      "\n",
      "[49] Label Model\n",
      "Total number of tokens missed:  35764\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9998    0.9446    0.9714     16442\n",
      "           1     0.2905    0.9920    0.4494       376\n",
      "\n",
      "    accuracy                         0.9457     16818\n",
      "   macro avg     0.6452    0.9683    0.7104     16818\n",
      "weighted avg     0.9839    0.9457    0.9597     16818\n",
      "\n",
      "Save the best overall model, configuration and partition for this experiment level\n"
     ]
    }
   ],
   "source": [
    "# CandGen Version v3 all\n",
    "\n",
    "predicted_s = train_plus(train_s_candidates, test_s_ebm_candidates, test_s_ebm_corr_candidates, Y_s, 's', paramgrid = param_grid, mode = 'pred')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "624f2abc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88aadf74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "8f5b6b40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparamater Search Space: 384\n",
      "Grid search over 50 configs\n",
      "[0] Label Model\n",
      "Total number of tokens missed:  35850\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9998    0.9493    0.9739     16362\n",
      "           1     0.3069    0.9919    0.4687       370\n",
      "\n",
      "    accuracy                         0.9503     16732\n",
      "   macro avg     0.6533    0.9706    0.7213     16732\n",
      "weighted avg     0.9845    0.9503    0.9627     16732\n",
      "\n",
      "[1] Label Model\n",
      "Total number of tokens missed:  35850\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9998    0.9492    0.9739     16362\n",
      "           1     0.3063    0.9919    0.4681       370\n",
      "\n",
      "    accuracy                         0.9502     16732\n",
      "   macro avg     0.6531    0.9706    0.7210     16732\n",
      "weighted avg     0.9845    0.9502    0.9627     16732\n",
      "\n",
      "[2] Label Model\n",
      "Total number of tokens missed:  35850\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9997    0.9495    0.9740     16362\n",
      "           1     0.3068    0.9892    0.4683       370\n",
      "\n",
      "    accuracy                         0.9503     16732\n",
      "   macro avg     0.6533    0.9693    0.7211     16732\n",
      "weighted avg     0.9844    0.9503    0.9628     16732\n",
      "\n",
      "[3] Label Model\n",
      "Total number of tokens missed:  35850\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9998    0.9492    0.9739     16362\n",
      "           1     0.3063    0.9919    0.4681       370\n",
      "\n",
      "    accuracy                         0.9502     16732\n",
      "   macro avg     0.6531    0.9706    0.7210     16732\n",
      "weighted avg     0.9845    0.9502    0.9627     16732\n",
      "\n",
      "[4] Label Model\n",
      "Total number of tokens missed:  35850\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9998    0.9493    0.9739     16362\n",
      "           1     0.3069    0.9919    0.4687       370\n",
      "\n",
      "    accuracy                         0.9503     16732\n",
      "   macro avg     0.6533    0.9706    0.7213     16732\n",
      "weighted avg     0.9845    0.9503    0.9627     16732\n",
      "\n",
      "[5] Label Model\n",
      "Total number of tokens missed:  35850\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9998    0.9493    0.9739     16362\n",
      "           1     0.3069    0.9919    0.4687       370\n",
      "\n",
      "    accuracy                         0.9503     16732\n",
      "   macro avg     0.6533    0.9706    0.7213     16732\n",
      "weighted avg     0.9845    0.9503    0.9627     16732\n",
      "\n",
      "[6] Label Model\n",
      "Total number of tokens missed:  35850\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9997    0.9495    0.9740     16362\n",
      "           1     0.3068    0.9892    0.4683       370\n",
      "\n",
      "    accuracy                         0.9503     16732\n",
      "   macro avg     0.6533    0.9693    0.7211     16732\n",
      "weighted avg     0.9844    0.9503    0.9628     16732\n",
      "\n",
      "[7] Label Model\n",
      "Total number of tokens missed:  35850\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9997    0.9495    0.9740     16362\n",
      "           1     0.3068    0.9892    0.4683       370\n",
      "\n",
      "    accuracy                         0.9503     16732\n",
      "   macro avg     0.6533    0.9693    0.7211     16732\n",
      "weighted avg     0.9844    0.9503    0.9628     16732\n",
      "\n",
      "[8] Label Model\n",
      "Total number of tokens missed:  35850\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9997    0.9495    0.9740     16362\n",
      "           1     0.3068    0.9892    0.4683       370\n",
      "\n",
      "    accuracy                         0.9503     16732\n",
      "   macro avg     0.6533    0.9693    0.7211     16732\n",
      "weighted avg     0.9844    0.9503    0.9628     16732\n",
      "\n",
      "[9] Label Model\n",
      "Total number of tokens missed:  35850\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9997    0.9495    0.9740     16362\n",
      "           1     0.3068    0.9892    0.4683       370\n",
      "\n",
      "    accuracy                         0.9503     16732\n",
      "   macro avg     0.6533    0.9693    0.7211     16732\n",
      "weighted avg     0.9844    0.9503    0.9628     16732\n",
      "\n",
      "[10] Label Model\n",
      "Total number of tokens missed:  35850\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9997    0.9495    0.9740     16362\n",
      "           1     0.3068    0.9892    0.4683       370\n",
      "\n",
      "    accuracy                         0.9503     16732\n",
      "   macro avg     0.6533    0.9693    0.7211     16732\n",
      "weighted avg     0.9844    0.9503    0.9628     16732\n",
      "\n",
      "[11] Label Model\n",
      "Total number of tokens missed:  35850\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9997    0.9495    0.9740     16362\n",
      "           1     0.3068    0.9892    0.4683       370\n",
      "\n",
      "    accuracy                         0.9503     16732\n",
      "   macro avg     0.6533    0.9693    0.7211     16732\n",
      "weighted avg     0.9844    0.9503    0.9628     16732\n",
      "\n",
      "[12] Label Model\n",
      "Total number of tokens missed:  35850\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9997    0.9495    0.9740     16362\n",
      "           1     0.3068    0.9892    0.4683       370\n",
      "\n",
      "    accuracy                         0.9503     16732\n",
      "   macro avg     0.6533    0.9693    0.7211     16732\n",
      "weighted avg     0.9844    0.9503    0.9628     16732\n",
      "\n",
      "[13] Label Model\n",
      "Total number of tokens missed:  35850\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9997    0.9495    0.9740     16362\n",
      "           1     0.3068    0.9892    0.4683       370\n",
      "\n",
      "    accuracy                         0.9503     16732\n",
      "   macro avg     0.6533    0.9693    0.7211     16732\n",
      "weighted avg     0.9844    0.9503    0.9628     16732\n",
      "\n",
      "[14] Label Model\n",
      "Total number of tokens missed:  35850\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9997    0.9495    0.9740     16362\n",
      "           1     0.3068    0.9892    0.4683       370\n",
      "\n",
      "    accuracy                         0.9503     16732\n",
      "   macro avg     0.6533    0.9693    0.7211     16732\n",
      "weighted avg     0.9844    0.9503    0.9628     16732\n",
      "\n",
      "[15] Label Model\n",
      "Total number of tokens missed:  35850\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9997    0.9495    0.9740     16362\n",
      "           1     0.3068    0.9892    0.4683       370\n",
      "\n",
      "    accuracy                         0.9503     16732\n",
      "   macro avg     0.6533    0.9693    0.7211     16732\n",
      "weighted avg     0.9844    0.9503    0.9628     16732\n",
      "\n",
      "[16] Label Model\n",
      "Total number of tokens missed:  35850\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9998    0.9492    0.9739     16362\n",
      "           1     0.3063    0.9919    0.4681       370\n",
      "\n",
      "    accuracy                         0.9502     16732\n",
      "   macro avg     0.6531    0.9706    0.7210     16732\n",
      "weighted avg     0.9845    0.9502    0.9627     16732\n",
      "\n",
      "[17] Label Model\n",
      "Total number of tokens missed:  35850\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9998    0.9492    0.9739     16362\n",
      "           1     0.3063    0.9919    0.4681       370\n",
      "\n",
      "    accuracy                         0.9502     16732\n",
      "   macro avg     0.6531    0.9706    0.7210     16732\n",
      "weighted avg     0.9845    0.9502    0.9627     16732\n",
      "\n",
      "[18] Label Model\n",
      "Total number of tokens missed:  35850\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9998    0.9493    0.9739     16362\n",
      "           1     0.3069    0.9919    0.4687       370\n",
      "\n",
      "    accuracy                         0.9503     16732\n",
      "   macro avg     0.6533    0.9706    0.7213     16732\n",
      "weighted avg     0.9845    0.9503    0.9627     16732\n",
      "\n",
      "[19] Label Model\n",
      "Total number of tokens missed:  35850\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9997    0.9495    0.9740     16362\n",
      "           1     0.3068    0.9892    0.4683       370\n",
      "\n",
      "    accuracy                         0.9503     16732\n",
      "   macro avg     0.6533    0.9693    0.7211     16732\n",
      "weighted avg     0.9844    0.9503    0.9628     16732\n",
      "\n",
      "[20] Label Model\n",
      "Total number of tokens missed:  35850\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9998    0.9493    0.9739     16362\n",
      "           1     0.3069    0.9919    0.4687       370\n",
      "\n",
      "    accuracy                         0.9503     16732\n",
      "   macro avg     0.6533    0.9706    0.7213     16732\n",
      "weighted avg     0.9845    0.9503    0.9627     16732\n",
      "\n",
      "[21] Label Model\n",
      "Total number of tokens missed:  35850\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9997    0.9495    0.9740     16362\n",
      "           1     0.3068    0.9892    0.4683       370\n",
      "\n",
      "    accuracy                         0.9503     16732\n",
      "   macro avg     0.6533    0.9693    0.7211     16732\n",
      "weighted avg     0.9844    0.9503    0.9628     16732\n",
      "\n",
      "[22] Label Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of tokens missed:  35850\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9998    0.9492    0.9739     16362\n",
      "           1     0.3063    0.9919    0.4681       370\n",
      "\n",
      "    accuracy                         0.9502     16732\n",
      "   macro avg     0.6531    0.9706    0.7210     16732\n",
      "weighted avg     0.9845    0.9502    0.9627     16732\n",
      "\n",
      "[23] Label Model\n",
      "Total number of tokens missed:  35850\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9997    0.9495    0.9740     16362\n",
      "           1     0.3068    0.9892    0.4683       370\n",
      "\n",
      "    accuracy                         0.9503     16732\n",
      "   macro avg     0.6533    0.9693    0.7211     16732\n",
      "weighted avg     0.9844    0.9503    0.9628     16732\n",
      "\n",
      "[24] Label Model\n",
      "Total number of tokens missed:  35850\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9997    0.9495    0.9740     16362\n",
      "           1     0.3068    0.9892    0.4683       370\n",
      "\n",
      "    accuracy                         0.9503     16732\n",
      "   macro avg     0.6533    0.9693    0.7211     16732\n",
      "weighted avg     0.9844    0.9503    0.9628     16732\n",
      "\n",
      "[25] Label Model\n",
      "Total number of tokens missed:  35850\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9998    0.9493    0.9739     16362\n",
      "           1     0.3069    0.9919    0.4687       370\n",
      "\n",
      "    accuracy                         0.9503     16732\n",
      "   macro avg     0.6533    0.9706    0.7213     16732\n",
      "weighted avg     0.9845    0.9503    0.9627     16732\n",
      "\n",
      "[26] Label Model\n",
      "Total number of tokens missed:  35850\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9998    0.9492    0.9739     16362\n",
      "           1     0.3063    0.9919    0.4681       370\n",
      "\n",
      "    accuracy                         0.9502     16732\n",
      "   macro avg     0.6531    0.9706    0.7210     16732\n",
      "weighted avg     0.9845    0.9502    0.9627     16732\n",
      "\n",
      "[27] Label Model\n",
      "Total number of tokens missed:  35850\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9997    0.9495    0.9740     16362\n",
      "           1     0.3068    0.9892    0.4683       370\n",
      "\n",
      "    accuracy                         0.9503     16732\n",
      "   macro avg     0.6533    0.9693    0.7211     16732\n",
      "weighted avg     0.9844    0.9503    0.9628     16732\n",
      "\n",
      "[28] Label Model\n",
      "Total number of tokens missed:  35850\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9998    0.9493    0.9739     16362\n",
      "           1     0.3069    0.9919    0.4687       370\n",
      "\n",
      "    accuracy                         0.9503     16732\n",
      "   macro avg     0.6533    0.9706    0.7213     16732\n",
      "weighted avg     0.9845    0.9503    0.9627     16732\n",
      "\n",
      "[29] Label Model\n",
      "Total number of tokens missed:  35850\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9998    0.9492    0.9739     16362\n",
      "           1     0.3063    0.9919    0.4681       370\n",
      "\n",
      "    accuracy                         0.9502     16732\n",
      "   macro avg     0.6531    0.9706    0.7210     16732\n",
      "weighted avg     0.9845    0.9502    0.9627     16732\n",
      "\n",
      "[30] Label Model\n",
      "Total number of tokens missed:  35850\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9998    0.9493    0.9739     16362\n",
      "           1     0.3069    0.9919    0.4687       370\n",
      "\n",
      "    accuracy                         0.9503     16732\n",
      "   macro avg     0.6533    0.9706    0.7213     16732\n",
      "weighted avg     0.9845    0.9503    0.9627     16732\n",
      "\n",
      "[31] Label Model\n",
      "Total number of tokens missed:  35850\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9997    0.9495    0.9740     16362\n",
      "           1     0.3068    0.9892    0.4683       370\n",
      "\n",
      "    accuracy                         0.9503     16732\n",
      "   macro avg     0.6533    0.9693    0.7211     16732\n",
      "weighted avg     0.9844    0.9503    0.9628     16732\n",
      "\n",
      "[32] Label Model\n",
      "Total number of tokens missed:  35850\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9998    0.9492    0.9739     16362\n",
      "           1     0.3063    0.9919    0.4681       370\n",
      "\n",
      "    accuracy                         0.9502     16732\n",
      "   macro avg     0.6531    0.9706    0.7210     16732\n",
      "weighted avg     0.9845    0.9502    0.9627     16732\n",
      "\n",
      "[33] Label Model\n",
      "Total number of tokens missed:  35850\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9998    0.9493    0.9739     16362\n",
      "           1     0.3069    0.9919    0.4687       370\n",
      "\n",
      "    accuracy                         0.9503     16732\n",
      "   macro avg     0.6533    0.9706    0.7213     16732\n",
      "weighted avg     0.9845    0.9503    0.9627     16732\n",
      "\n",
      "[34] Label Model\n",
      "Total number of tokens missed:  35850\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9998    0.9493    0.9739     16362\n",
      "           1     0.3069    0.9919    0.4687       370\n",
      "\n",
      "    accuracy                         0.9503     16732\n",
      "   macro avg     0.6533    0.9706    0.7213     16732\n",
      "weighted avg     0.9845    0.9503    0.9627     16732\n",
      "\n",
      "[35] Label Model\n",
      "Total number of tokens missed:  35850\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9997    0.9495    0.9740     16362\n",
      "           1     0.3068    0.9892    0.4683       370\n",
      "\n",
      "    accuracy                         0.9503     16732\n",
      "   macro avg     0.6533    0.9693    0.7211     16732\n",
      "weighted avg     0.9844    0.9503    0.9628     16732\n",
      "\n",
      "[36] Label Model\n",
      "Total number of tokens missed:  35850\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9998    0.9492    0.9739     16362\n",
      "           1     0.3063    0.9919    0.4681       370\n",
      "\n",
      "    accuracy                         0.9502     16732\n",
      "   macro avg     0.6531    0.9706    0.7210     16732\n",
      "weighted avg     0.9845    0.9502    0.9627     16732\n",
      "\n",
      "[37] Label Model\n",
      "Total number of tokens missed:  35850\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9998    0.9492    0.9739     16362\n",
      "           1     0.3063    0.9919    0.4681       370\n",
      "\n",
      "    accuracy                         0.9502     16732\n",
      "   macro avg     0.6531    0.9706    0.7210     16732\n",
      "weighted avg     0.9845    0.9502    0.9627     16732\n",
      "\n",
      "[38] Label Model\n",
      "Total number of tokens missed:  35850\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9998    0.9492    0.9739     16362\n",
      "           1     0.3063    0.9919    0.4681       370\n",
      "\n",
      "    accuracy                         0.9502     16732\n",
      "   macro avg     0.6531    0.9706    0.7210     16732\n",
      "weighted avg     0.9845    0.9502    0.9627     16732\n",
      "\n",
      "[39] Label Model\n",
      "Total number of tokens missed:  35850\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9998    0.9492    0.9739     16362\n",
      "           1     0.3063    0.9919    0.4681       370\n",
      "\n",
      "    accuracy                         0.9502     16732\n",
      "   macro avg     0.6531    0.9706    0.7210     16732\n",
      "weighted avg     0.9845    0.9502    0.9627     16732\n",
      "\n",
      "[40] Label Model\n",
      "Total number of tokens missed:  35850\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9997    0.9495    0.9740     16362\n",
      "           1     0.3068    0.9892    0.4683       370\n",
      "\n",
      "    accuracy                         0.9503     16732\n",
      "   macro avg     0.6533    0.9693    0.7211     16732\n",
      "weighted avg     0.9844    0.9503    0.9628     16732\n",
      "\n",
      "[41] Label Model\n",
      "Total number of tokens missed:  35850\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9998    0.9492    0.9739     16362\n",
      "           1     0.3063    0.9919    0.4681       370\n",
      "\n",
      "    accuracy                         0.9502     16732\n",
      "   macro avg     0.6531    0.9706    0.7210     16732\n",
      "weighted avg     0.9845    0.9502    0.9627     16732\n",
      "\n",
      "[42] Label Model\n",
      "Total number of tokens missed:  35850\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9998    0.9493    0.9739     16362\n",
      "           1     0.3069    0.9919    0.4687       370\n",
      "\n",
      "    accuracy                         0.9503     16732\n",
      "   macro avg     0.6533    0.9706    0.7213     16732\n",
      "weighted avg     0.9845    0.9503    0.9627     16732\n",
      "\n",
      "[43] Label Model\n",
      "Total number of tokens missed:  35850\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9997    0.9495    0.9740     16362\n",
      "           1     0.3068    0.9892    0.4683       370\n",
      "\n",
      "    accuracy                         0.9503     16732\n",
      "   macro avg     0.6533    0.9693    0.7211     16732\n",
      "weighted avg     0.9844    0.9503    0.9628     16732\n",
      "\n",
      "[44] Label Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of tokens missed:  35850\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9997    0.9495    0.9740     16362\n",
      "           1     0.3068    0.9892    0.4683       370\n",
      "\n",
      "    accuracy                         0.9503     16732\n",
      "   macro avg     0.6533    0.9693    0.7211     16732\n",
      "weighted avg     0.9844    0.9503    0.9628     16732\n",
      "\n",
      "[45] Label Model\n",
      "Total number of tokens missed:  35850\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9997    0.9495    0.9740     16362\n",
      "           1     0.3068    0.9892    0.4683       370\n",
      "\n",
      "    accuracy                         0.9503     16732\n",
      "   macro avg     0.6533    0.9693    0.7211     16732\n",
      "weighted avg     0.9844    0.9503    0.9628     16732\n",
      "\n",
      "[46] Label Model\n",
      "Total number of tokens missed:  35850\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9997    0.9495    0.9740     16362\n",
      "           1     0.3068    0.9892    0.4683       370\n",
      "\n",
      "    accuracy                         0.9503     16732\n",
      "   macro avg     0.6533    0.9693    0.7211     16732\n",
      "weighted avg     0.9844    0.9503    0.9628     16732\n",
      "\n",
      "[47] Label Model\n",
      "Total number of tokens missed:  35850\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9997    0.9495    0.9740     16362\n",
      "           1     0.3068    0.9892    0.4683       370\n",
      "\n",
      "    accuracy                         0.9503     16732\n",
      "   macro avg     0.6533    0.9693    0.7211     16732\n",
      "weighted avg     0.9844    0.9503    0.9628     16732\n",
      "\n",
      "[48] Label Model\n",
      "Total number of tokens missed:  35850\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9998    0.9492    0.9739     16362\n",
      "           1     0.3063    0.9919    0.4681       370\n",
      "\n",
      "    accuracy                         0.9502     16732\n",
      "   macro avg     0.6531    0.9706    0.7210     16732\n",
      "weighted avg     0.9845    0.9502    0.9627     16732\n",
      "\n",
      "[49] Label Model\n",
      "Total number of tokens missed:  35850\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9998    0.9492    0.9739     16362\n",
      "           1     0.3063    0.9919    0.4681       370\n",
      "\n",
      "    accuracy                         0.9502     16732\n",
      "   macro avg     0.6531    0.9706    0.7210     16732\n",
      "weighted avg     0.9845    0.9502    0.9627     16732\n",
      "\n",
      "Save the best overall model, configuration and partition for this experiment level\n"
     ]
    }
   ],
   "source": [
    "# CandGen Version v3 (removed heur_pattern and heur_pattern_2)\n",
    "\n",
    "predicted_s = train_plus(train_s_candidates, test_s_ebm_candidates, test_s_ebm_corr_candidates, Y_s, 's', paramgrid = param_grid, mode = 'pred')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e95cb0dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c142d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18732d76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b7c460",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec3061c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933b2d94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65e0842",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "d4327cb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparamater Search Space: 336\n",
      "Grid search over 50 configs\n",
      "[0] Label Model\n",
      "Total number of tokens missed:  50714\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9811    0.0357    0.0690      1455\n",
      "           1     0.2270    0.9976    0.3698       413\n",
      "\n",
      "    accuracy                         0.2484      1868\n",
      "   macro avg     0.6041    0.5167    0.2194      1868\n",
      "weighted avg     0.8144    0.2484    0.1355      1868\n",
      "\n",
      "[1] Label Model\n",
      "Total number of tokens missed:  50714\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9811    0.0357    0.0690      1455\n",
      "           1     0.2270    0.9976    0.3698       413\n",
      "\n",
      "    accuracy                         0.2484      1868\n",
      "   macro avg     0.6041    0.5167    0.2194      1868\n",
      "weighted avg     0.8144    0.2484    0.1355      1868\n",
      "\n",
      "[2] Label Model\n",
      "Total number of tokens missed:  50714\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000      1455\n",
      "           1     0.2211    1.0000    0.3621       413\n",
      "\n",
      "    accuracy                         0.2211      1868\n",
      "   macro avg     0.1105    0.5000    0.1811      1868\n",
      "weighted avg     0.0489    0.2211    0.0801      1868\n",
      "\n",
      "[3] Label Model\n",
      "Total number of tokens missed:  50714\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000      1455\n",
      "           1     0.2211    1.0000    0.3621       413\n",
      "\n",
      "    accuracy                         0.2211      1868\n",
      "   macro avg     0.1105    0.5000    0.1811      1868\n",
      "weighted avg     0.0489    0.2211    0.0801      1868\n",
      "\n",
      "[4] Label Model\n",
      "Total number of tokens missed:  50714\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000      1455\n",
      "           1     0.2207    0.9976    0.3614       413\n",
      "\n",
      "    accuracy                         0.2206      1868\n",
      "   macro avg     0.1103    0.4988    0.1807      1868\n",
      "weighted avg     0.0488    0.2206    0.0799      1868\n",
      "\n",
      "[5] Label Model\n",
      "Total number of tokens missed:  50714\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9811    0.0357    0.0690      1455\n",
      "           1     0.2270    0.9976    0.3698       413\n",
      "\n",
      "    accuracy                         0.2484      1868\n",
      "   macro avg     0.6041    0.5167    0.2194      1868\n",
      "weighted avg     0.8144    0.2484    0.1355      1868\n",
      "\n",
      "[6] Label Model\n",
      "Total number of tokens missed:  50714\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000      1455\n",
      "           1     0.2211    1.0000    0.3621       413\n",
      "\n",
      "    accuracy                         0.2211      1868\n",
      "   macro avg     0.1105    0.5000    0.1811      1868\n",
      "weighted avg     0.0489    0.2211    0.0801      1868\n",
      "\n",
      "[7] Label Model\n",
      "Total number of tokens missed:  50714\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000      1455\n",
      "           1     0.2211    1.0000    0.3621       413\n",
      "\n",
      "    accuracy                         0.2211      1868\n",
      "   macro avg     0.1105    0.5000    0.1811      1868\n",
      "weighted avg     0.0489    0.2211    0.0801      1868\n",
      "\n",
      "[8] Label Model\n",
      "Total number of tokens missed:  50714\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9811    0.0357    0.0690      1455\n",
      "           1     0.2270    0.9976    0.3698       413\n",
      "\n",
      "    accuracy                         0.2484      1868\n",
      "   macro avg     0.6041    0.5167    0.2194      1868\n",
      "weighted avg     0.8144    0.2484    0.1355      1868\n",
      "\n",
      "[9] Label Model\n",
      "Total number of tokens missed:  50714\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000      1455\n",
      "           1     0.2211    1.0000    0.3621       413\n",
      "\n",
      "    accuracy                         0.2211      1868\n",
      "   macro avg     0.1105    0.5000    0.1811      1868\n",
      "weighted avg     0.0489    0.2211    0.0801      1868\n",
      "\n",
      "[10] Label Model\n",
      "Total number of tokens missed:  50714\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000      1455\n",
      "           1     0.2211    1.0000    0.3621       413\n",
      "\n",
      "    accuracy                         0.2211      1868\n",
      "   macro avg     0.1105    0.5000    0.1811      1868\n",
      "weighted avg     0.0489    0.2211    0.0801      1868\n",
      "\n",
      "[11] Label Model\n",
      "Total number of tokens missed:  50714\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9811    0.0357    0.0690      1455\n",
      "           1     0.2270    0.9976    0.3698       413\n",
      "\n",
      "    accuracy                         0.2484      1868\n",
      "   macro avg     0.6041    0.5167    0.2194      1868\n",
      "weighted avg     0.8144    0.2484    0.1355      1868\n",
      "\n",
      "[12] Label Model\n",
      "Total number of tokens missed:  50714\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9811    0.0357    0.0690      1455\n",
      "           1     0.2270    0.9976    0.3698       413\n",
      "\n",
      "    accuracy                         0.2484      1868\n",
      "   macro avg     0.6041    0.5167    0.2194      1868\n",
      "weighted avg     0.8144    0.2484    0.1355      1868\n",
      "\n",
      "[13] Label Model\n",
      "Total number of tokens missed:  50714\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000      1455\n",
      "           1     0.2207    0.9976    0.3614       413\n",
      "\n",
      "    accuracy                         0.2206      1868\n",
      "   macro avg     0.1103    0.4988    0.1807      1868\n",
      "weighted avg     0.0488    0.2206    0.0799      1868\n",
      "\n",
      "[14] Label Model\n",
      "Total number of tokens missed:  50714\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000      1455\n",
      "           1     0.2207    0.9976    0.3614       413\n",
      "\n",
      "    accuracy                         0.2206      1868\n",
      "   macro avg     0.1103    0.4988    0.1807      1868\n",
      "weighted avg     0.0488    0.2206    0.0799      1868\n",
      "\n",
      "[15] Label Model\n",
      "Total number of tokens missed:  50714\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9811    0.0357    0.0690      1455\n",
      "           1     0.2270    0.9976    0.3698       413\n",
      "\n",
      "    accuracy                         0.2484      1868\n",
      "   macro avg     0.6041    0.5167    0.2194      1868\n",
      "weighted avg     0.8144    0.2484    0.1355      1868\n",
      "\n",
      "[16] Label Model\n",
      "Total number of tokens missed:  50714\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000      1455\n",
      "           1     0.2211    1.0000    0.3621       413\n",
      "\n",
      "    accuracy                         0.2211      1868\n",
      "   macro avg     0.1105    0.5000    0.1811      1868\n",
      "weighted avg     0.0489    0.2211    0.0801      1868\n",
      "\n",
      "[17] Label Model\n",
      "Total number of tokens missed:  50714\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000      1455\n",
      "           1     0.2211    1.0000    0.3621       413\n",
      "\n",
      "    accuracy                         0.2211      1868\n",
      "   macro avg     0.1105    0.5000    0.1811      1868\n",
      "weighted avg     0.0489    0.2211    0.0801      1868\n",
      "\n",
      "[18] Label Model\n",
      "Total number of tokens missed:  50714\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000      1455\n",
      "           1     0.2207    0.9976    0.3614       413\n",
      "\n",
      "    accuracy                         0.2206      1868\n",
      "   macro avg     0.1103    0.4988    0.1807      1868\n",
      "weighted avg     0.0488    0.2206    0.0799      1868\n",
      "\n",
      "[19] Label Model\n",
      "Total number of tokens missed:  50714\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9811    0.0357    0.0690      1455\n",
      "           1     0.2270    0.9976    0.3698       413\n",
      "\n",
      "    accuracy                         0.2484      1868\n",
      "   macro avg     0.6041    0.5167    0.2194      1868\n",
      "weighted avg     0.8144    0.2484    0.1355      1868\n",
      "\n",
      "[20] Label Model\n",
      "Total number of tokens missed:  50714\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000      1455\n",
      "           1     0.2203    0.9952    0.3607       413\n",
      "\n",
      "    accuracy                         0.2200      1868\n",
      "   macro avg     0.1101    0.4976    0.1803      1868\n",
      "weighted avg     0.0487    0.2200    0.0797      1868\n",
      "\n",
      "[21] Label Model\n",
      "Total number of tokens missed:  50714\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000      1455\n",
      "           1     0.2207    0.9976    0.3614       413\n",
      "\n",
      "    accuracy                         0.2206      1868\n",
      "   macro avg     0.1103    0.4988    0.1807      1868\n",
      "weighted avg     0.0488    0.2206    0.0799      1868\n",
      "\n",
      "[22] Label Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of tokens missed:  50714\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000      1455\n",
      "           1     0.2211    1.0000    0.3621       413\n",
      "\n",
      "    accuracy                         0.2211      1868\n",
      "   macro avg     0.1105    0.5000    0.1811      1868\n",
      "weighted avg     0.0489    0.2211    0.0801      1868\n",
      "\n",
      "[23] Label Model\n",
      "Total number of tokens missed:  50714\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000      1455\n",
      "           1     0.2207    0.9976    0.3614       413\n",
      "\n",
      "    accuracy                         0.2206      1868\n",
      "   macro avg     0.1103    0.4988    0.1807      1868\n",
      "weighted avg     0.0488    0.2206    0.0799      1868\n",
      "\n",
      "[24] Label Model\n",
      "Total number of tokens missed:  50714\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000      1455\n",
      "           1     0.2211    1.0000    0.3621       413\n",
      "\n",
      "    accuracy                         0.2211      1868\n",
      "   macro avg     0.1105    0.5000    0.1811      1868\n",
      "weighted avg     0.0489    0.2211    0.0801      1868\n",
      "\n",
      "[25] Label Model\n",
      "Total number of tokens missed:  50714\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000      1455\n",
      "           1     0.2203    0.9952    0.3607       413\n",
      "\n",
      "    accuracy                         0.2200      1868\n",
      "   macro avg     0.1101    0.4976    0.1803      1868\n",
      "weighted avg     0.0487    0.2200    0.0797      1868\n",
      "\n",
      "[26] Label Model\n",
      "Total number of tokens missed:  50714\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000      1455\n",
      "           1     0.2211    1.0000    0.3621       413\n",
      "\n",
      "    accuracy                         0.2211      1868\n",
      "   macro avg     0.1105    0.5000    0.1811      1868\n",
      "weighted avg     0.0489    0.2211    0.0801      1868\n",
      "\n",
      "[27] Label Model\n",
      "Total number of tokens missed:  50714\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9811    0.0357    0.0690      1455\n",
      "           1     0.2270    0.9976    0.3698       413\n",
      "\n",
      "    accuracy                         0.2484      1868\n",
      "   macro avg     0.6041    0.5167    0.2194      1868\n",
      "weighted avg     0.8144    0.2484    0.1355      1868\n",
      "\n",
      "[28] Label Model\n",
      "Total number of tokens missed:  50714\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000      1455\n",
      "           1     0.2207    0.9976    0.3614       413\n",
      "\n",
      "    accuracy                         0.2206      1868\n",
      "   macro avg     0.1103    0.4988    0.1807      1868\n",
      "weighted avg     0.0488    0.2206    0.0799      1868\n",
      "\n",
      "[29] Label Model\n",
      "Total number of tokens missed:  50714\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000      1455\n",
      "           1     0.2211    1.0000    0.3621       413\n",
      "\n",
      "    accuracy                         0.2211      1868\n",
      "   macro avg     0.1105    0.5000    0.1811      1868\n",
      "weighted avg     0.0489    0.2211    0.0801      1868\n",
      "\n",
      "[30] Label Model\n",
      "Total number of tokens missed:  50714\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000      1455\n",
      "           1     0.2211    1.0000    0.3621       413\n",
      "\n",
      "    accuracy                         0.2211      1868\n",
      "   macro avg     0.1105    0.5000    0.1811      1868\n",
      "weighted avg     0.0489    0.2211    0.0801      1868\n",
      "\n",
      "[31] Label Model\n",
      "Total number of tokens missed:  50714\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000      1455\n",
      "           1     0.2211    1.0000    0.3621       413\n",
      "\n",
      "    accuracy                         0.2211      1868\n",
      "   macro avg     0.1105    0.5000    0.1811      1868\n",
      "weighted avg     0.0489    0.2211    0.0801      1868\n",
      "\n",
      "[32] Label Model\n",
      "Total number of tokens missed:  50714\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000      1455\n",
      "           1     0.2211    1.0000    0.3621       413\n",
      "\n",
      "    accuracy                         0.2211      1868\n",
      "   macro avg     0.1105    0.5000    0.1811      1868\n",
      "weighted avg     0.0489    0.2211    0.0801      1868\n",
      "\n",
      "[33] Label Model\n",
      "Total number of tokens missed:  50714\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000      1455\n",
      "           1     0.2211    1.0000    0.3621       413\n",
      "\n",
      "    accuracy                         0.2211      1868\n",
      "   macro avg     0.1105    0.5000    0.1811      1868\n",
      "weighted avg     0.0489    0.2211    0.0801      1868\n",
      "\n",
      "[34] Label Model\n",
      "Total number of tokens missed:  50714\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000      1455\n",
      "           1     0.2211    1.0000    0.3621       413\n",
      "\n",
      "    accuracy                         0.2211      1868\n",
      "   macro avg     0.1105    0.5000    0.1811      1868\n",
      "weighted avg     0.0489    0.2211    0.0801      1868\n",
      "\n",
      "[35] Label Model\n",
      "Total number of tokens missed:  50714\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000      1455\n",
      "           1     0.2211    1.0000    0.3621       413\n",
      "\n",
      "    accuracy                         0.2211      1868\n",
      "   macro avg     0.1105    0.5000    0.1811      1868\n",
      "weighted avg     0.0489    0.2211    0.0801      1868\n",
      "\n",
      "[36] Label Model\n",
      "Total number of tokens missed:  50714\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9811    0.0357    0.0690      1455\n",
      "           1     0.2270    0.9976    0.3698       413\n",
      "\n",
      "    accuracy                         0.2484      1868\n",
      "   macro avg     0.6041    0.5167    0.2194      1868\n",
      "weighted avg     0.8144    0.2484    0.1355      1868\n",
      "\n",
      "[37] Label Model\n",
      "Total number of tokens missed:  50714\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000      1455\n",
      "           1     0.2211    1.0000    0.3621       413\n",
      "\n",
      "    accuracy                         0.2211      1868\n",
      "   macro avg     0.1105    0.5000    0.1811      1868\n",
      "weighted avg     0.0489    0.2211    0.0801      1868\n",
      "\n",
      "[38] Label Model\n",
      "Total number of tokens missed:  50714\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9811    0.0357    0.0690      1455\n",
      "           1     0.2270    0.9976    0.3698       413\n",
      "\n",
      "    accuracy                         0.2484      1868\n",
      "   macro avg     0.6041    0.5167    0.2194      1868\n",
      "weighted avg     0.8144    0.2484    0.1355      1868\n",
      "\n",
      "[39] Label Model\n",
      "Total number of tokens missed:  50714\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9811    0.0357    0.0690      1455\n",
      "           1     0.2270    0.9976    0.3698       413\n",
      "\n",
      "    accuracy                         0.2484      1868\n",
      "   macro avg     0.6041    0.5167    0.2194      1868\n",
      "weighted avg     0.8144    0.2484    0.1355      1868\n",
      "\n",
      "[40] Label Model\n",
      "Total number of tokens missed:  50714\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9811    0.0357    0.0690      1455\n",
      "           1     0.2270    0.9976    0.3698       413\n",
      "\n",
      "    accuracy                         0.2484      1868\n",
      "   macro avg     0.6041    0.5167    0.2194      1868\n",
      "weighted avg     0.8144    0.2484    0.1355      1868\n",
      "\n",
      "[41] Label Model\n",
      "Total number of tokens missed:  50714\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000      1455\n",
      "           1     0.2211    1.0000    0.3621       413\n",
      "\n",
      "    accuracy                         0.2211      1868\n",
      "   macro avg     0.1105    0.5000    0.1811      1868\n",
      "weighted avg     0.0489    0.2211    0.0801      1868\n",
      "\n",
      "[42] Label Model\n",
      "Total number of tokens missed:  50714\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9811    0.0357    0.0690      1455\n",
      "           1     0.2270    0.9976    0.3698       413\n",
      "\n",
      "    accuracy                         0.2484      1868\n",
      "   macro avg     0.6041    0.5167    0.2194      1868\n",
      "weighted avg     0.8144    0.2484    0.1355      1868\n",
      "\n",
      "[43] Label Model\n",
      "Total number of tokens missed:  50714\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000      1455\n",
      "           1     0.2211    1.0000    0.3621       413\n",
      "\n",
      "    accuracy                         0.2211      1868\n",
      "   macro avg     0.1105    0.5000    0.1811      1868\n",
      "weighted avg     0.0489    0.2211    0.0801      1868\n",
      "\n",
      "[44] Label Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of tokens missed:  50714\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000      1455\n",
      "           1     0.2207    0.9976    0.3614       413\n",
      "\n",
      "    accuracy                         0.2206      1868\n",
      "   macro avg     0.1103    0.4988    0.1807      1868\n",
      "weighted avg     0.0488    0.2206    0.0799      1868\n",
      "\n",
      "[45] Label Model\n",
      "Total number of tokens missed:  50714\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000      1455\n",
      "           1     0.2211    1.0000    0.3621       413\n",
      "\n",
      "    accuracy                         0.2211      1868\n",
      "   macro avg     0.1105    0.5000    0.1811      1868\n",
      "weighted avg     0.0489    0.2211    0.0801      1868\n",
      "\n",
      "[46] Label Model\n",
      "Total number of tokens missed:  50714\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9811    0.0357    0.0690      1455\n",
      "           1     0.2270    0.9976    0.3698       413\n",
      "\n",
      "    accuracy                         0.2484      1868\n",
      "   macro avg     0.6041    0.5167    0.2194      1868\n",
      "weighted avg     0.8144    0.2484    0.1355      1868\n",
      "\n",
      "[47] Label Model\n",
      "Total number of tokens missed:  50714\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000      1455\n",
      "           1     0.2207    0.9976    0.3614       413\n",
      "\n",
      "    accuracy                         0.2206      1868\n",
      "   macro avg     0.1103    0.4988    0.1807      1868\n",
      "weighted avg     0.0488    0.2206    0.0799      1868\n",
      "\n",
      "[48] Label Model\n",
      "Total number of tokens missed:  50714\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000      1455\n",
      "           1     0.2211    1.0000    0.3621       413\n",
      "\n",
      "    accuracy                         0.2211      1868\n",
      "   macro avg     0.1105    0.5000    0.1811      1868\n",
      "weighted avg     0.0489    0.2211    0.0801      1868\n",
      "\n",
      "[49] Label Model\n",
      "Total number of tokens missed:  50714\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9811    0.0357    0.0690      1455\n",
      "           1     0.2270    0.9976    0.3698       413\n",
      "\n",
      "    accuracy                         0.2484      1868\n",
      "   macro avg     0.6041    0.5167    0.2194      1868\n",
      "weighted avg     0.8144    0.2484    0.1355      1868\n",
      "\n",
      "Save the best overall model, configuration and partition for this experiment level\n"
     ]
    }
   ],
   "source": [
    "# CandGen Version v4 (LFs = 14) # delete this later\n",
    "\n",
    "predicted_s = train_plus(train_s_candidates, test_s_ebm_candidates, test_s_ebm_corr_candidates, Y_s, 's', paramgrid = param_grid, mode = 'pred')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01cbd8d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7886b20d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635e4a0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d42774",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "5b0dfb38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparamater Search Space: 336\n",
      "Grid search over 50 configs\n",
      "[0] Label Model\n",
      "Total number of tokens missed:  51289\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9956    0.4967    0.6628       918\n",
      "           1     0.4467    0.9947    0.6165       375\n",
      "\n",
      "    accuracy                         0.6411      1293\n",
      "   macro avg     0.7212    0.7457    0.6397      1293\n",
      "weighted avg     0.8364    0.6411    0.6494      1293\n",
      "\n",
      "[1] Label Model\n",
      "Total number of tokens missed:  51289\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9956    0.4967    0.6628       918\n",
      "           1     0.4467    0.9947    0.6165       375\n",
      "\n",
      "    accuracy                         0.6411      1293\n",
      "   macro avg     0.7212    0.7457    0.6397      1293\n",
      "weighted avg     0.8364    0.6411    0.6494      1293\n",
      "\n",
      "[2] Label Model\n",
      "Total number of tokens missed:  51289\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000       918\n",
      "           1     0.2900    1.0000    0.4496       375\n",
      "\n",
      "    accuracy                         0.2900      1293\n",
      "   macro avg     0.1450    0.5000    0.2248      1293\n",
      "weighted avg     0.0841    0.2900    0.1304      1293\n",
      "\n",
      "[3] Label Model\n",
      "Total number of tokens missed:  51289\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000       918\n",
      "           1     0.2900    1.0000    0.4496       375\n",
      "\n",
      "    accuracy                         0.2900      1293\n",
      "   macro avg     0.1450    0.5000    0.2248      1293\n",
      "weighted avg     0.0841    0.2900    0.1304      1293\n",
      "\n",
      "[4] Label Model\n",
      "Total number of tokens missed:  51289\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000       918\n",
      "           1     0.2889    0.9947    0.4478       375\n",
      "\n",
      "    accuracy                         0.2885      1293\n",
      "   macro avg     0.1445    0.4973    0.2239      1293\n",
      "weighted avg     0.0838    0.2885    0.1299      1293\n",
      "\n",
      "[5] Label Model\n",
      "Total number of tokens missed:  51289\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9630    0.0566    0.1070       918\n",
      "           1     0.3010    0.9947    0.4622       375\n",
      "\n",
      "    accuracy                         0.3287      1293\n",
      "   macro avg     0.6320    0.5257    0.2846      1293\n",
      "weighted avg     0.7710    0.3287    0.2100      1293\n",
      "\n",
      "[6] Label Model\n",
      "Total number of tokens missed:  51289\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000       918\n",
      "           1     0.2900    1.0000    0.4496       375\n",
      "\n",
      "    accuracy                         0.2900      1293\n",
      "   macro avg     0.1450    0.5000    0.2248      1293\n",
      "weighted avg     0.0841    0.2900    0.1304      1293\n",
      "\n",
      "[7] Label Model\n",
      "Total number of tokens missed:  51289\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000       918\n",
      "           1     0.2900    1.0000    0.4496       375\n",
      "\n",
      "    accuracy                         0.2900      1293\n",
      "   macro avg     0.1450    0.5000    0.2248      1293\n",
      "weighted avg     0.0841    0.2900    0.1304      1293\n",
      "\n",
      "[8] Label Model\n",
      "Total number of tokens missed:  51289\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9956    0.4967    0.6628       918\n",
      "           1     0.4467    0.9947    0.6165       375\n",
      "\n",
      "    accuracy                         0.6411      1293\n",
      "   macro avg     0.7212    0.7457    0.6397      1293\n",
      "weighted avg     0.8364    0.6411    0.6494      1293\n",
      "\n",
      "[9] Label Model\n",
      "Total number of tokens missed:  51289\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000       918\n",
      "           1     0.2900    1.0000    0.4496       375\n",
      "\n",
      "    accuracy                         0.2900      1293\n",
      "   macro avg     0.1450    0.5000    0.2248      1293\n",
      "weighted avg     0.0841    0.2900    0.1304      1293\n",
      "\n",
      "[10] Label Model\n",
      "Total number of tokens missed:  51289\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000       918\n",
      "           1     0.2900    1.0000    0.4496       375\n",
      "\n",
      "    accuracy                         0.2900      1293\n",
      "   macro avg     0.1450    0.5000    0.2248      1293\n",
      "weighted avg     0.0841    0.2900    0.1304      1293\n",
      "\n",
      "[11] Label Model\n",
      "Total number of tokens missed:  51289\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9956    0.4967    0.6628       918\n",
      "           1     0.4467    0.9947    0.6165       375\n",
      "\n",
      "    accuracy                         0.6411      1293\n",
      "   macro avg     0.7212    0.7457    0.6397      1293\n",
      "weighted avg     0.8364    0.6411    0.6494      1293\n",
      "\n",
      "[12] Label Model\n",
      "Total number of tokens missed:  51289\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9956    0.4967    0.6628       918\n",
      "           1     0.4467    0.9947    0.6165       375\n",
      "\n",
      "    accuracy                         0.6411      1293\n",
      "   macro avg     0.7212    0.7457    0.6397      1293\n",
      "weighted avg     0.8364    0.6411    0.6494      1293\n",
      "\n",
      "[13] Label Model\n",
      "Total number of tokens missed:  51289\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000       918\n",
      "           1     0.2889    0.9947    0.4478       375\n",
      "\n",
      "    accuracy                         0.2885      1293\n",
      "   macro avg     0.1445    0.4973    0.2239      1293\n",
      "weighted avg     0.0838    0.2885    0.1299      1293\n",
      "\n",
      "[14] Label Model\n",
      "Total number of tokens missed:  51289\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000       918\n",
      "           1     0.2889    0.9947    0.4478       375\n",
      "\n",
      "    accuracy                         0.2885      1293\n",
      "   macro avg     0.1445    0.4973    0.2239      1293\n",
      "weighted avg     0.0838    0.2885    0.1299      1293\n",
      "\n",
      "[15] Label Model\n",
      "Total number of tokens missed:  51289\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9956    0.4967    0.6628       918\n",
      "           1     0.4467    0.9947    0.6165       375\n",
      "\n",
      "    accuracy                         0.6411      1293\n",
      "   macro avg     0.7212    0.7457    0.6397      1293\n",
      "weighted avg     0.8364    0.6411    0.6494      1293\n",
      "\n",
      "[16] Label Model\n",
      "Total number of tokens missed:  51289\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000       918\n",
      "           1     0.2900    1.0000    0.4496       375\n",
      "\n",
      "    accuracy                         0.2900      1293\n",
      "   macro avg     0.1450    0.5000    0.2248      1293\n",
      "weighted avg     0.0841    0.2900    0.1304      1293\n",
      "\n",
      "[17] Label Model\n",
      "Total number of tokens missed:  51289\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000       918\n",
      "           1     0.2900    1.0000    0.4496       375\n",
      "\n",
      "    accuracy                         0.2900      1293\n",
      "   macro avg     0.1450    0.5000    0.2248      1293\n",
      "weighted avg     0.0841    0.2900    0.1304      1293\n",
      "\n",
      "[18] Label Model\n",
      "Total number of tokens missed:  51289\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000       918\n",
      "           1     0.2889    0.9947    0.4478       375\n",
      "\n",
      "    accuracy                         0.2885      1293\n",
      "   macro avg     0.1445    0.4973    0.2239      1293\n",
      "weighted avg     0.0838    0.2885    0.1299      1293\n",
      "\n",
      "[19] Label Model\n",
      "Total number of tokens missed:  51289\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9956    0.4967    0.6628       918\n",
      "           1     0.4467    0.9947    0.6165       375\n",
      "\n",
      "    accuracy                         0.6411      1293\n",
      "   macro avg     0.7212    0.7457    0.6397      1293\n",
      "weighted avg     0.8364    0.6411    0.6494      1293\n",
      "\n",
      "[20] Label Model\n",
      "Total number of tokens missed:  51289\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000       918\n",
      "           1     0.2889    0.9947    0.4478       375\n",
      "\n",
      "    accuracy                         0.2885      1293\n",
      "   macro avg     0.1445    0.4973    0.2239      1293\n",
      "weighted avg     0.0838    0.2885    0.1299      1293\n",
      "\n",
      "[21] Label Model\n",
      "Total number of tokens missed:  51289\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000       918\n",
      "           1     0.2889    0.9947    0.4478       375\n",
      "\n",
      "    accuracy                         0.2885      1293\n",
      "   macro avg     0.1445    0.4973    0.2239      1293\n",
      "weighted avg     0.0838    0.2885    0.1299      1293\n",
      "\n",
      "[22] Label Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of tokens missed:  51289\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000       918\n",
      "           1     0.2900    1.0000    0.4496       375\n",
      "\n",
      "    accuracy                         0.2900      1293\n",
      "   macro avg     0.1450    0.5000    0.2248      1293\n",
      "weighted avg     0.0841    0.2900    0.1304      1293\n",
      "\n",
      "[23] Label Model\n",
      "Total number of tokens missed:  51289\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000       918\n",
      "           1     0.2889    0.9947    0.4478       375\n",
      "\n",
      "    accuracy                         0.2885      1293\n",
      "   macro avg     0.1445    0.4973    0.2239      1293\n",
      "weighted avg     0.0838    0.2885    0.1299      1293\n",
      "\n",
      "[24] Label Model\n",
      "Total number of tokens missed:  51289\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000       918\n",
      "           1     0.2900    1.0000    0.4496       375\n",
      "\n",
      "    accuracy                         0.2900      1293\n",
      "   macro avg     0.1450    0.5000    0.2248      1293\n",
      "weighted avg     0.0841    0.2900    0.1304      1293\n",
      "\n",
      "[25] Label Model\n",
      "Total number of tokens missed:  51289\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000       918\n",
      "           1     0.2889    0.9947    0.4478       375\n",
      "\n",
      "    accuracy                         0.2885      1293\n",
      "   macro avg     0.1445    0.4973    0.2239      1293\n",
      "weighted avg     0.0838    0.2885    0.1299      1293\n",
      "\n",
      "[26] Label Model\n",
      "Total number of tokens missed:  51289\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000       918\n",
      "           1     0.2900    1.0000    0.4496       375\n",
      "\n",
      "    accuracy                         0.2900      1293\n",
      "   macro avg     0.1450    0.5000    0.2248      1293\n",
      "weighted avg     0.0841    0.2900    0.1304      1293\n",
      "\n",
      "[27] Label Model\n",
      "Total number of tokens missed:  51289\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9956    0.4967    0.6628       918\n",
      "           1     0.4467    0.9947    0.6165       375\n",
      "\n",
      "    accuracy                         0.6411      1293\n",
      "   macro avg     0.7212    0.7457    0.6397      1293\n",
      "weighted avg     0.8364    0.6411    0.6494      1293\n",
      "\n",
      "[28] Label Model\n",
      "Total number of tokens missed:  51289\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000       918\n",
      "           1     0.2900    1.0000    0.4496       375\n",
      "\n",
      "    accuracy                         0.2900      1293\n",
      "   macro avg     0.1450    0.5000    0.2248      1293\n",
      "weighted avg     0.0841    0.2900    0.1304      1293\n",
      "\n",
      "[29] Label Model\n",
      "Total number of tokens missed:  51289\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000       918\n",
      "           1     0.2900    1.0000    0.4496       375\n",
      "\n",
      "    accuracy                         0.2900      1293\n",
      "   macro avg     0.1450    0.5000    0.2248      1293\n",
      "weighted avg     0.0841    0.2900    0.1304      1293\n",
      "\n",
      "[30] Label Model\n",
      "Total number of tokens missed:  51289\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000       918\n",
      "           1     0.2900    1.0000    0.4496       375\n",
      "\n",
      "    accuracy                         0.2900      1293\n",
      "   macro avg     0.1450    0.5000    0.2248      1293\n",
      "weighted avg     0.0841    0.2900    0.1304      1293\n",
      "\n",
      "[31] Label Model\n",
      "Total number of tokens missed:  51289\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000       918\n",
      "           1     0.2900    1.0000    0.4496       375\n",
      "\n",
      "    accuracy                         0.2900      1293\n",
      "   macro avg     0.1450    0.5000    0.2248      1293\n",
      "weighted avg     0.0841    0.2900    0.1304      1293\n",
      "\n",
      "[32] Label Model\n",
      "Total number of tokens missed:  51289\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000       918\n",
      "           1     0.2900    1.0000    0.4496       375\n",
      "\n",
      "    accuracy                         0.2900      1293\n",
      "   macro avg     0.1450    0.5000    0.2248      1293\n",
      "weighted avg     0.0841    0.2900    0.1304      1293\n",
      "\n",
      "[33] Label Model\n",
      "Total number of tokens missed:  51289\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000       918\n",
      "           1     0.2900    1.0000    0.4496       375\n",
      "\n",
      "    accuracy                         0.2900      1293\n",
      "   macro avg     0.1450    0.5000    0.2248      1293\n",
      "weighted avg     0.0841    0.2900    0.1304      1293\n",
      "\n",
      "[34] Label Model\n",
      "Total number of tokens missed:  51289\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000       918\n",
      "           1     0.2900    1.0000    0.4496       375\n",
      "\n",
      "    accuracy                         0.2900      1293\n",
      "   macro avg     0.1450    0.5000    0.2248      1293\n",
      "weighted avg     0.0841    0.2900    0.1304      1293\n",
      "\n",
      "[35] Label Model\n",
      "Total number of tokens missed:  51289\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000       918\n",
      "           1     0.2900    1.0000    0.4496       375\n",
      "\n",
      "    accuracy                         0.2900      1293\n",
      "   macro avg     0.1450    0.5000    0.2248      1293\n",
      "weighted avg     0.0841    0.2900    0.1304      1293\n",
      "\n",
      "[36] Label Model\n",
      "Total number of tokens missed:  51289\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9956    0.4967    0.6628       918\n",
      "           1     0.4467    0.9947    0.6165       375\n",
      "\n",
      "    accuracy                         0.6411      1293\n",
      "   macro avg     0.7212    0.7457    0.6397      1293\n",
      "weighted avg     0.8364    0.6411    0.6494      1293\n",
      "\n",
      "[37] Label Model\n",
      "Total number of tokens missed:  51289\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000       918\n",
      "           1     0.2900    1.0000    0.4496       375\n",
      "\n",
      "    accuracy                         0.2900      1293\n",
      "   macro avg     0.1450    0.5000    0.2248      1293\n",
      "weighted avg     0.0841    0.2900    0.1304      1293\n",
      "\n",
      "[38] Label Model\n",
      "Total number of tokens missed:  51289\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9956    0.4967    0.6628       918\n",
      "           1     0.4467    0.9947    0.6165       375\n",
      "\n",
      "    accuracy                         0.6411      1293\n",
      "   macro avg     0.7212    0.7457    0.6397      1293\n",
      "weighted avg     0.8364    0.6411    0.6494      1293\n",
      "\n",
      "[39] Label Model\n",
      "Total number of tokens missed:  51289\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9956    0.4967    0.6628       918\n",
      "           1     0.4467    0.9947    0.6165       375\n",
      "\n",
      "    accuracy                         0.6411      1293\n",
      "   macro avg     0.7212    0.7457    0.6397      1293\n",
      "weighted avg     0.8364    0.6411    0.6494      1293\n",
      "\n",
      "[40] Label Model\n",
      "Total number of tokens missed:  51289\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9956    0.4967    0.6628       918\n",
      "           1     0.4467    0.9947    0.6165       375\n",
      "\n",
      "    accuracy                         0.6411      1293\n",
      "   macro avg     0.7212    0.7457    0.6397      1293\n",
      "weighted avg     0.8364    0.6411    0.6494      1293\n",
      "\n",
      "[41] Label Model\n",
      "Total number of tokens missed:  51289\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000       918\n",
      "           1     0.2900    1.0000    0.4496       375\n",
      "\n",
      "    accuracy                         0.2900      1293\n",
      "   macro avg     0.1450    0.5000    0.2248      1293\n",
      "weighted avg     0.0841    0.2900    0.1304      1293\n",
      "\n",
      "[42] Label Model\n",
      "Total number of tokens missed:  51289\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9956    0.4967    0.6628       918\n",
      "           1     0.4467    0.9947    0.6165       375\n",
      "\n",
      "    accuracy                         0.6411      1293\n",
      "   macro avg     0.7212    0.7457    0.6397      1293\n",
      "weighted avg     0.8364    0.6411    0.6494      1293\n",
      "\n",
      "[43] Label Model\n",
      "Total number of tokens missed:  51289\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000       918\n",
      "           1     0.2900    1.0000    0.4496       375\n",
      "\n",
      "    accuracy                         0.2900      1293\n",
      "   macro avg     0.1450    0.5000    0.2248      1293\n",
      "weighted avg     0.0841    0.2900    0.1304      1293\n",
      "\n",
      "[44] Label Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of tokens missed:  51289\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000       918\n",
      "           1     0.2900    1.0000    0.4496       375\n",
      "\n",
      "    accuracy                         0.2900      1293\n",
      "   macro avg     0.1450    0.5000    0.2248      1293\n",
      "weighted avg     0.0841    0.2900    0.1304      1293\n",
      "\n",
      "[45] Label Model\n",
      "Total number of tokens missed:  51289\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000       918\n",
      "           1     0.2900    1.0000    0.4496       375\n",
      "\n",
      "    accuracy                         0.2900      1293\n",
      "   macro avg     0.1450    0.5000    0.2248      1293\n",
      "weighted avg     0.0841    0.2900    0.1304      1293\n",
      "\n",
      "[46] Label Model\n",
      "Total number of tokens missed:  51289\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9956    0.4967    0.6628       918\n",
      "           1     0.4467    0.9947    0.6165       375\n",
      "\n",
      "    accuracy                         0.6411      1293\n",
      "   macro avg     0.7212    0.7457    0.6397      1293\n",
      "weighted avg     0.8364    0.6411    0.6494      1293\n",
      "\n",
      "[47] Label Model\n",
      "Total number of tokens missed:  51289\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000       918\n",
      "           1     0.2900    1.0000    0.4496       375\n",
      "\n",
      "    accuracy                         0.2900      1293\n",
      "   macro avg     0.1450    0.5000    0.2248      1293\n",
      "weighted avg     0.0841    0.2900    0.1304      1293\n",
      "\n",
      "[48] Label Model\n",
      "Total number of tokens missed:  51289\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000       918\n",
      "           1     0.2900    1.0000    0.4496       375\n",
      "\n",
      "    accuracy                         0.2900      1293\n",
      "   macro avg     0.1450    0.5000    0.2248      1293\n",
      "weighted avg     0.0841    0.2900    0.1304      1293\n",
      "\n",
      "[49] Label Model\n",
      "Total number of tokens missed:  51289\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9956    0.4967    0.6628       918\n",
      "           1     0.4467    0.9947    0.6165       375\n",
      "\n",
      "    accuracy                         0.6411      1293\n",
      "   macro avg     0.7212    0.7457    0.6397      1293\n",
      "weighted avg     0.8364    0.6411    0.6494      1293\n",
      "\n",
      "Save the best overall model, configuration and partition for this experiment level\n"
     ]
    }
   ],
   "source": [
    "# CandGen Version v4 (LFs = 14)\n",
    "\n",
    "predicted_s = train_plus(train_s_candidates, test_s_ebm_candidates, test_s_ebm_corr_candidates, Y_s, 's', paramgrid = param_grid, mode = 'pred')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "10dd0f64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparamater Search Space: 336\n",
      "Grid search over 50 configs\n",
      "[0] Label Model\n",
      "Total number of tokens missed:  51289\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9956    0.4967    0.6628       918\n",
      "           1     0.4467    0.9947    0.6165       375\n",
      "\n",
      "    accuracy                         0.6411      1293\n",
      "   macro avg     0.7212    0.7457    0.6397      1293\n",
      "weighted avg     0.8364    0.6411    0.6494      1293\n",
      "\n",
      "[1] Label Model\n",
      "Total number of tokens missed:  51289\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9956    0.4967    0.6628       918\n",
      "           1     0.4467    0.9947    0.6165       375\n",
      "\n",
      "    accuracy                         0.6411      1293\n",
      "   macro avg     0.7212    0.7457    0.6397      1293\n",
      "weighted avg     0.8364    0.6411    0.6494      1293\n",
      "\n",
      "[2] Label Model\n",
      "Total number of tokens missed:  51289\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000       918\n",
      "           1     0.2900    1.0000    0.4496       375\n",
      "\n",
      "    accuracy                         0.2900      1293\n",
      "   macro avg     0.1450    0.5000    0.2248      1293\n",
      "weighted avg     0.0841    0.2900    0.1304      1293\n",
      "\n",
      "[3] Label Model\n",
      "Total number of tokens missed:  51289\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000       918\n",
      "           1     0.2900    1.0000    0.4496       375\n",
      "\n",
      "    accuracy                         0.2900      1293\n",
      "   macro avg     0.1450    0.5000    0.2248      1293\n",
      "weighted avg     0.0841    0.2900    0.1304      1293\n",
      "\n",
      "[4] Label Model\n",
      "Total number of tokens missed:  51289\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000       918\n",
      "           1     0.2889    0.9947    0.4478       375\n",
      "\n",
      "    accuracy                         0.2885      1293\n",
      "   macro avg     0.1445    0.4973    0.2239      1293\n",
      "weighted avg     0.0838    0.2885    0.1299      1293\n",
      "\n",
      "[5] Label Model\n",
      "Total number of tokens missed:  51289\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9630    0.0566    0.1070       918\n",
      "           1     0.3010    0.9947    0.4622       375\n",
      "\n",
      "    accuracy                         0.3287      1293\n",
      "   macro avg     0.6320    0.5257    0.2846      1293\n",
      "weighted avg     0.7710    0.3287    0.2100      1293\n",
      "\n",
      "[6] Label Model\n",
      "Total number of tokens missed:  51289\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000       918\n",
      "           1     0.2900    1.0000    0.4496       375\n",
      "\n",
      "    accuracy                         0.2900      1293\n",
      "   macro avg     0.1450    0.5000    0.2248      1293\n",
      "weighted avg     0.0841    0.2900    0.1304      1293\n",
      "\n",
      "[7] Label Model\n",
      "Total number of tokens missed:  51289\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000       918\n",
      "           1     0.2900    1.0000    0.4496       375\n",
      "\n",
      "    accuracy                         0.2900      1293\n",
      "   macro avg     0.1450    0.5000    0.2248      1293\n",
      "weighted avg     0.0841    0.2900    0.1304      1293\n",
      "\n",
      "[8] Label Model\n",
      "Total number of tokens missed:  51289\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9956    0.4967    0.6628       918\n",
      "           1     0.4467    0.9947    0.6165       375\n",
      "\n",
      "    accuracy                         0.6411      1293\n",
      "   macro avg     0.7212    0.7457    0.6397      1293\n",
      "weighted avg     0.8364    0.6411    0.6494      1293\n",
      "\n",
      "[9] Label Model\n",
      "Total number of tokens missed:  51289\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000       918\n",
      "           1     0.2900    1.0000    0.4496       375\n",
      "\n",
      "    accuracy                         0.2900      1293\n",
      "   macro avg     0.1450    0.5000    0.2248      1293\n",
      "weighted avg     0.0841    0.2900    0.1304      1293\n",
      "\n",
      "[10] Label Model\n",
      "Total number of tokens missed:  51289\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000       918\n",
      "           1     0.2900    1.0000    0.4496       375\n",
      "\n",
      "    accuracy                         0.2900      1293\n",
      "   macro avg     0.1450    0.5000    0.2248      1293\n",
      "weighted avg     0.0841    0.2900    0.1304      1293\n",
      "\n",
      "[11] Label Model\n",
      "Total number of tokens missed:  51289\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9956    0.4967    0.6628       918\n",
      "           1     0.4467    0.9947    0.6165       375\n",
      "\n",
      "    accuracy                         0.6411      1293\n",
      "   macro avg     0.7212    0.7457    0.6397      1293\n",
      "weighted avg     0.8364    0.6411    0.6494      1293\n",
      "\n",
      "[12] Label Model\n",
      "Total number of tokens missed:  51289\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9956    0.4967    0.6628       918\n",
      "           1     0.4467    0.9947    0.6165       375\n",
      "\n",
      "    accuracy                         0.6411      1293\n",
      "   macro avg     0.7212    0.7457    0.6397      1293\n",
      "weighted avg     0.8364    0.6411    0.6494      1293\n",
      "\n",
      "[13] Label Model\n",
      "Total number of tokens missed:  51289\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000       918\n",
      "           1     0.2889    0.9947    0.4478       375\n",
      "\n",
      "    accuracy                         0.2885      1293\n",
      "   macro avg     0.1445    0.4973    0.2239      1293\n",
      "weighted avg     0.0838    0.2885    0.1299      1293\n",
      "\n",
      "[14] Label Model\n",
      "Total number of tokens missed:  51289\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000       918\n",
      "           1     0.2889    0.9947    0.4478       375\n",
      "\n",
      "    accuracy                         0.2885      1293\n",
      "   macro avg     0.1445    0.4973    0.2239      1293\n",
      "weighted avg     0.0838    0.2885    0.1299      1293\n",
      "\n",
      "[15] Label Model\n",
      "Total number of tokens missed:  51289\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9956    0.4967    0.6628       918\n",
      "           1     0.4467    0.9947    0.6165       375\n",
      "\n",
      "    accuracy                         0.6411      1293\n",
      "   macro avg     0.7212    0.7457    0.6397      1293\n",
      "weighted avg     0.8364    0.6411    0.6494      1293\n",
      "\n",
      "[16] Label Model\n",
      "Total number of tokens missed:  51289\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000       918\n",
      "           1     0.2900    1.0000    0.4496       375\n",
      "\n",
      "    accuracy                         0.2900      1293\n",
      "   macro avg     0.1450    0.5000    0.2248      1293\n",
      "weighted avg     0.0841    0.2900    0.1304      1293\n",
      "\n",
      "[17] Label Model\n",
      "Total number of tokens missed:  51289\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000       918\n",
      "           1     0.2900    1.0000    0.4496       375\n",
      "\n",
      "    accuracy                         0.2900      1293\n",
      "   macro avg     0.1450    0.5000    0.2248      1293\n",
      "weighted avg     0.0841    0.2900    0.1304      1293\n",
      "\n",
      "[18] Label Model\n",
      "Total number of tokens missed:  51289\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000       918\n",
      "           1     0.2889    0.9947    0.4478       375\n",
      "\n",
      "    accuracy                         0.2885      1293\n",
      "   macro avg     0.1445    0.4973    0.2239      1293\n",
      "weighted avg     0.0838    0.2885    0.1299      1293\n",
      "\n",
      "[19] Label Model\n",
      "Total number of tokens missed:  51289\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9956    0.4967    0.6628       918\n",
      "           1     0.4467    0.9947    0.6165       375\n",
      "\n",
      "    accuracy                         0.6411      1293\n",
      "   macro avg     0.7212    0.7457    0.6397      1293\n",
      "weighted avg     0.8364    0.6411    0.6494      1293\n",
      "\n",
      "[20] Label Model\n",
      "Total number of tokens missed:  51289\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000       918\n",
      "           1     0.2889    0.9947    0.4478       375\n",
      "\n",
      "    accuracy                         0.2885      1293\n",
      "   macro avg     0.1445    0.4973    0.2239      1293\n",
      "weighted avg     0.0838    0.2885    0.1299      1293\n",
      "\n",
      "[21] Label Model\n",
      "Total number of tokens missed:  51289\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000       918\n",
      "           1     0.2889    0.9947    0.4478       375\n",
      "\n",
      "    accuracy                         0.2885      1293\n",
      "   macro avg     0.1445    0.4973    0.2239      1293\n",
      "weighted avg     0.0838    0.2885    0.1299      1293\n",
      "\n",
      "[22] Label Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of tokens missed:  51289\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000       918\n",
      "           1     0.2900    1.0000    0.4496       375\n",
      "\n",
      "    accuracy                         0.2900      1293\n",
      "   macro avg     0.1450    0.5000    0.2248      1293\n",
      "weighted avg     0.0841    0.2900    0.1304      1293\n",
      "\n",
      "[23] Label Model\n",
      "Total number of tokens missed:  51289\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000       918\n",
      "           1     0.2889    0.9947    0.4478       375\n",
      "\n",
      "    accuracy                         0.2885      1293\n",
      "   macro avg     0.1445    0.4973    0.2239      1293\n",
      "weighted avg     0.0838    0.2885    0.1299      1293\n",
      "\n",
      "[24] Label Model\n",
      "Total number of tokens missed:  51289\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000       918\n",
      "           1     0.2900    1.0000    0.4496       375\n",
      "\n",
      "    accuracy                         0.2900      1293\n",
      "   macro avg     0.1450    0.5000    0.2248      1293\n",
      "weighted avg     0.0841    0.2900    0.1304      1293\n",
      "\n",
      "[25] Label Model\n",
      "Total number of tokens missed:  51289\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000       918\n",
      "           1     0.2889    0.9947    0.4478       375\n",
      "\n",
      "    accuracy                         0.2885      1293\n",
      "   macro avg     0.1445    0.4973    0.2239      1293\n",
      "weighted avg     0.0838    0.2885    0.1299      1293\n",
      "\n",
      "[26] Label Model\n",
      "Total number of tokens missed:  51289\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000       918\n",
      "           1     0.2900    1.0000    0.4496       375\n",
      "\n",
      "    accuracy                         0.2900      1293\n",
      "   macro avg     0.1450    0.5000    0.2248      1293\n",
      "weighted avg     0.0841    0.2900    0.1304      1293\n",
      "\n",
      "[27] Label Model\n",
      "Total number of tokens missed:  51289\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9956    0.4967    0.6628       918\n",
      "           1     0.4467    0.9947    0.6165       375\n",
      "\n",
      "    accuracy                         0.6411      1293\n",
      "   macro avg     0.7212    0.7457    0.6397      1293\n",
      "weighted avg     0.8364    0.6411    0.6494      1293\n",
      "\n",
      "[28] Label Model\n",
      "Total number of tokens missed:  51289\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000       918\n",
      "           1     0.2900    1.0000    0.4496       375\n",
      "\n",
      "    accuracy                         0.2900      1293\n",
      "   macro avg     0.1450    0.5000    0.2248      1293\n",
      "weighted avg     0.0841    0.2900    0.1304      1293\n",
      "\n",
      "[29] Label Model\n",
      "Total number of tokens missed:  51289\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000       918\n",
      "           1     0.2900    1.0000    0.4496       375\n",
      "\n",
      "    accuracy                         0.2900      1293\n",
      "   macro avg     0.1450    0.5000    0.2248      1293\n",
      "weighted avg     0.0841    0.2900    0.1304      1293\n",
      "\n",
      "[30] Label Model\n",
      "Total number of tokens missed:  51289\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000       918\n",
      "           1     0.2900    1.0000    0.4496       375\n",
      "\n",
      "    accuracy                         0.2900      1293\n",
      "   macro avg     0.1450    0.5000    0.2248      1293\n",
      "weighted avg     0.0841    0.2900    0.1304      1293\n",
      "\n",
      "[31] Label Model\n",
      "Total number of tokens missed:  51289\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000       918\n",
      "           1     0.2900    1.0000    0.4496       375\n",
      "\n",
      "    accuracy                         0.2900      1293\n",
      "   macro avg     0.1450    0.5000    0.2248      1293\n",
      "weighted avg     0.0841    0.2900    0.1304      1293\n",
      "\n",
      "[32] Label Model\n",
      "Total number of tokens missed:  51289\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000       918\n",
      "           1     0.2900    1.0000    0.4496       375\n",
      "\n",
      "    accuracy                         0.2900      1293\n",
      "   macro avg     0.1450    0.5000    0.2248      1293\n",
      "weighted avg     0.0841    0.2900    0.1304      1293\n",
      "\n",
      "[33] Label Model\n",
      "Total number of tokens missed:  51289\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000       918\n",
      "           1     0.2900    1.0000    0.4496       375\n",
      "\n",
      "    accuracy                         0.2900      1293\n",
      "   macro avg     0.1450    0.5000    0.2248      1293\n",
      "weighted avg     0.0841    0.2900    0.1304      1293\n",
      "\n",
      "[34] Label Model\n",
      "Total number of tokens missed:  51289\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000       918\n",
      "           1     0.2900    1.0000    0.4496       375\n",
      "\n",
      "    accuracy                         0.2900      1293\n",
      "   macro avg     0.1450    0.5000    0.2248      1293\n",
      "weighted avg     0.0841    0.2900    0.1304      1293\n",
      "\n",
      "[35] Label Model\n",
      "Total number of tokens missed:  51289\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000       918\n",
      "           1     0.2900    1.0000    0.4496       375\n",
      "\n",
      "    accuracy                         0.2900      1293\n",
      "   macro avg     0.1450    0.5000    0.2248      1293\n",
      "weighted avg     0.0841    0.2900    0.1304      1293\n",
      "\n",
      "[36] Label Model\n",
      "Total number of tokens missed:  51289\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9956    0.4967    0.6628       918\n",
      "           1     0.4467    0.9947    0.6165       375\n",
      "\n",
      "    accuracy                         0.6411      1293\n",
      "   macro avg     0.7212    0.7457    0.6397      1293\n",
      "weighted avg     0.8364    0.6411    0.6494      1293\n",
      "\n",
      "[37] Label Model\n",
      "Total number of tokens missed:  51289\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000       918\n",
      "           1     0.2900    1.0000    0.4496       375\n",
      "\n",
      "    accuracy                         0.2900      1293\n",
      "   macro avg     0.1450    0.5000    0.2248      1293\n",
      "weighted avg     0.0841    0.2900    0.1304      1293\n",
      "\n",
      "[38] Label Model\n",
      "Total number of tokens missed:  51289\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9956    0.4967    0.6628       918\n",
      "           1     0.4467    0.9947    0.6165       375\n",
      "\n",
      "    accuracy                         0.6411      1293\n",
      "   macro avg     0.7212    0.7457    0.6397      1293\n",
      "weighted avg     0.8364    0.6411    0.6494      1293\n",
      "\n",
      "[39] Label Model\n",
      "Total number of tokens missed:  51289\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9956    0.4967    0.6628       918\n",
      "           1     0.4467    0.9947    0.6165       375\n",
      "\n",
      "    accuracy                         0.6411      1293\n",
      "   macro avg     0.7212    0.7457    0.6397      1293\n",
      "weighted avg     0.8364    0.6411    0.6494      1293\n",
      "\n",
      "[40] Label Model\n",
      "Total number of tokens missed:  51289\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9956    0.4967    0.6628       918\n",
      "           1     0.4467    0.9947    0.6165       375\n",
      "\n",
      "    accuracy                         0.6411      1293\n",
      "   macro avg     0.7212    0.7457    0.6397      1293\n",
      "weighted avg     0.8364    0.6411    0.6494      1293\n",
      "\n",
      "[41] Label Model\n",
      "Total number of tokens missed:  51289\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000       918\n",
      "           1     0.2900    1.0000    0.4496       375\n",
      "\n",
      "    accuracy                         0.2900      1293\n",
      "   macro avg     0.1450    0.5000    0.2248      1293\n",
      "weighted avg     0.0841    0.2900    0.1304      1293\n",
      "\n",
      "[42] Label Model\n",
      "Total number of tokens missed:  51289\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9956    0.4967    0.6628       918\n",
      "           1     0.4467    0.9947    0.6165       375\n",
      "\n",
      "    accuracy                         0.6411      1293\n",
      "   macro avg     0.7212    0.7457    0.6397      1293\n",
      "weighted avg     0.8364    0.6411    0.6494      1293\n",
      "\n",
      "[43] Label Model\n",
      "Total number of tokens missed:  51289\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000       918\n",
      "           1     0.2900    1.0000    0.4496       375\n",
      "\n",
      "    accuracy                         0.2900      1293\n",
      "   macro avg     0.1450    0.5000    0.2248      1293\n",
      "weighted avg     0.0841    0.2900    0.1304      1293\n",
      "\n",
      "[44] Label Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of tokens missed:  51289\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000       918\n",
      "           1     0.2900    1.0000    0.4496       375\n",
      "\n",
      "    accuracy                         0.2900      1293\n",
      "   macro avg     0.1450    0.5000    0.2248      1293\n",
      "weighted avg     0.0841    0.2900    0.1304      1293\n",
      "\n",
      "[45] Label Model\n",
      "Total number of tokens missed:  51289\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000       918\n",
      "           1     0.2900    1.0000    0.4496       375\n",
      "\n",
      "    accuracy                         0.2900      1293\n",
      "   macro avg     0.1450    0.5000    0.2248      1293\n",
      "weighted avg     0.0841    0.2900    0.1304      1293\n",
      "\n",
      "[46] Label Model\n",
      "Total number of tokens missed:  51289\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9956    0.4967    0.6628       918\n",
      "           1     0.4467    0.9947    0.6165       375\n",
      "\n",
      "    accuracy                         0.6411      1293\n",
      "   macro avg     0.7212    0.7457    0.6397      1293\n",
      "weighted avg     0.8364    0.6411    0.6494      1293\n",
      "\n",
      "[47] Label Model\n",
      "Total number of tokens missed:  51289\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000       918\n",
      "           1     0.2900    1.0000    0.4496       375\n",
      "\n",
      "    accuracy                         0.2900      1293\n",
      "   macro avg     0.1450    0.5000    0.2248      1293\n",
      "weighted avg     0.0841    0.2900    0.1304      1293\n",
      "\n",
      "[48] Label Model\n",
      "Total number of tokens missed:  51289\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000       918\n",
      "           1     0.2900    1.0000    0.4496       375\n",
      "\n",
      "    accuracy                         0.2900      1293\n",
      "   macro avg     0.1450    0.5000    0.2248      1293\n",
      "weighted avg     0.0841    0.2900    0.1304      1293\n",
      "\n",
      "[49] Label Model\n",
      "Total number of tokens missed:  51289\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9956    0.4967    0.6628       918\n",
      "           1     0.4467    0.9947    0.6165       375\n",
      "\n",
      "    accuracy                         0.6411      1293\n",
      "   macro avg     0.7212    0.7457    0.6397      1293\n",
      "weighted avg     0.8364    0.6411    0.6494      1293\n",
      "\n",
      "Save the best overall model, configuration and partition for this experiment level\n"
     ]
    }
   ],
   "source": [
    "# CandGen Version v4 (LFs = 13)\n",
    "\n",
    "predicted_s = train_plus(train_s_candidates, test_s_ebm_candidates, test_s_ebm_corr_candidates, Y_s, 's', paramgrid = param_grid, mode = 'pred')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b8e0b989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparamater Search Space: 336\n",
      "Grid search over 50 configs\n",
      "[0] Label Model\n",
      "Total number of tokens missed:  51341\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9951    0.4665    0.6352       866\n",
      "           1     0.4467    0.9947    0.6165       375\n",
      "\n",
      "    accuracy                         0.6261      1241\n",
      "   macro avg     0.7209    0.7306    0.6259      1241\n",
      "weighted avg     0.8294    0.6261    0.6296      1241\n",
      "\n",
      "[1] Label Model\n",
      "Total number of tokens missed:  51341\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9951    0.4665    0.6352       866\n",
      "           1     0.4467    0.9947    0.6165       375\n",
      "\n",
      "    accuracy                         0.6261      1241\n",
      "   macro avg     0.7209    0.7306    0.6259      1241\n",
      "weighted avg     0.8294    0.6261    0.6296      1241\n",
      "\n",
      "[2] Label Model\n",
      "Total number of tokens missed:  51341\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000       866\n",
      "           1     0.3022    1.0000    0.4641       375\n",
      "\n",
      "    accuracy                         0.3022      1241\n",
      "   macro avg     0.1511    0.5000    0.2321      1241\n",
      "weighted avg     0.0913    0.3022    0.1402      1241\n",
      "\n",
      "[3] Label Model\n",
      "Total number of tokens missed:  51341\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000       866\n",
      "           1     0.3022    1.0000    0.4641       375\n",
      "\n",
      "    accuracy                         0.3022      1241\n",
      "   macro avg     0.1511    0.5000    0.2321      1241\n",
      "weighted avg     0.0913    0.3022    0.1402      1241\n",
      "\n",
      "[4] Label Model\n",
      "Total number of tokens missed:  51341\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000       866\n",
      "           1     0.3010    0.9947    0.4622       375\n",
      "\n",
      "    accuracy                         0.3006      1241\n",
      "   macro avg     0.1505    0.4973    0.2311      1241\n",
      "weighted avg     0.0910    0.3006    0.1397      1241\n",
      "\n",
      "[5] Label Model\n",
      "Total number of tokens missed:  51341\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9951    0.4665    0.6352       866\n",
      "           1     0.4467    0.9947    0.6165       375\n",
      "\n",
      "    accuracy                         0.6261      1241\n",
      "   macro avg     0.7209    0.7306    0.6259      1241\n",
      "weighted avg     0.8294    0.6261    0.6296      1241\n",
      "\n",
      "[6] Label Model\n",
      "Total number of tokens missed:  51341\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000       866\n",
      "           1     0.3022    1.0000    0.4641       375\n",
      "\n",
      "    accuracy                         0.3022      1241\n",
      "   macro avg     0.1511    0.5000    0.2321      1241\n",
      "weighted avg     0.0913    0.3022    0.1402      1241\n",
      "\n",
      "[7] Label Model\n",
      "Total number of tokens missed:  51341\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000       866\n",
      "           1     0.3022    1.0000    0.4641       375\n",
      "\n",
      "    accuracy                         0.3022      1241\n",
      "   macro avg     0.1511    0.5000    0.2321      1241\n",
      "weighted avg     0.0913    0.3022    0.1402      1241\n",
      "\n",
      "[8] Label Model\n",
      "Total number of tokens missed:  51341\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9951    0.4665    0.6352       866\n",
      "           1     0.4467    0.9947    0.6165       375\n",
      "\n",
      "    accuracy                         0.6261      1241\n",
      "   macro avg     0.7209    0.7306    0.6259      1241\n",
      "weighted avg     0.8294    0.6261    0.6296      1241\n",
      "\n",
      "[9] Label Model\n",
      "Total number of tokens missed:  51341\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000       866\n",
      "           1     0.3022    1.0000    0.4641       375\n",
      "\n",
      "    accuracy                         0.3022      1241\n",
      "   macro avg     0.1511    0.5000    0.2321      1241\n",
      "weighted avg     0.0913    0.3022    0.1402      1241\n",
      "\n",
      "[10] Label Model\n",
      "Total number of tokens missed:  51341\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000       866\n",
      "           1     0.3022    1.0000    0.4641       375\n",
      "\n",
      "    accuracy                         0.3022      1241\n",
      "   macro avg     0.1511    0.5000    0.2321      1241\n",
      "weighted avg     0.0913    0.3022    0.1402      1241\n",
      "\n",
      "[11] Label Model\n",
      "Total number of tokens missed:  51341\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9951    0.4665    0.6352       866\n",
      "           1     0.4467    0.9947    0.6165       375\n",
      "\n",
      "    accuracy                         0.6261      1241\n",
      "   macro avg     0.7209    0.7306    0.6259      1241\n",
      "weighted avg     0.8294    0.6261    0.6296      1241\n",
      "\n",
      "[12] Label Model\n",
      "Total number of tokens missed:  51341\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9951    0.4665    0.6352       866\n",
      "           1     0.4467    0.9947    0.6165       375\n",
      "\n",
      "    accuracy                         0.6261      1241\n",
      "   macro avg     0.7209    0.7306    0.6259      1241\n",
      "weighted avg     0.8294    0.6261    0.6296      1241\n",
      "\n",
      "[13] Label Model\n",
      "Total number of tokens missed:  51341\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000       866\n",
      "           1     0.3010    0.9947    0.4622       375\n",
      "\n",
      "    accuracy                         0.3006      1241\n",
      "   macro avg     0.1505    0.4973    0.2311      1241\n",
      "weighted avg     0.0910    0.3006    0.1397      1241\n",
      "\n",
      "[14] Label Model\n",
      "Total number of tokens missed:  51341\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000       866\n",
      "           1     0.3010    0.9947    0.4622       375\n",
      "\n",
      "    accuracy                         0.3006      1241\n",
      "   macro avg     0.1505    0.4973    0.2311      1241\n",
      "weighted avg     0.0910    0.3006    0.1397      1241\n",
      "\n",
      "[15] Label Model\n",
      "Total number of tokens missed:  51341\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9951    0.4665    0.6352       866\n",
      "           1     0.4467    0.9947    0.6165       375\n",
      "\n",
      "    accuracy                         0.6261      1241\n",
      "   macro avg     0.7209    0.7306    0.6259      1241\n",
      "weighted avg     0.8294    0.6261    0.6296      1241\n",
      "\n",
      "[16] Label Model\n",
      "Total number of tokens missed:  51341\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000       866\n",
      "           1     0.3022    1.0000    0.4641       375\n",
      "\n",
      "    accuracy                         0.3022      1241\n",
      "   macro avg     0.1511    0.5000    0.2321      1241\n",
      "weighted avg     0.0913    0.3022    0.1402      1241\n",
      "\n",
      "[17] Label Model\n",
      "Total number of tokens missed:  51341\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000       866\n",
      "           1     0.3022    1.0000    0.4641       375\n",
      "\n",
      "    accuracy                         0.3022      1241\n",
      "   macro avg     0.1511    0.5000    0.2321      1241\n",
      "weighted avg     0.0913    0.3022    0.1402      1241\n",
      "\n",
      "[18] Label Model\n",
      "Total number of tokens missed:  51341\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9951    0.4665    0.6352       866\n",
      "           1     0.4467    0.9947    0.6165       375\n",
      "\n",
      "    accuracy                         0.6261      1241\n",
      "   macro avg     0.7209    0.7306    0.6259      1241\n",
      "weighted avg     0.8294    0.6261    0.6296      1241\n",
      "\n",
      "[19] Label Model\n",
      "Total number of tokens missed:  51341\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9951    0.4665    0.6352       866\n",
      "           1     0.4467    0.9947    0.6165       375\n",
      "\n",
      "    accuracy                         0.6261      1241\n",
      "   macro avg     0.7209    0.7306    0.6259      1241\n",
      "weighted avg     0.8294    0.6261    0.6296      1241\n",
      "\n",
      "[20] Label Model\n",
      "Total number of tokens missed:  51341\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000       866\n",
      "           1     0.3010    0.9947    0.4622       375\n",
      "\n",
      "    accuracy                         0.3006      1241\n",
      "   macro avg     0.1505    0.4973    0.2311      1241\n",
      "weighted avg     0.0910    0.3006    0.1397      1241\n",
      "\n",
      "[21] Label Model\n",
      "Total number of tokens missed:  51341\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000       866\n",
      "           1     0.3010    0.9947    0.4622       375\n",
      "\n",
      "    accuracy                         0.3006      1241\n",
      "   macro avg     0.1505    0.4973    0.2311      1241\n",
      "weighted avg     0.0910    0.3006    0.1397      1241\n",
      "\n",
      "[22] Label Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of tokens missed:  51341\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000       866\n",
      "           1     0.3022    1.0000    0.4641       375\n",
      "\n",
      "    accuracy                         0.3022      1241\n",
      "   macro avg     0.1511    0.5000    0.2321      1241\n",
      "weighted avg     0.0913    0.3022    0.1402      1241\n",
      "\n",
      "[23] Label Model\n",
      "Total number of tokens missed:  51341\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000       866\n",
      "           1     0.3010    0.9947    0.4622       375\n",
      "\n",
      "    accuracy                         0.3006      1241\n",
      "   macro avg     0.1505    0.4973    0.2311      1241\n",
      "weighted avg     0.0910    0.3006    0.1397      1241\n",
      "\n",
      "[24] Label Model\n",
      "Total number of tokens missed:  51341\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000       866\n",
      "           1     0.3022    1.0000    0.4641       375\n",
      "\n",
      "    accuracy                         0.3022      1241\n",
      "   macro avg     0.1511    0.5000    0.2321      1241\n",
      "weighted avg     0.0913    0.3022    0.1402      1241\n",
      "\n",
      "[25] Label Model\n",
      "Total number of tokens missed:  51341\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000       866\n",
      "           1     0.3010    0.9947    0.4622       375\n",
      "\n",
      "    accuracy                         0.3006      1241\n",
      "   macro avg     0.1505    0.4973    0.2311      1241\n",
      "weighted avg     0.0910    0.3006    0.1397      1241\n",
      "\n",
      "[26] Label Model\n",
      "Total number of tokens missed:  51341\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000       866\n",
      "           1     0.3022    1.0000    0.4641       375\n",
      "\n",
      "    accuracy                         0.3022      1241\n",
      "   macro avg     0.1511    0.5000    0.2321      1241\n",
      "weighted avg     0.0913    0.3022    0.1402      1241\n",
      "\n",
      "[27] Label Model\n",
      "Total number of tokens missed:  51341\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9951    0.4665    0.6352       866\n",
      "           1     0.4467    0.9947    0.6165       375\n",
      "\n",
      "    accuracy                         0.6261      1241\n",
      "   macro avg     0.7209    0.7306    0.6259      1241\n",
      "weighted avg     0.8294    0.6261    0.6296      1241\n",
      "\n",
      "[28] Label Model\n",
      "Total number of tokens missed:  51341\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000       866\n",
      "           1     0.3010    0.9947    0.4622       375\n",
      "\n",
      "    accuracy                         0.3006      1241\n",
      "   macro avg     0.1505    0.4973    0.2311      1241\n",
      "weighted avg     0.0910    0.3006    0.1397      1241\n",
      "\n",
      "[29] Label Model\n",
      "Total number of tokens missed:  51341\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000       866\n",
      "           1     0.3022    1.0000    0.4641       375\n",
      "\n",
      "    accuracy                         0.3022      1241\n",
      "   macro avg     0.1511    0.5000    0.2321      1241\n",
      "weighted avg     0.0913    0.3022    0.1402      1241\n",
      "\n",
      "[30] Label Model\n",
      "Total number of tokens missed:  51341\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000       866\n",
      "           1     0.3022    1.0000    0.4641       375\n",
      "\n",
      "    accuracy                         0.3022      1241\n",
      "   macro avg     0.1511    0.5000    0.2321      1241\n",
      "weighted avg     0.0913    0.3022    0.1402      1241\n",
      "\n",
      "[31] Label Model\n",
      "Total number of tokens missed:  51341\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000       866\n",
      "           1     0.3022    1.0000    0.4641       375\n",
      "\n",
      "    accuracy                         0.3022      1241\n",
      "   macro avg     0.1511    0.5000    0.2321      1241\n",
      "weighted avg     0.0913    0.3022    0.1402      1241\n",
      "\n",
      "[32] Label Model\n",
      "Total number of tokens missed:  51341\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000       866\n",
      "           1     0.3022    1.0000    0.4641       375\n",
      "\n",
      "    accuracy                         0.3022      1241\n",
      "   macro avg     0.1511    0.5000    0.2321      1241\n",
      "weighted avg     0.0913    0.3022    0.1402      1241\n",
      "\n",
      "[33] Label Model\n",
      "Total number of tokens missed:  51341\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000       866\n",
      "           1     0.3022    1.0000    0.4641       375\n",
      "\n",
      "    accuracy                         0.3022      1241\n",
      "   macro avg     0.1511    0.5000    0.2321      1241\n",
      "weighted avg     0.0913    0.3022    0.1402      1241\n",
      "\n",
      "[34] Label Model\n",
      "Total number of tokens missed:  51341\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000       866\n",
      "           1     0.3022    1.0000    0.4641       375\n",
      "\n",
      "    accuracy                         0.3022      1241\n",
      "   macro avg     0.1511    0.5000    0.2321      1241\n",
      "weighted avg     0.0913    0.3022    0.1402      1241\n",
      "\n",
      "[35] Label Model\n",
      "Total number of tokens missed:  51341\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000       866\n",
      "           1     0.3022    1.0000    0.4641       375\n",
      "\n",
      "    accuracy                         0.3022      1241\n",
      "   macro avg     0.1511    0.5000    0.2321      1241\n",
      "weighted avg     0.0913    0.3022    0.1402      1241\n",
      "\n",
      "[36] Label Model\n",
      "Total number of tokens missed:  51341\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9951    0.4665    0.6352       866\n",
      "           1     0.4467    0.9947    0.6165       375\n",
      "\n",
      "    accuracy                         0.6261      1241\n",
      "   macro avg     0.7209    0.7306    0.6259      1241\n",
      "weighted avg     0.8294    0.6261    0.6296      1241\n",
      "\n",
      "[37] Label Model\n",
      "Total number of tokens missed:  51341\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000       866\n",
      "           1     0.3022    1.0000    0.4641       375\n",
      "\n",
      "    accuracy                         0.3022      1241\n",
      "   macro avg     0.1511    0.5000    0.2321      1241\n",
      "weighted avg     0.0913    0.3022    0.1402      1241\n",
      "\n",
      "[38] Label Model\n",
      "Total number of tokens missed:  51341\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9951    0.4665    0.6352       866\n",
      "           1     0.4467    0.9947    0.6165       375\n",
      "\n",
      "    accuracy                         0.6261      1241\n",
      "   macro avg     0.7209    0.7306    0.6259      1241\n",
      "weighted avg     0.8294    0.6261    0.6296      1241\n",
      "\n",
      "[39] Label Model\n",
      "Total number of tokens missed:  51341\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9951    0.4665    0.6352       866\n",
      "           1     0.4467    0.9947    0.6165       375\n",
      "\n",
      "    accuracy                         0.6261      1241\n",
      "   macro avg     0.7209    0.7306    0.6259      1241\n",
      "weighted avg     0.8294    0.6261    0.6296      1241\n",
      "\n",
      "[40] Label Model\n",
      "Total number of tokens missed:  51341\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9951    0.4665    0.6352       866\n",
      "           1     0.4467    0.9947    0.6165       375\n",
      "\n",
      "    accuracy                         0.6261      1241\n",
      "   macro avg     0.7209    0.7306    0.6259      1241\n",
      "weighted avg     0.8294    0.6261    0.6296      1241\n",
      "\n",
      "[41] Label Model\n",
      "Total number of tokens missed:  51341\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000       866\n",
      "           1     0.3022    1.0000    0.4641       375\n",
      "\n",
      "    accuracy                         0.3022      1241\n",
      "   macro avg     0.1511    0.5000    0.2321      1241\n",
      "weighted avg     0.0913    0.3022    0.1402      1241\n",
      "\n",
      "[42] Label Model\n",
      "Total number of tokens missed:  51341\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9951    0.4665    0.6352       866\n",
      "           1     0.4467    0.9947    0.6165       375\n",
      "\n",
      "    accuracy                         0.6261      1241\n",
      "   macro avg     0.7209    0.7306    0.6259      1241\n",
      "weighted avg     0.8294    0.6261    0.6296      1241\n",
      "\n",
      "[43] Label Model\n",
      "Total number of tokens missed:  51341\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000       866\n",
      "           1     0.3022    1.0000    0.4641       375\n",
      "\n",
      "    accuracy                         0.3022      1241\n",
      "   macro avg     0.1511    0.5000    0.2321      1241\n",
      "weighted avg     0.0913    0.3022    0.1402      1241\n",
      "\n",
      "[44] Label Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of tokens missed:  51341\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000       866\n",
      "           1     0.3010    0.9947    0.4622       375\n",
      "\n",
      "    accuracy                         0.3006      1241\n",
      "   macro avg     0.1505    0.4973    0.2311      1241\n",
      "weighted avg     0.0910    0.3006    0.1397      1241\n",
      "\n",
      "[45] Label Model\n",
      "Total number of tokens missed:  51341\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000       866\n",
      "           1     0.3022    1.0000    0.4641       375\n",
      "\n",
      "    accuracy                         0.3022      1241\n",
      "   macro avg     0.1511    0.5000    0.2321      1241\n",
      "weighted avg     0.0913    0.3022    0.1402      1241\n",
      "\n",
      "[46] Label Model\n",
      "Total number of tokens missed:  51341\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9951    0.4665    0.6352       866\n",
      "           1     0.4467    0.9947    0.6165       375\n",
      "\n",
      "    accuracy                         0.6261      1241\n",
      "   macro avg     0.7209    0.7306    0.6259      1241\n",
      "weighted avg     0.8294    0.6261    0.6296      1241\n",
      "\n",
      "[47] Label Model\n",
      "Total number of tokens missed:  51341\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000       866\n",
      "           1     0.3010    0.9947    0.4622       375\n",
      "\n",
      "    accuracy                         0.3006      1241\n",
      "   macro avg     0.1505    0.4973    0.2311      1241\n",
      "weighted avg     0.0910    0.3006    0.1397      1241\n",
      "\n",
      "[48] Label Model\n",
      "Total number of tokens missed:  51341\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000       866\n",
      "           1     0.3022    1.0000    0.4641       375\n",
      "\n",
      "    accuracy                         0.3022      1241\n",
      "   macro avg     0.1511    0.5000    0.2321      1241\n",
      "weighted avg     0.0913    0.3022    0.1402      1241\n",
      "\n",
      "[49] Label Model\n",
      "Total number of tokens missed:  51341\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9951    0.4665    0.6352       866\n",
      "           1     0.4467    0.9947    0.6165       375\n",
      "\n",
      "    accuracy                         0.6261      1241\n",
      "   macro avg     0.7209    0.7306    0.6259      1241\n",
      "weighted avg     0.8294    0.6261    0.6296      1241\n",
      "\n",
      "Save the best overall model, configuration and partition for this experiment level\n"
     ]
    }
   ],
   "source": [
    "# CandGen Version v4 (LFs = 12)\n",
    "\n",
    "predicted_s = train_plus(train_s_candidates, test_s_ebm_candidates, test_s_ebm_corr_candidates, Y_s, 's', paramgrid = param_grid, mode = 'pred')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "05079643",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparamater Search Space: 336\n",
      "Grid search over 50 configs\n",
      "[0] Label Model\n",
      "Total number of tokens missed:  51432\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9909    0.8361    0.9069       781\n",
      "           1     0.7393    0.9837    0.8442       369\n",
      "\n",
      "    accuracy                         0.8835      1150\n",
      "   macro avg     0.8651    0.9099    0.8756      1150\n",
      "weighted avg     0.9102    0.8835    0.8868      1150\n",
      "\n",
      "[1] Label Model\n",
      "Total number of tokens missed:  51432\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9909    0.8361    0.9069       781\n",
      "           1     0.7393    0.9837    0.8442       369\n",
      "\n",
      "    accuracy                         0.8835      1150\n",
      "   macro avg     0.8651    0.9099    0.8756      1150\n",
      "weighted avg     0.9102    0.8835    0.8868      1150\n",
      "\n",
      "[2] Label Model\n",
      "Total number of tokens missed:  51432\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000       781\n",
      "           1     0.3209    1.0000    0.4858       369\n",
      "\n",
      "    accuracy                         0.3209      1150\n",
      "   macro avg     0.1604    0.5000    0.2429      1150\n",
      "weighted avg     0.1030    0.3209    0.1559      1150\n",
      "\n",
      "[3] Label Model\n",
      "Total number of tokens missed:  51432\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000       781\n",
      "           1     0.3209    1.0000    0.4858       369\n",
      "\n",
      "    accuracy                         0.3209      1150\n",
      "   macro avg     0.1604    0.5000    0.2429      1150\n",
      "weighted avg     0.1030    0.3209    0.1559      1150\n",
      "\n",
      "[4] Label Model\n",
      "Total number of tokens missed:  51432\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000       781\n",
      "           1     0.3197    0.9946    0.4838       369\n",
      "\n",
      "    accuracy                         0.3191      1150\n",
      "   macro avg     0.1598    0.4973    0.2419      1150\n",
      "weighted avg     0.1026    0.3191    0.1553      1150\n",
      "\n",
      "[5] Label Model\n",
      "Total number of tokens missed:  51432\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9909    0.8361    0.9069       781\n",
      "           1     0.7393    0.9837    0.8442       369\n",
      "\n",
      "    accuracy                         0.8835      1150\n",
      "   macro avg     0.8651    0.9099    0.8756      1150\n",
      "weighted avg     0.9102    0.8835    0.8868      1150\n",
      "\n",
      "[6] Label Model\n",
      "Total number of tokens missed:  51432\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000       781\n",
      "           1     0.3209    1.0000    0.4858       369\n",
      "\n",
      "    accuracy                         0.3209      1150\n",
      "   macro avg     0.1604    0.5000    0.2429      1150\n",
      "weighted avg     0.1030    0.3209    0.1559      1150\n",
      "\n",
      "[7] Label Model\n",
      "Total number of tokens missed:  51432\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000       781\n",
      "           1     0.3209    1.0000    0.4858       369\n",
      "\n",
      "    accuracy                         0.3209      1150\n",
      "   macro avg     0.1604    0.5000    0.2429      1150\n",
      "weighted avg     0.1030    0.3209    0.1559      1150\n",
      "\n",
      "[8] Label Model\n",
      "Total number of tokens missed:  51432\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9909    0.8361    0.9069       781\n",
      "           1     0.7393    0.9837    0.8442       369\n",
      "\n",
      "    accuracy                         0.8835      1150\n",
      "   macro avg     0.8651    0.9099    0.8756      1150\n",
      "weighted avg     0.9102    0.8835    0.8868      1150\n",
      "\n",
      "[9] Label Model\n",
      "Total number of tokens missed:  51432\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000       781\n",
      "           1     0.3209    1.0000    0.4858       369\n",
      "\n",
      "    accuracy                         0.3209      1150\n",
      "   macro avg     0.1604    0.5000    0.2429      1150\n",
      "weighted avg     0.1030    0.3209    0.1559      1150\n",
      "\n",
      "[10] Label Model\n",
      "Total number of tokens missed:  51432\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000       781\n",
      "           1     0.3209    1.0000    0.4858       369\n",
      "\n",
      "    accuracy                         0.3209      1150\n",
      "   macro avg     0.1604    0.5000    0.2429      1150\n",
      "weighted avg     0.1030    0.3209    0.1559      1150\n",
      "\n",
      "[11] Label Model\n",
      "Total number of tokens missed:  51432\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9909    0.8361    0.9069       781\n",
      "           1     0.7393    0.9837    0.8442       369\n",
      "\n",
      "    accuracy                         0.8835      1150\n",
      "   macro avg     0.8651    0.9099    0.8756      1150\n",
      "weighted avg     0.9102    0.8835    0.8868      1150\n",
      "\n",
      "[12] Label Model\n",
      "Total number of tokens missed:  51432\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9909    0.8361    0.9069       781\n",
      "           1     0.7393    0.9837    0.8442       369\n",
      "\n",
      "    accuracy                         0.8835      1150\n",
      "   macro avg     0.8651    0.9099    0.8756      1150\n",
      "weighted avg     0.9102    0.8835    0.8868      1150\n",
      "\n",
      "[13] Label Model\n",
      "Total number of tokens missed:  51432\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000       781\n",
      "           1     0.3197    0.9946    0.4838       369\n",
      "\n",
      "    accuracy                         0.3191      1150\n",
      "   macro avg     0.1598    0.4973    0.2419      1150\n",
      "weighted avg     0.1026    0.3191    0.1553      1150\n",
      "\n",
      "[14] Label Model\n",
      "Total number of tokens missed:  51432\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9817    0.2740    0.4284       781\n",
      "           1     0.3916    0.9892    0.5611       369\n",
      "\n",
      "    accuracy                         0.5035      1150\n",
      "   macro avg     0.6866    0.6316    0.4948      1150\n",
      "weighted avg     0.7923    0.5035    0.4710      1150\n",
      "\n",
      "[15] Label Model\n",
      "Total number of tokens missed:  51432\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9909    0.8361    0.9069       781\n",
      "           1     0.7393    0.9837    0.8442       369\n",
      "\n",
      "    accuracy                         0.8835      1150\n",
      "   macro avg     0.8651    0.9099    0.8756      1150\n",
      "weighted avg     0.9102    0.8835    0.8868      1150\n",
      "\n",
      "[16] Label Model\n",
      "Total number of tokens missed:  51432\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000       781\n",
      "           1     0.3209    1.0000    0.4858       369\n",
      "\n",
      "    accuracy                         0.3209      1150\n",
      "   macro avg     0.1604    0.5000    0.2429      1150\n",
      "weighted avg     0.1030    0.3209    0.1559      1150\n",
      "\n",
      "[17] Label Model\n",
      "Total number of tokens missed:  51432\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000       781\n",
      "           1     0.3209    1.0000    0.4858       369\n",
      "\n",
      "    accuracy                         0.3209      1150\n",
      "   macro avg     0.1604    0.5000    0.2429      1150\n",
      "weighted avg     0.1030    0.3209    0.1559      1150\n",
      "\n",
      "[18] Label Model\n",
      "Total number of tokens missed:  51432\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9909    0.8361    0.9069       781\n",
      "           1     0.7393    0.9837    0.8442       369\n",
      "\n",
      "    accuracy                         0.8835      1150\n",
      "   macro avg     0.8651    0.9099    0.8756      1150\n",
      "weighted avg     0.9102    0.8835    0.8868      1150\n",
      "\n",
      "[19] Label Model\n",
      "Total number of tokens missed:  51432\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9909    0.8361    0.9069       781\n",
      "           1     0.7393    0.9837    0.8442       369\n",
      "\n",
      "    accuracy                         0.8835      1150\n",
      "   macro avg     0.8651    0.9099    0.8756      1150\n",
      "weighted avg     0.9102    0.8835    0.8868      1150\n",
      "\n",
      "[20] Label Model\n",
      "Total number of tokens missed:  51432\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000       781\n",
      "           1     0.3197    0.9946    0.4838       369\n",
      "\n",
      "    accuracy                         0.3191      1150\n",
      "   macro avg     0.1598    0.4973    0.2419      1150\n",
      "weighted avg     0.1026    0.3191    0.1553      1150\n",
      "\n",
      "[21] Label Model\n",
      "Total number of tokens missed:  51432\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9817    0.2740    0.4284       781\n",
      "           1     0.3916    0.9892    0.5611       369\n",
      "\n",
      "    accuracy                         0.5035      1150\n",
      "   macro avg     0.6866    0.6316    0.4948      1150\n",
      "weighted avg     0.7923    0.5035    0.4710      1150\n",
      "\n",
      "[22] Label Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of tokens missed:  51432\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000       781\n",
      "           1     0.3209    1.0000    0.4858       369\n",
      "\n",
      "    accuracy                         0.3209      1150\n",
      "   macro avg     0.1604    0.5000    0.2429      1150\n",
      "weighted avg     0.1030    0.3209    0.1559      1150\n",
      "\n",
      "[23] Label Model\n",
      "Total number of tokens missed:  51432\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000       781\n",
      "           1     0.3197    0.9946    0.4838       369\n",
      "\n",
      "    accuracy                         0.3191      1150\n",
      "   macro avg     0.1598    0.4973    0.2419      1150\n",
      "weighted avg     0.1026    0.3191    0.1553      1150\n",
      "\n",
      "[24] Label Model\n",
      "Total number of tokens missed:  51432\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000       781\n",
      "           1     0.3209    1.0000    0.4858       369\n",
      "\n",
      "    accuracy                         0.3209      1150\n",
      "   macro avg     0.1604    0.5000    0.2429      1150\n",
      "weighted avg     0.1030    0.3209    0.1559      1150\n",
      "\n",
      "[25] Label Model\n",
      "Total number of tokens missed:  51432\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000       781\n",
      "           1     0.3197    0.9946    0.4838       369\n",
      "\n",
      "    accuracy                         0.3191      1150\n",
      "   macro avg     0.1598    0.4973    0.2419      1150\n",
      "weighted avg     0.1026    0.3191    0.1553      1150\n",
      "\n",
      "[26] Label Model\n",
      "Total number of tokens missed:  51432\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000       781\n",
      "           1     0.3209    1.0000    0.4858       369\n",
      "\n",
      "    accuracy                         0.3209      1150\n",
      "   macro avg     0.1604    0.5000    0.2429      1150\n",
      "weighted avg     0.1030    0.3209    0.1559      1150\n",
      "\n",
      "[27] Label Model\n",
      "Total number of tokens missed:  51432\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9909    0.8361    0.9069       781\n",
      "           1     0.7393    0.9837    0.8442       369\n",
      "\n",
      "    accuracy                         0.8835      1150\n",
      "   macro avg     0.8651    0.9099    0.8756      1150\n",
      "weighted avg     0.9102    0.8835    0.8868      1150\n",
      "\n",
      "[28] Label Model\n",
      "Total number of tokens missed:  51432\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000       781\n",
      "           1     0.3209    1.0000    0.4858       369\n",
      "\n",
      "    accuracy                         0.3209      1150\n",
      "   macro avg     0.1604    0.5000    0.2429      1150\n",
      "weighted avg     0.1030    0.3209    0.1559      1150\n",
      "\n",
      "[29] Label Model\n",
      "Total number of tokens missed:  51432\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000       781\n",
      "           1     0.3209    1.0000    0.4858       369\n",
      "\n",
      "    accuracy                         0.3209      1150\n",
      "   macro avg     0.1604    0.5000    0.2429      1150\n",
      "weighted avg     0.1030    0.3209    0.1559      1150\n",
      "\n",
      "[30] Label Model\n",
      "Total number of tokens missed:  51432\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000       781\n",
      "           1     0.3209    1.0000    0.4858       369\n",
      "\n",
      "    accuracy                         0.3209      1150\n",
      "   macro avg     0.1604    0.5000    0.2429      1150\n",
      "weighted avg     0.1030    0.3209    0.1559      1150\n",
      "\n",
      "[31] Label Model\n",
      "Total number of tokens missed:  51432\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000       781\n",
      "           1     0.3209    1.0000    0.4858       369\n",
      "\n",
      "    accuracy                         0.3209      1150\n",
      "   macro avg     0.1604    0.5000    0.2429      1150\n",
      "weighted avg     0.1030    0.3209    0.1559      1150\n",
      "\n",
      "[32] Label Model\n",
      "Total number of tokens missed:  51432\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000       781\n",
      "           1     0.3209    1.0000    0.4858       369\n",
      "\n",
      "    accuracy                         0.3209      1150\n",
      "   macro avg     0.1604    0.5000    0.2429      1150\n",
      "weighted avg     0.1030    0.3209    0.1559      1150\n",
      "\n",
      "[33] Label Model\n",
      "Total number of tokens missed:  51432\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000       781\n",
      "           1     0.3209    1.0000    0.4858       369\n",
      "\n",
      "    accuracy                         0.3209      1150\n",
      "   macro avg     0.1604    0.5000    0.2429      1150\n",
      "weighted avg     0.1030    0.3209    0.1559      1150\n",
      "\n",
      "[34] Label Model\n",
      "Total number of tokens missed:  51432\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000       781\n",
      "           1     0.3209    1.0000    0.4858       369\n",
      "\n",
      "    accuracy                         0.3209      1150\n",
      "   macro avg     0.1604    0.5000    0.2429      1150\n",
      "weighted avg     0.1030    0.3209    0.1559      1150\n",
      "\n",
      "[35] Label Model\n",
      "Total number of tokens missed:  51432\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000       781\n",
      "           1     0.3209    1.0000    0.4858       369\n",
      "\n",
      "    accuracy                         0.3209      1150\n",
      "   macro avg     0.1604    0.5000    0.2429      1150\n",
      "weighted avg     0.1030    0.3209    0.1559      1150\n",
      "\n",
      "[36] Label Model\n",
      "Total number of tokens missed:  51432\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9909    0.8361    0.9069       781\n",
      "           1     0.7393    0.9837    0.8442       369\n",
      "\n",
      "    accuracy                         0.8835      1150\n",
      "   macro avg     0.8651    0.9099    0.8756      1150\n",
      "weighted avg     0.9102    0.8835    0.8868      1150\n",
      "\n",
      "[37] Label Model\n",
      "Total number of tokens missed:  51432\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000       781\n",
      "           1     0.3209    1.0000    0.4858       369\n",
      "\n",
      "    accuracy                         0.3209      1150\n",
      "   macro avg     0.1604    0.5000    0.2429      1150\n",
      "weighted avg     0.1030    0.3209    0.1559      1150\n",
      "\n",
      "[38] Label Model\n",
      "Total number of tokens missed:  51432\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9909    0.8361    0.9069       781\n",
      "           1     0.7393    0.9837    0.8442       369\n",
      "\n",
      "    accuracy                         0.8835      1150\n",
      "   macro avg     0.8651    0.9099    0.8756      1150\n",
      "weighted avg     0.9102    0.8835    0.8868      1150\n",
      "\n",
      "[39] Label Model\n",
      "Total number of tokens missed:  51432\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9909    0.8361    0.9069       781\n",
      "           1     0.7393    0.9837    0.8442       369\n",
      "\n",
      "    accuracy                         0.8835      1150\n",
      "   macro avg     0.8651    0.9099    0.8756      1150\n",
      "weighted avg     0.9102    0.8835    0.8868      1150\n",
      "\n",
      "[40] Label Model\n",
      "Total number of tokens missed:  51432\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9909    0.8361    0.9069       781\n",
      "           1     0.7393    0.9837    0.8442       369\n",
      "\n",
      "    accuracy                         0.8835      1150\n",
      "   macro avg     0.8651    0.9099    0.8756      1150\n",
      "weighted avg     0.9102    0.8835    0.8868      1150\n",
      "\n",
      "[41] Label Model\n",
      "Total number of tokens missed:  51432\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000       781\n",
      "           1     0.3209    1.0000    0.4858       369\n",
      "\n",
      "    accuracy                         0.3209      1150\n",
      "   macro avg     0.1604    0.5000    0.2429      1150\n",
      "weighted avg     0.1030    0.3209    0.1559      1150\n",
      "\n",
      "[42] Label Model\n",
      "Total number of tokens missed:  51432\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9909    0.8361    0.9069       781\n",
      "           1     0.7393    0.9837    0.8442       369\n",
      "\n",
      "    accuracy                         0.8835      1150\n",
      "   macro avg     0.8651    0.9099    0.8756      1150\n",
      "weighted avg     0.9102    0.8835    0.8868      1150\n",
      "\n",
      "[43] Label Model\n",
      "Total number of tokens missed:  51432\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000       781\n",
      "           1     0.3209    1.0000    0.4858       369\n",
      "\n",
      "    accuracy                         0.3209      1150\n",
      "   macro avg     0.1604    0.5000    0.2429      1150\n",
      "weighted avg     0.1030    0.3209    0.1559      1150\n",
      "\n",
      "[44] Label Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of tokens missed:  51432\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9817    0.2740    0.4284       781\n",
      "           1     0.3916    0.9892    0.5611       369\n",
      "\n",
      "    accuracy                         0.5035      1150\n",
      "   macro avg     0.6866    0.6316    0.4948      1150\n",
      "weighted avg     0.7923    0.5035    0.4710      1150\n",
      "\n",
      "[45] Label Model\n",
      "Total number of tokens missed:  51432\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000       781\n",
      "           1     0.3209    1.0000    0.4858       369\n",
      "\n",
      "    accuracy                         0.3209      1150\n",
      "   macro avg     0.1604    0.5000    0.2429      1150\n",
      "weighted avg     0.1030    0.3209    0.1559      1150\n",
      "\n",
      "[46] Label Model\n",
      "Total number of tokens missed:  51432\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9909    0.8361    0.9069       781\n",
      "           1     0.7393    0.9837    0.8442       369\n",
      "\n",
      "    accuracy                         0.8835      1150\n",
      "   macro avg     0.8651    0.9099    0.8756      1150\n",
      "weighted avg     0.9102    0.8835    0.8868      1150\n",
      "\n",
      "[47] Label Model\n",
      "Total number of tokens missed:  51432\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000       781\n",
      "           1     0.3209    1.0000    0.4858       369\n",
      "\n",
      "    accuracy                         0.3209      1150\n",
      "   macro avg     0.1604    0.5000    0.2429      1150\n",
      "weighted avg     0.1030    0.3209    0.1559      1150\n",
      "\n",
      "[48] Label Model\n",
      "Total number of tokens missed:  51432\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000       781\n",
      "           1     0.3209    1.0000    0.4858       369\n",
      "\n",
      "    accuracy                         0.3209      1150\n",
      "   macro avg     0.1604    0.5000    0.2429      1150\n",
      "weighted avg     0.1030    0.3209    0.1559      1150\n",
      "\n",
      "[49] Label Model\n",
      "Total number of tokens missed:  51432\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9909    0.8361    0.9069       781\n",
      "           1     0.7393    0.9837    0.8442       369\n",
      "\n",
      "    accuracy                         0.8835      1150\n",
      "   macro avg     0.8651    0.9099    0.8756      1150\n",
      "weighted avg     0.9102    0.8835    0.8868      1150\n",
      "\n",
      "Save the best overall model, configuration and partition for this experiment level\n"
     ]
    }
   ],
   "source": [
    "# CandGen Version v4 (LFs = 11)\n",
    "\n",
    "predicted_s = train_plus(train_s_candidates, test_s_ebm_candidates, test_s_ebm_corr_candidates, Y_s, 's', paramgrid = param_grid, mode = 'pred')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a260d6ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

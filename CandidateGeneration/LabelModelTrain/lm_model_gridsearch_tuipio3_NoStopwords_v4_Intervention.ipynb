{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b3b4e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import enum\n",
    "import glob\n",
    "import os\n",
    "from hashlib import new\n",
    "from pathlib import Path\n",
    "import time\n",
    "from itertools import product\n",
    "\n",
    "import functools\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from snorkel.labeling.model import LabelModel as LMsnorkel\n",
    "from snorkel.labeling.model import MajorityLabelVoter\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import itertools\n",
    "import ast\n",
    "import time \n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3801c730",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize seed\n",
    "seed_i = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0cd54fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import json\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7798c0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.exceptions import UndefinedMetricWarning\n",
    "\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d1d2219",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list2Nested(l, nested_length):\n",
    "    return [l[i:i+nested_length] for i in range(0, len(l), nested_length)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "daaad8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "labelModel_mapper_LF = {1:1, -1:0, 0:-1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0638a0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import LMutils\n",
    "\n",
    "train_file = '/mnt/nas2/results/Results/systematicReview/distant_pico/EBM_PICO_GT/v4/gt/train_ebm_labels_tui_pio3.tsv'\n",
    "training_data = pd.read_csv(train_file, sep='\\t', header=0)\n",
    "\n",
    "ebm_test_file = '/mnt/nas2/results/Results/systematicReview/distant_pico/EBM_PICO_GT/v4/gt/test_ebm_labels_tui_pio3.tsv'\n",
    "test_ebm_data = pd.read_csv(ebm_test_file, sep='\\t', header=0)\n",
    "test_ebm_data.rename( columns={'Unnamed: 0':'series'}, inplace=True )\n",
    "\n",
    "physio_test_file = '/mnt/nas2/results/Results/systematicReview/distant_pico/EBM_PICO_GT/v4/gt/test_physio_labels_tui_pio3.tsv'\n",
    "test_physio_data = pd.read_csv(physio_test_file, sep='\\t', header=0)\n",
    "test_physio_data.rename( columns={'Unnamed: 0':'series'}, inplace=True )\n",
    "\n",
    "ebm_test_corrected_file = '/mnt/nas2/results/Results/systematicReview/distant_pico/EBM_PICO_GT/v4/gt/test_ebm_correctedlabels_tui_pio3.tsv'\n",
    "test_ebm_corrected_data = pd.read_csv(ebm_test_corrected_file, sep='\\t', header=0)\n",
    "test_ebm_corrected_data.rename( columns={'Unnamed: 0':'series'}, inplace=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fff28521",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_df(df):\n",
    "\n",
    "    df_series = [ index for index, value in df.tokens.items() for word in ast.literal_eval(value) ]\n",
    "    df_tokens = [ word for index, value in df.tokens.items() for word in ast.literal_eval(value) ]\n",
    "    df_pos = [ word for index, value in df.pos.items() for word in ast.literal_eval(value) ]\n",
    "    df_offsets = [ word for index, value in df.offsets.items() for word in ast.literal_eval(value) ]\n",
    "\n",
    "\n",
    "    df_p = [ int(lab) for index, value in df.p.items() for lab in ast.literal_eval(value) ]\n",
    "    df_p_fine = [ int(lab) for index, value in df.p_f.items() for lab in ast.literal_eval(value) ]\n",
    "    df_i = [ int(lab) for index, value in df.i.items() for lab in ast.literal_eval(value) ]\n",
    "    df_i_fine = [ int(lab) for index, value in df.i_f.items() for lab in ast.literal_eval(value) ]\n",
    "    df_o = [ int(lab) for index, value in df.o.items() for lab in ast.literal_eval(value) ]\n",
    "    df_o_fine = [ int(lab) for index, value in df.o_f.items() for lab in ast.literal_eval(value) ]\n",
    "    df_s = [ int(lab) for index, value in df.s.items() for lab in ast.literal_eval(value) ]\n",
    "    df_s_fine = [ int(lab) for index, value in df.s_f.items() for lab in ast.literal_eval(value) ]\n",
    "    \n",
    "    df_flattened = pd.DataFrame({ 'series': df_series,\n",
    "                        'tokens' : df_tokens,\n",
    "                        'offsets': df_offsets,\n",
    "                        'pos': df_pos,\n",
    "                        'p' : df_p,\n",
    "                        'i' : df_i,\n",
    "                        'o' : df_o,\n",
    "                        's' : df_s,\n",
    "                        'p_f' : df_p_fine,\n",
    "                        'i_f' : df_i_fine,\n",
    "                        'o_f' : df_o_fine,\n",
    "                        's_f' : df_s_fine})\n",
    "    \n",
    "    return df_flattened"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b8e07f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten the dataframes (currently only the training dataframe and test ebm dataframe with corrected labels can be flattened)\n",
    "data_df = flatten_df(training_data)\n",
    "test_ebm_data = flatten_df(test_ebm_data)\n",
    "test_ebm_corr_df = flatten_df(test_ebm_corrected_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f0c041c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "series = [\n",
    "    data_df.series.to_numpy() ,\n",
    "    test_ebm_data.series.to_numpy() ,\n",
    "    test_physio_data.series.to_numpy(),   \n",
    "    test_ebm_corr_df.series.to_numpy()\n",
    "]\n",
    "\n",
    "\n",
    "sents = [\n",
    "    data_df.tokens.to_numpy() ,\n",
    "    test_ebm_data.tokens.to_numpy() ,\n",
    "    test_physio_data.tokens.to_numpy(),   \n",
    "    test_ebm_corr_df.tokens.to_numpy()    \n",
    "]\n",
    "\n",
    "\n",
    "part_of_speech = [\n",
    "    data_df.pos.to_numpy() ,\n",
    "    test_ebm_data.pos.to_numpy() ,\n",
    "    test_physio_data.pos.to_numpy(),   \n",
    "    test_ebm_corr_df.pos.to_numpy()     \n",
    "]\n",
    "\n",
    "\n",
    "offsets = [\n",
    "    data_df.offsets.to_numpy() ,\n",
    "    test_ebm_data.offsets.to_numpy() ,\n",
    "    test_physio_data.offsets.to_numpy(),   \n",
    "    test_ebm_corr_df.offsets.to_numpy() \n",
    "]\n",
    "\n",
    "\n",
    "Y_p = [\n",
    "    data_df.p.to_numpy() , # 0 -7\n",
    "    data_df.p_f.to_numpy() , # 1 -6\n",
    "    test_ebm_data.p.to_numpy() , # 2 -5\n",
    "    test_ebm_data.p_f.to_numpy() , # 3 -4\n",
    "    test_physio_data.p.to_numpy(),  # 4 -3\n",
    "    test_ebm_corr_df.p.to_numpy(),   # 5 -2\n",
    "    test_ebm_corr_df.p_f.to_numpy() # 6 -1\n",
    "]\n",
    "\n",
    "\n",
    "Y_i = [\n",
    "    data_df.i.to_numpy() , # 0 -7\n",
    "    data_df.i_f.to_numpy() , # 1 -6\n",
    "    test_ebm_data.i.to_numpy() , # 2 -5\n",
    "    test_ebm_data.i_f.to_numpy() , # 3 -4\n",
    "    test_physio_data.i.to_numpy(),  # 4 -3\n",
    "    test_ebm_corr_df.i.to_numpy(),   # 5 -2\n",
    "    test_ebm_corr_df.i_f.to_numpy() # 6 -1\n",
    "]\n",
    "\n",
    "\n",
    "Y_o = [\n",
    "    data_df.o.to_numpy() ,\n",
    "    data_df.o_f.to_numpy() ,\n",
    "    test_ebm_data.o.to_numpy() ,\n",
    "    test_physio_data.o.to_numpy() \n",
    "]\n",
    "\n",
    "Y_s = [\n",
    "    data_df.s.to_numpy() , # 0 -7\n",
    "    data_df.s_f.to_numpy() , # 1 -6\n",
    "    test_ebm_data.s.to_numpy() , # 2 -5\n",
    "    test_ebm_data.s_f.to_numpy() , # 3 -4\n",
    "    test_physio_data.s.to_numpy(),  # 4 -3\n",
    "    test_ebm_corr_df.s.to_numpy(),   # 5 -2\n",
    "    test_ebm_corr_df.s_f.to_numpy() # 6 -1\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fd0f16cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write data for error analysis\n",
    "\n",
    "error_analysis_ebm_p = pd.DataFrame({'tokens' : test_ebm_data.tokens,\n",
    "                                'participant' : test_ebm_data.p,\n",
    "                                'participant_fine' : test_ebm_data.p_f }, \n",
    "                                columns=['tokens','participant', 'participant_fine'])\n",
    "\n",
    "#error_analysis_ebm_p.to_csv (r'/mnt/nas2/results/Results/systematicReview/distant_pico/EBM_PICO_GT/error_analysis/test_ebmgold_p', index = None, header=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c4c4068d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write data for error analysis\n",
    "\n",
    "error_analysis_ebmcorr_p = pd.DataFrame({'tokens' : test_ebm_corr_df.tokens,\n",
    "                                'participant' : test_ebm_corr_df.p,\n",
    "                                'participant_fine' : test_ebm_corr_df.p_f }, \n",
    "                                columns=['tokens','participant', 'participant_fine'])\n",
    "\n",
    "#error_analysis_ebmcorr_p.to_csv (r'/mnt/nas2/results/Results/systematicReview/distant_pico/EBM_PICO_GT/error_analysis/test_ebmgoldcorr_p', index = None, header=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0c7fe1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_list(data_column):\n",
    "    return [ word for index, value in data_column.items() for word in ast.literal_eval(value) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "35850d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_array(data_column):\n",
    "    return np.array( [ word for index, value in data_column.items() for word in ast.literal_eval(value) ] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a9f6e149",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_to_array(label_column):\n",
    "    return np.array( [ labelModel_mapper_LF[int(lab)] for index, value in label_column.items() for k, lab in ast.literal_eval(value).items() ] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b873406f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lfs(indir):\n",
    "    \n",
    "    pathlist = Path(indir).glob('**/*.tsv')\n",
    "\n",
    "    tokens = ''\n",
    "\n",
    "    lfs = dict()\n",
    "    lfs_lm = dict()\n",
    "\n",
    "    for counter, file in enumerate(pathlist):\n",
    "        #print(file)\n",
    "       \n",
    "        if '/I/' in str(file) and '_negs' not in str(file):\n",
    "            #print(file)\n",
    "\n",
    "            k = str( file ).split('/v4/')[-1].replace('.tsv', '').replace('/', '_')\n",
    "            mypath = Path(file)\n",
    "            if mypath.stat().st_size != 0:\n",
    "                data = pd.read_csv(file, sep='\\t', header=0)\n",
    "\n",
    "                data_tokens = data.tokens\n",
    "                if len(tokens) < 5:\n",
    "                    tokens = df_to_array(data_tokens)\n",
    "\n",
    "                data_labels = data.labels\n",
    "                labels = dict_to_array(data_labels)\n",
    "                if len(labels) != len(tokens):\n",
    "                    print(k, len(labels) , len(tokens) )\n",
    "                lfs[k] = labels\n",
    "\n",
    "\n",
    "    print( 'Total number of tokens in validation set: ', len(tokens) )\n",
    "    print( 'Total number of LFs in the dictionary', len(lfs) )\n",
    "    \n",
    "    return lfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a1119c42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of tokens in validation set:  1303169\n",
      "Total number of LFs in the dictionary 287\n"
     ]
    }
   ],
   "source": [
    "indir = '/mnt/nas2/results/Results/systematicReview/distant_pico/training_ebm_candidate_generation/v4'\n",
    "train_ebm_lfs = get_lfs(indir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "456a19e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of tokens in validation set:  52582\n",
      "Total number of LFs in the dictionary 287\n"
     ]
    }
   ],
   "source": [
    "indir_test_ebm_corr = '/mnt/nas2/results/Results/systematicReview/distant_pico/test_ebm_anjani_candidate_generation/v4'\n",
    "test_ebm_corr_lfs = get_lfs(indir_test_ebm_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "58ac9849",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of tokens in validation set:  51784\n",
      "Total number of LFs in the dictionary 287\n"
     ]
    }
   ],
   "source": [
    "indir_test_ebm = '/mnt/nas2/results/Results/systematicReview/distant_pico/test_ebm_candidate_generation/v4'\n",
    "test_ebm_lfs = get_lfs(indir_test_ebm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "370133ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of tokens in validation set:  52504\n",
      "Total number of LFs in the dictionary 287\n"
     ]
    }
   ],
   "source": [
    "indir_test_physio = '/mnt/nas2/results/Results/systematicReview/distant_pico/test_physio_candidate_generation/v4'\n",
    "test_physio_lfs = get_lfs(indir_test_physio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4392530f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping no positive label LFs\n"
     ]
    }
   ],
   "source": [
    "# Remove the annotations where there are no positive labels\n",
    "print('Dropping no positive label LFs')\n",
    "\n",
    "def drop_nopositive(lfs_d):\n",
    "    \n",
    "    dropped_no_positives = dict()\n",
    "\n",
    "    for k, v in lfs_d.items():\n",
    "\n",
    "        if len(set(v)) < 3:\n",
    "            if 1 in list(set(v)):\n",
    "                dropped_no_positives[k] = v\n",
    "        else:\n",
    "            dropped_no_positives[k] = v\n",
    "            \n",
    "    return dropped_no_positives\n",
    "\n",
    "#lfs_dropped = drop_nopositive(lfs)\n",
    "#print('Number of LFs: ', len(lfs_dropped))\n",
    "#lfs_ebm_corr_dropped = drop_nopositive(test_ebm_corr_lfs)\n",
    "#print('Number of LFs: ', len(lfs_ebm_corr_dropped))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "001d73ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lf_levels(umls_d:dict, pattern:str, picos:str):\n",
    "\n",
    "    umls_level = dict()\n",
    "\n",
    "    for key, value in umls_d.items():   # iter on both keys and values\n",
    "        search_pattern = pattern + picos\n",
    "        if key.startswith(search_pattern):\n",
    "            k = str(key).split('_')[-1]\n",
    "            umls_level[ k ] = value\n",
    "\n",
    "    return umls_level\n",
    "\n",
    "\n",
    "# Level 1: UMLS\n",
    "umls_p = [\n",
    "    lf_levels(train_ebm_lfs, name, 'P') \n",
    "    for i, name in enumerate(['UMLS_direct_', 'UMLS_fuzzy_'])\n",
    "]\n",
    "\n",
    "umls_p_testcorrected = [\n",
    "    lf_levels(test_ebm_corr_lfs, name, 'P') \n",
    "    for i, name in enumerate(['UMLS_direct_', 'UMLS_fuzzy_'])\n",
    "]\n",
    "\n",
    "umls_p_testebm = [\n",
    "    lf_levels(test_ebm_lfs, name, 'P') \n",
    "    for i, name in enumerate(['UMLS_direct_', 'UMLS_fuzzy_'])\n",
    "]\n",
    "\n",
    "umls_p_testphysio = [\n",
    "    lf_levels(test_physio_lfs, name, 'P') \n",
    "    for i, name in enumerate(['UMLS_direct_', 'UMLS_fuzzy_'])\n",
    "]\n",
    "\n",
    "# ------------------------------------------------------------------------\n",
    "\n",
    "umls_i = [\n",
    "    lf_levels(train_ebm_lfs, name, 'I') \n",
    "    for i, name in enumerate(['UMLS_direct_', 'UMLS_fuzzy_'])\n",
    "]\n",
    "\n",
    "umls_i_testcorrected = [\n",
    "    lf_levels(test_ebm_corr_lfs, name, 'I') \n",
    "    for i, name in enumerate(['UMLS_direct_', 'UMLS_fuzzy_'])\n",
    "]\n",
    "\n",
    "umls_i_testebm = [\n",
    "    lf_levels(test_ebm_lfs, name, 'I') \n",
    "    for i, name in enumerate(['UMLS_direct_', 'UMLS_fuzzy_'])\n",
    "]\n",
    "\n",
    "umls_i_testphysio = [\n",
    "    lf_levels(test_physio_lfs, name, 'I') \n",
    "    for i, name in enumerate(['UMLS_direct_', 'UMLS_fuzzy_'])\n",
    "]\n",
    "\n",
    "# ------------------------------------------------------------------------\n",
    "\n",
    "umls_o = [\n",
    "    lf_levels(train_ebm_lfs, name, 'O') \n",
    "    for i, name in enumerate(['UMLS_direct_', 'UMLS_fuzzy_'])\n",
    "]\n",
    "\n",
    "umls_o_testcorrected = [\n",
    "    lf_levels(test_ebm_corr_lfs, name, 'O') \n",
    "    for i, name in enumerate(['UMLS_direct_', 'UMLS_fuzzy_'])\n",
    "]\n",
    "\n",
    "umls_o_testebm = [\n",
    "    lf_levels(test_ebm_lfs, name, 'O') \n",
    "    for i, name in enumerate(['UMLS_direct_', 'UMLS_fuzzy_'])\n",
    "]\n",
    "\n",
    "umls_o_testphysio = [\n",
    "    lf_levels(test_physio_lfs, name, 'O') \n",
    "    for i, name in enumerate(['UMLS_direct_', 'UMLS_fuzzy_'])\n",
    "]\n",
    "\n",
    "# ------------------------------------------------------------------------\n",
    "# ------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "# Level 2: non UMLS\n",
    "nonumls_p = [\n",
    "    lf_levels(train_ebm_lfs, name, 'P') \n",
    "    for i, name in enumerate(['nonUMLS_direct_', 'nonUMLS_fuzzy_'])\n",
    "]\n",
    "\n",
    "nonumls_p_testcorrected = [\n",
    "    lf_levels(test_ebm_corr_lfs, name, 'P') \n",
    "    for i, name in enumerate(['nonUMLS_direct_', 'nonUMLS_fuzzy_'])\n",
    "]\n",
    "\n",
    "nonumls_p_testebm = [\n",
    "    lf_levels(test_ebm_lfs, name, 'P') \n",
    "    for i, name in enumerate(['nonUMLS_direct_', 'nonUMLS_fuzzy_'])\n",
    "]\n",
    "\n",
    "nonumls_p_testphysio = [\n",
    "    lf_levels(test_physio_lfs, name, 'P') \n",
    "    for i, name in enumerate(['nonUMLS_direct_', 'nonUMLS_fuzzy_'])\n",
    "]\n",
    "\n",
    "# ------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "nonumls_i = [\n",
    "    lf_levels(train_ebm_lfs, name, 'I') \n",
    "    for i, name in enumerate(['nonUMLS_direct_', 'nonUMLS_fuzzy_'])\n",
    "]\n",
    "\n",
    "nonumls_i_testcorrected = [\n",
    "    lf_levels(test_ebm_corr_lfs, name, 'I') \n",
    "    for i, name in enumerate(['nonUMLS_direct_', 'nonUMLS_fuzzy_'])\n",
    "]\n",
    "\n",
    "nonumls_i_testebm = [\n",
    "    lf_levels(test_ebm_lfs, name, 'I') \n",
    "    for i, name in enumerate(['nonUMLS_direct_', 'nonUMLS_fuzzy_'])\n",
    "]\n",
    "\n",
    "nonumls_i_testphysio = [\n",
    "    lf_levels(test_physio_lfs, name, 'I') \n",
    "    for i, name in enumerate(['nonUMLS_direct_', 'nonUMLS_fuzzy_'])\n",
    "]\n",
    "\n",
    "# ------------------------------------------------------------------------\n",
    "\n",
    "nonumls_o = [\n",
    "    lf_levels(train_ebm_lfs, name, 'O') \n",
    "    for i, name in enumerate(['nonUMLS_direct_', 'nonUMLS_fuzzy_'])\n",
    "]\n",
    "\n",
    "nonumls_o_testcorrected = [\n",
    "    lf_levels(test_ebm_corr_lfs, name, 'O') \n",
    "    for i, name in enumerate(['nonUMLS_direct_', 'nonUMLS_fuzzy_'])\n",
    "]\n",
    "\n",
    "nonumls_o_testebm = [\n",
    "    lf_levels(test_ebm_lfs, name, 'O') \n",
    "    for i, name in enumerate(['nonUMLS_direct_', 'nonUMLS_fuzzy_'])\n",
    "]\n",
    "\n",
    "nonumls_o_testphysio = [\n",
    "    lf_levels(test_physio_lfs, name, 'O') \n",
    "    for i, name in enumerate(['nonUMLS_direct_', 'nonUMLS_fuzzy_'])\n",
    "]\n",
    "\n",
    "# ------------------------------------------------------------------------\n",
    "# ------------------------------------------------------------------------\n",
    "\n",
    "# Level 3: DS\n",
    "ds_p = [\n",
    "    lf_levels(train_ebm_lfs, name, 'P') \n",
    "    for i, name in enumerate(['ds_direct_', 'ds_fuzzy_'])\n",
    "]\n",
    "\n",
    "ds_p_testcorrected = [\n",
    "    lf_levels(test_ebm_corr_lfs, name, 'P') \n",
    "    for i, name in enumerate(['ds_direct_', 'ds_fuzzy_'])\n",
    "]\n",
    "\n",
    "ds_p_testebm = [\n",
    "    lf_levels(test_ebm_lfs, name, 'P') \n",
    "    for i, name in enumerate(['ds_direct_', 'ds_fuzzy_'])\n",
    "]\n",
    "\n",
    "ds_p_testphysio = [\n",
    "    lf_levels(test_physio_lfs, name, 'P') \n",
    "    for i, name in enumerate(['ds_direct_', 'ds_fuzzy_'])\n",
    "]\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------------\n",
    "\n",
    "ds_i = [\n",
    "    lf_levels(train_ebm_lfs, name, 'I') \n",
    "    for i, name in enumerate(['ds_direct_', 'ds_fuzzy_'])\n",
    "]\n",
    "\n",
    "ds_i_testcorrected = [\n",
    "    lf_levels(test_ebm_corr_lfs, name, 'I') \n",
    "    for i, name in enumerate(['ds_direct_', 'ds_fuzzy_'])\n",
    "]\n",
    "\n",
    "ds_i_testebm = [\n",
    "    lf_levels(test_ebm_lfs, name, 'I') \n",
    "    for i, name in enumerate(['ds_direct_', 'ds_fuzzy_'])\n",
    "]\n",
    "\n",
    "ds_i_testphysio = [\n",
    "    lf_levels(test_physio_lfs, name, 'I') \n",
    "    for i, name in enumerate(['ds_direct_', 'ds_fuzzy_'])\n",
    "]\n",
    "\n",
    "# ------------------------------------------------------------------------\n",
    "\n",
    "ds_o = [\n",
    "    lf_levels(train_ebm_lfs, name, 'O') \n",
    "    for i, name in enumerate(['ds_direct_', 'ds_fuzzy_'])\n",
    "]\n",
    "\n",
    "ds_o_testcorrected = [\n",
    "    lf_levels(test_ebm_corr_lfs, name, 'O') \n",
    "    for i, name in enumerate(['ds_direct_', 'ds_fuzzy_'])\n",
    "]\n",
    "\n",
    "ds_o_testebm = [\n",
    "    lf_levels(test_ebm_lfs, name, 'O') \n",
    "    for i, name in enumerate(['ds_direct_', 'ds_fuzzy_'])\n",
    "]\n",
    "\n",
    "ds_o_testphysio = [\n",
    "    lf_levels(test_physio_lfs, name, 'O') \n",
    "    for i, name in enumerate(['ds_direct_', 'ds_fuzzy_'])\n",
    "]\n",
    "\n",
    "# ------------------------------------------------------------------------\n",
    "# ------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "# Level 4: dictionary, rules, heuristics\n",
    "heur_p = [\n",
    "    lf_levels(train_ebm_lfs, name, 'P') \n",
    "    for i, name in enumerate(['heuristics_direct_'])\n",
    "]\n",
    "\n",
    "heur_p_testcorrected = [\n",
    "    lf_levels(test_ebm_corr_lfs, name, 'P') \n",
    "    for i, name in enumerate(['heuristics_direct_'])\n",
    "]\n",
    "\n",
    "heur_p_testebm = [\n",
    "    lf_levels(test_ebm_lfs, name, 'P') \n",
    "    for i, name in enumerate(['heuristics_direct_'])\n",
    "]\n",
    "\n",
    "heur_p_testphysio = [\n",
    "    lf_levels(test_physio_lfs, name, 'P') \n",
    "    for i, name in enumerate(['heuristics_direct_'])\n",
    "]\n",
    "\n",
    "# ------------------------------------------------------------------------\n",
    "\n",
    "heur_i = [\n",
    "    lf_levels(train_ebm_lfs, name, 'I') \n",
    "    for i, name in enumerate(['heuristics_direct_'])\n",
    "]\n",
    "\n",
    "heur_i_testcorrected = [\n",
    "    lf_levels(test_ebm_corr_lfs, name, 'I') \n",
    "    for i, name in enumerate(['heuristics_direct_'])\n",
    "]\n",
    "\n",
    "heur_i_testebm = [\n",
    "    lf_levels(test_ebm_lfs, name, 'I') \n",
    "    for i, name in enumerate(['heuristics_direct_'])\n",
    "]\n",
    "\n",
    "heur_i_testphysio = [\n",
    "    lf_levels(test_physio_lfs, name, 'I') \n",
    "    for i, name in enumerate(['heuristics_direct_'])\n",
    "]\n",
    "\n",
    "# ------------------------------------------------------------------------\n",
    "\n",
    "heur_o = [\n",
    "    lf_levels(train_ebm_lfs, name, 'O') \n",
    "    for i, name in enumerate(['heuristics_direct_'])\n",
    "]\n",
    "\n",
    "heur_o_testcorrected = [\n",
    "    lf_levels(test_ebm_corr_lfs, name, 'O') \n",
    "    for i, name in enumerate(['heuristics_direct_'])\n",
    "]\n",
    "\n",
    "\n",
    "heur_o_testebm = [\n",
    "    lf_levels(test_ebm_lfs, name, 'O') \n",
    "    for i, name in enumerate(['heuristics_direct_'])\n",
    "]\n",
    "\n",
    "heur_o_testphysio = [\n",
    "    lf_levels(test_physio_lfs, name, 'O') \n",
    "    for i, name in enumerate(['heuristics_direct_'])\n",
    "]\n",
    "\n",
    "# ------------------------------------------------------------------------\n",
    "\n",
    "heur_s = [\n",
    "    lf_levels(train_ebm_lfs, name, 'S') \n",
    "    for i, name in enumerate(['heuristics_direct_'])\n",
    "]\n",
    "\n",
    "heur_s_testcorrected = [\n",
    "    lf_levels(test_ebm_corr_lfs, name, 'S') \n",
    "    for i, name in enumerate(['heuristics_direct_'])\n",
    "]\n",
    "\n",
    "\n",
    "heur_s_testebm = [\n",
    "    lf_levels(test_ebm_lfs, name, 'S') \n",
    "    for i, name in enumerate(['heuristics_direct_'])\n",
    "]\n",
    "\n",
    "heur_s_testphysio = [\n",
    "    lf_levels(test_physio_lfs, name, 'S') \n",
    "    for i, name in enumerate(['heuristics_direct_'])\n",
    "]\n",
    "\n",
    "# ------------------------------------------------------------------------\n",
    "# ------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "dict_p = [\n",
    "    lf_levels(train_ebm_lfs, name, 'P') \n",
    "    for i, name in enumerate(['dictionary_direct_', 'dictionary_fuzzy_'])\n",
    "]\n",
    "\n",
    "dict_p_testcorrected = [\n",
    "    lf_levels(test_ebm_corr_lfs, name, 'P') \n",
    "    for i, name in enumerate(['dictionary_direct_', 'dictionary_fuzzy_'])\n",
    "]\n",
    "\n",
    "dict_p_testebm = [\n",
    "    lf_levels(test_ebm_lfs, name, 'P') \n",
    "    for i, name in enumerate(['dictionary_direct_', 'dictionary_fuzzy_'])\n",
    "]\n",
    "\n",
    "dict_p_testphysio = [\n",
    "    lf_levels(test_physio_lfs, name, 'P') \n",
    "    for i, name in enumerate(['dictionary_direct_', 'dictionary_fuzzy_'])\n",
    "]\n",
    "\n",
    "# ------------------------------------------------------------------------\n",
    "\n",
    "dict_i = [\n",
    "    lf_levels(train_ebm_lfs, name, 'I') \n",
    "    for i, name in enumerate(['dictionary_direct_', 'dictionary_fuzzy_'])\n",
    "]\n",
    "\n",
    "dict_i_testcorrected = [\n",
    "    lf_levels(test_ebm_corr_lfs, name, 'I') \n",
    "    for i, name in enumerate(['dictionary_direct_', 'dictionary_fuzzy_'])\n",
    "]\n",
    "\n",
    "dict_i_testebm = [\n",
    "    lf_levels(test_ebm_lfs, name, 'I') \n",
    "    for i, name in enumerate(['dictionary_direct_', 'dictionary_fuzzy_'])\n",
    "]\n",
    "\n",
    "dict_i_testphysio = [\n",
    "    lf_levels(test_physio_lfs, name, 'I') \n",
    "    for i, name in enumerate(['dictionary_direct_', 'dictionary_fuzzy_'])\n",
    "]\n",
    "\n",
    "# ------------------------------------------------------------------------\n",
    "\n",
    "dict_o = [\n",
    "    lf_levels(train_ebm_lfs, name, 'O') \n",
    "    for i, name in enumerate(['dictionary_direct_', 'dictionary_fuzzy_'])\n",
    "]\n",
    "\n",
    "dict_o_testcorrected = [\n",
    "    lf_levels(test_ebm_corr_lfs, name, 'O') \n",
    "    for i, name in enumerate(['dictionary_direct_', 'dictionary_fuzzy_'])\n",
    "]\n",
    "\n",
    "dict_o_testebm = [\n",
    "    lf_levels(test_ebm_lfs, name, 'O') \n",
    "    for i, name in enumerate(['dictionary_direct_', 'dictionary_fuzzy_'])\n",
    "]\n",
    "\n",
    "dict_o_testphysio = [\n",
    "    lf_levels(test_physio_lfs, name, 'O') \n",
    "    for i, name in enumerate(['dictionary_direct_', 'dictionary_fuzzy_'])\n",
    "]\n",
    "\n",
    "# ------------------------------------------------------------------------\n",
    "\n",
    "dict_s = [\n",
    "    lf_levels(train_ebm_lfs, name, 'S') \n",
    "    for i, name in enumerate(['dictionary_direct_', 'dictionary_fuzzy_'])\n",
    "]\n",
    "\n",
    "dict_s_testcorrected = [\n",
    "    lf_levels(test_ebm_corr_lfs, name, 'S') \n",
    "    for i, name in enumerate(['dictionary_direct_', 'dictionary_fuzzy_'])\n",
    "]\n",
    "\n",
    "dict_s_testebm = [\n",
    "    lf_levels(test_ebm_lfs, name, 'S') \n",
    "    for i, name in enumerate(['dictionary_direct_', 'dictionary_fuzzy_'])\n",
    "]\n",
    "\n",
    "dict_s_testphysio = [\n",
    "    lf_levels(test_physio_lfs, name, 'S') \n",
    "    for i, name in enumerate(['dictionary_direct_', 'dictionary_fuzzy_'])\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1435d2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Participant data\n",
    "\n",
    "train_candidates = [umls_p[1], nonumls_p[1], ds_p[1], dict_p[1], heur_p[0]]\n",
    "test_ebm_corr_candidates = [umls_p_testcorrected[1], nonumls_p_testcorrected[1], ds_p_testcorrected[1], dict_p_testcorrected[1], heur_p_testcorrected[0]]\n",
    "test_ebm_candidates = [umls_p_testebm[1], nonumls_p_testebm[1], ds_p_testebm[1], dict_p_testebm[1], heur_p_testebm[0]]\n",
    "test_physio_candidates = [umls_p_testphysio[1], nonumls_p_testphysio[1], ds_p_testphysio[1], dict_p_testphysio[1], heur_p_testphysio[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a469e386",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intervention data\n",
    "\n",
    "train_i_candidates = [umls_i[1], nonumls_i[1], ds_i[1], dict_i[1], heur_i[0]]\n",
    "test_i_ebm_corr_candidates = [umls_i_testcorrected[1], nonumls_i_testcorrected[1], ds_i_testcorrected[1], dict_i_testcorrected[1], heur_i_testcorrected[0]]\n",
    "test_i_ebm_candidates = [umls_i_testebm[1], nonumls_i_testebm[1], ds_i_testebm[1], dict_i_testebm[1], heur_i_testebm[0]]\n",
    "test_i_physio_candidates = [umls_i_testphysio[1], nonumls_i_testphysio[1], ds_i_testphysio[1], dict_i_testphysio[1], heur_i_testphysio[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4746e0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outcome data\n",
    "\n",
    "train_o_candidates = [umls_o[1], nonumls_o[1], ds_o[1], dict_o[1], heur_o[0]]\n",
    "test_o_ebm_corr_candidates = [umls_o_testcorrected[1], nonumls_o_testcorrected[1], ds_o_testcorrected[1], dict_o_testcorrected[1], heur_o_testcorrected[0]]\n",
    "test_o_ebm_candidates = [umls_o_testebm[1], nonumls_o_testebm[1], ds_o_testebm[1], dict_o_testebm[1], heur_o_testebm[0]]\n",
    "test_o_physio_candidates = [umls_o_testphysio[1], nonumls_o_testphysio[1], ds_o_testphysio[1], dict_o_testphysio[1], heur_o_testphysio[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f69ef012",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Study Type data\n",
    "\n",
    "train_s_candidates = [dict_s[1], heur_s[0]]\n",
    "test_s_ebm_corr_candidates = [dict_s_testcorrected[1], heur_s_testcorrected[0]]\n",
    "test_s_ebm_candidates = [dict_s_testebm[1], heur_s_testebm[0]]\n",
    "test_s_physio_candidates = [dict_s_testphysio[1], heur_s_testphysio[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "02cff49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLen(lf):\n",
    "    for l in lf:\n",
    "        for k,v in l.items():\n",
    "            print(len(v))\n",
    "            \n",
    "#getLen(umls_i) \n",
    "#getLen(nonumls_i) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6dff19b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch UMLS ranks\n",
    "\n",
    "sum_lf_p = '/mnt/nas2/results/Results/systematicReview/distant_pico/EBM_PICO_GT/v3/summaries/lf_p_summary_tuipio3_train.csv'\n",
    "sum_lf_i = '/mnt/nas2/results/Results/systematicReview/distant_pico/EBM_PICO_GT/v3/summaries/lf_i_summary_tuipio3_train.csv'\n",
    "sum_lf_o = '/mnt/nas2/results/Results/systematicReview/distant_pico/EBM_PICO_GT/v3/summaries/lf_o_summary_tuipio3_train.csv'\n",
    "\n",
    "\n",
    "def fetchRank(sum_lf_d, pattern, picos: str, drop_nopos: bool):\n",
    "    \n",
    "    drop_nopos_keys = []\n",
    "    for k,v in train_ebm_lfs.items():\n",
    "        query = '_'+picos+'_'\n",
    "        if query in str(k):\n",
    "            key = str(k).split('_lf_')[-1]\n",
    "            drop_nopos_keys.append(key)\n",
    "    \n",
    "    ranked_umls_coverage = dict()    \n",
    "    umls_coverage_ = dict()\n",
    "    \n",
    "    data=pd.read_csv(sum_lf_d, sep='\\t')\n",
    "    \n",
    "    for index, row in data.iterrows():\n",
    "        if row[0].startswith(pattern):\n",
    "            umls_coverage_[row[0]] = row[3]\n",
    "    \n",
    "    umls_coverage_sorted = sorted(umls_coverage_.items(), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    for i in umls_coverage_sorted:\n",
    "        k = str(i[0]).split('_')[-1]\n",
    "        if drop_nopos == False:\n",
    "            ranked_umls_coverage[k] = i[1]\n",
    "        else:\n",
    "            if k in drop_nopos_keys:\n",
    "                ranked_umls_coverage[k] = i[1]\n",
    "\n",
    "    return ranked_umls_coverage\n",
    "\n",
    "\n",
    "# fuzzy UMLS\n",
    "ranksorted_p_umls_fuzzy = fetchRank(sum_lf_p, 'UMLS_fuzzy_', picos='P', drop_nopos = False)\n",
    "ranksorted_i_umls_fuzzy = fetchRank(sum_lf_i, 'UMLS_fuzzy_', picos='I', drop_nopos = False)\n",
    "ranksorted_o_umls_fuzzy = fetchRank(sum_lf_o, 'UMLS_fuzzy_', picos='O', drop_nopos = False)\n",
    "\n",
    "\n",
    "# direct UMLS\n",
    "ranksorted_p_umls_direct = fetchRank(sum_lf_p, 'UMLS_direct_', picos='P', drop_nopos = False)\n",
    "ranksorted_i_umls_direct = fetchRank(sum_lf_i, 'UMLS_direct_', picos='I', drop_nopos = False)\n",
    "ranksorted_o_umls_direct = fetchRank(sum_lf_o, 'UMLS_direct_', picos='O', drop_nopos = False)\n",
    "\n",
    "proper_coverage_p = '/mnt/nas2/results/Results/systematicReview/distant_pico/coverage_results/participant_UMLS_v3_coverage.json'\n",
    "\n",
    "with open(proper_coverage_p, 'r') as rf:\n",
    "    data = json.load(rf)\n",
    " \n",
    "    for k, v in data.items():\n",
    "        if k in ranksorted_p_umls_fuzzy:\n",
    "            ranksorted_p_umls_fuzzy[k] = data[k]\n",
    "            \n",
    "ranksorted_coverage_p_umls_fuzzy = sorted(ranksorted_p_umls_fuzzy.items(), key=lambda x: x[1], reverse=True)\n",
    "ranksorted_coverage_p_umls_fuzzy = dict(ranksorted_coverage_p_umls_fuzzy)\n",
    "\n",
    "\n",
    "proper_coverage_i = '/mnt/nas2/results/Results/systematicReview/distant_pico/coverage_results/intervention_UMLS_v3_coverage.json'\n",
    "\n",
    "with open(proper_coverage_i, 'r') as rf:\n",
    "    data = json.load(rf)\n",
    " \n",
    "    for k, v in data.items():\n",
    "        if k in ranksorted_i_umls_fuzzy:\n",
    "            ranksorted_i_umls_fuzzy[k] = data[k]\n",
    "            \n",
    "ranksorted_coverage_i_umls_fuzzy = sorted(ranksorted_i_umls_fuzzy.items(), key=lambda x: x[1], reverse=True)\n",
    "ranksorted_coverage_i_umls_fuzzy = dict(ranksorted_coverage_i_umls_fuzzy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3f749e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Partition LF's\n",
    "\n",
    "def partitionLFs(umls_d):\n",
    "    \n",
    "    keys = list(umls_d.keys())\n",
    "\n",
    "    partitioned_lfs = [ ]\n",
    "    \n",
    "    for i in range( 0, len(keys) ):\n",
    "\n",
    "        if i == 0 or i == len(keys):\n",
    "            if i == 0:\n",
    "                partitioned_lfs.append( [keys] )\n",
    "            if i ==len(keys):\n",
    "                temp3 = list2Nested(keys, 1)\n",
    "                partitioned_lfs.append( temp3 )\n",
    "        else:\n",
    "            temp1, temp2 = keys[:i] , keys[i:]\n",
    "            temp3 = list2Nested( keys[:i], 1)\n",
    "            temp3.append( keys[i:] )\n",
    "            partitioned_lfs.append( temp3 )\n",
    "    \n",
    "    return partitioned_lfs\n",
    "\n",
    "\n",
    "partitioned_p_umls_fuzzy = partitionLFs(ranksorted_coverage_p_umls_fuzzy)\n",
    "partitioned_i_umls_fuzzy = partitionLFs(ranksorted_coverage_i_umls_fuzzy)\n",
    "partitioned_o_umls_fuzzy = partitionLFs(ranksorted_o_umls_fuzzy)\n",
    "\n",
    "partitioned_p_umls_direct = partitionLFs(ranksorted_p_umls_direct)\n",
    "partitioned_i_umls_direct = partitionLFs(ranksorted_i_umls_direct)\n",
    "partitioned_o_umls_direct = partitionLFs(ranksorted_o_umls_direct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9551349e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#exp_level = ['UMLS', 'UMLS_Ontology', 'UMLS_Ontology_Rules']\n",
    "exp_level = ['UMLS_Ontology_Rules', 'UMLS_Ontology', 'UMLS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2c6e5471",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'lr': [0.001, 0.0001],\n",
    "    'l2': [0.001, 0.0001],\n",
    "    'n_epochs': [50, 100, 200, 600, 700, 1000, 2000],\n",
    "    'prec_init': [0.6, 0.7, 0.8, 0.9],\n",
    "    'optimizer': [\"adamax\", \"adam\", \"sgd\"],\n",
    "    'lr_scheduler': ['constant'],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3d083955",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_param_grid(param_grid, seed):\n",
    "    \"\"\" Sample parameter grid\n",
    "    :param param_grid:\n",
    "    :param seed:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    rstate = np.random.get_state()\n",
    "    np.random.seed(seed)\n",
    "    params = list(product(*[param_grid[name] for name in param_grid]))\n",
    "    np.random.shuffle(params)\n",
    "    np.random.set_state(rstate)\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c0cc37ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare(s, t):\n",
    "    return sorted(s) == sorted(t)\n",
    "\n",
    "def getLFs(partition:list, umls_d:dict, seed_len:int):\n",
    "\n",
    "    all_lfs_combined = []\n",
    "    \n",
    "    for lf in partition: # for each lf in a partition\n",
    "        \n",
    "        combine_here = [0] * seed_len\n",
    "\n",
    "        for sab in lf:\n",
    "            new_a = list(umls_d[sab])\n",
    "            old_a = combine_here\n",
    "            temp_a = []\n",
    "            \n",
    "            for o_a, n_a in zip(old_a, new_a):\n",
    "                               \n",
    "                if compare([o_a, n_a] ,[-1, 1]) == True:\n",
    "                    replace_a = max( o_a, n_a )\n",
    "                    temp_a.append( replace_a )\n",
    "                    \n",
    "                elif compare([o_a, n_a] ,[0, 1]) == True:\n",
    "                    replace_a = max( o_a, n_a )\n",
    "                    temp_a.append( replace_a )\n",
    "                    \n",
    "                elif compare([o_a, n_a] ,[-1, 0]) == True:\n",
    "                    replace_a = min( o_a, n_a )\n",
    "                    temp_a.append( replace_a )\n",
    "                else:\n",
    "                    temp_a.append( o_a )\n",
    "\n",
    "            combine_here = temp_a\n",
    "\n",
    "        all_lfs_combined.append( combine_here )\n",
    "\n",
    "    return all_lfs_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c151bccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def compare(s, t):\n",
    "    return sorted(s) == sorted(t)\n",
    "\n",
    "def getLFs_modified(partitions:list, umls_d:dict, seed_len:int):\n",
    "    \n",
    "    start = time.time()\n",
    "\n",
    "    all_lfs_combined = []\n",
    "    \n",
    "    for part in partitions: # for each lf in a partition\n",
    "        \n",
    "        merged_lfs = list( map(umls_d.get, part) )\n",
    "        merged_lfs = np.stack( merged_lfs )\n",
    "        merged_lfs = pd.DataFrame( merged_lfs )\n",
    "        merged_lfs = merged_lfs.transpose()\n",
    "        merged_lfs = merged_lfs.to_dict('records')\n",
    "\n",
    "        emitted = []\n",
    "        \n",
    "        #for index, row in merged_lfs.iterrows(): # NEVER USE ITERROWS\n",
    "        for row in merged_lfs:\n",
    "            \n",
    "            emit = ''\n",
    "            to_compare = list( set( list(row.values())  ) )\n",
    "            if len( to_compare ) == 3:\n",
    "                emit = max( to_compare )\n",
    "            else:\n",
    "                if 1 in to_compare:\n",
    "                    emit = max( to_compare )\n",
    "                else:\n",
    "                    emit = min( to_compare )\n",
    "                    \n",
    "            emitted.append( emit )\n",
    "            \n",
    "        all_lfs_combined.append( emitted )\n",
    "    \n",
    "    end = time.time()\n",
    "    \n",
    "    #print('End time: ', end - start)\n",
    "\n",
    "    return all_lfs_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8287557b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get LF combinations based on partitions\n",
    "# train_o_candidates, test_o_ebm_candidates, test_o_ebm_corr_candidates\n",
    "\n",
    "def get_part_candidates(partitioned_d_umls, cands):\n",
    "\n",
    "    part_cand_dict = dict()\n",
    "\n",
    "    for i, partition in enumerate(  tqdm(partitioned_d_umls) ):\n",
    "        \n",
    "        #if i <= 3:\n",
    "        combined_lf = getLFs_modified(partition, cands[0], len( data_df.tokens ))\n",
    "        assert len( combined_lf ) == (i+1)\n",
    "\n",
    "        part_cand_dict[i] = combined_lf\n",
    "\n",
    "    return part_cand_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f38face1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dump the partitions to a fine\n",
    "picos = 'I'\n",
    "candgen_version = 'v4'\n",
    "\n",
    "def write_parition( data_dict, setname, k ):\n",
    "    write_dir = f'/mnt/nas2/results/Results/systematicReview/distant_pico/partitions/{candgen_version}/{picos}/'\n",
    "    filename = str(setname) + '.json'\n",
    "    write_file = write_dir + filename\n",
    "    with open(write_file , 'a+') as wf:\n",
    "        json.dump(data_dict, wf)\n",
    "        wf.write( '\\n' )\n",
    "\n",
    "def part2file( data_dict, setname ):\n",
    "    \n",
    "    for k, v in tqdm( data_dict.items() ):\n",
    "        \n",
    "        temp_dict = dict()\n",
    "        temp_dict[k] = v\n",
    "        write_parition( temp_dict, setname, k )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f7187b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print( 'Getting candidate partitions for test ebm set' )\n",
    "#part_cand_i_test_ebm = get_part_candidates(partitioned_i_umls_fuzzy, test_i_ebm_candidates)\n",
    "\n",
    "print( 'Getting candidate partitions for test ebm set corrected' )\n",
    "#part_cand_i_test_ebm_corr = get_part_candidates(partitioned_i_umls_fuzzy, test_i_ebm_corr_candidates)\n",
    "\n",
    "print( 'Getting candidate partitions for test physio set' )\n",
    "#part_cand_i_test_physio_corr = get_part_candidates(partitioned_i_umls_fuzzy, test_i_physio_candidates)\n",
    "\n",
    "print( 'Getting candidate partitions for training set' )\n",
    "#part_cand_i_train = get_part_candidates(partitioned_i_umls_fuzzy, train_i_candidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "68b201cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 127/127 [04:21<00:00,  2.06s/it]\n"
     ]
    }
   ],
   "source": [
    "#part2file( part_cand_i_test_ebm, 'test_ebm_candidate_generation' )        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9f118289",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 127/127 [04:33<00:00,  2.15s/it]\n"
     ]
    }
   ],
   "source": [
    "#part2file( part_cand_i_test_ebm_corr, 'test_ebm_anjani_candidate_generation' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3800563a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 127/127 [04:27<00:00,  2.10s/it]\n"
     ]
    }
   ],
   "source": [
    "#part2file( part_cand_i_test_physio_corr, 'test_physio_candidate_generation' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "41f32ec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 127/127 [1:51:53<00:00, 52.87s/it] \n"
     ]
    }
   ],
   "source": [
    "#part2file( part_cand_i_train, 'training_ebm_candidate_generation' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b9f8eb9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the partitions from the JSON files\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "\n",
    "training_file = f'/mnt/nas2/results/Results/systematicReview/distant_pico/partitions/{candgen_version}/{picos}/training_ebm_candidate_generation/'\n",
    "test_ebm_file = f'/mnt/nas2/results/Results/systematicReview/distant_pico/partitions/{candgen_version}/{picos}/test_ebm_candidate_generation/'\n",
    "test_ebm_corr_file = f'/mnt/nas2/results/Results/systematicReview/distant_pico/partitions/{candgen_version}/{picos}/test_ebm_anjani_candidate_generation/'\n",
    "test_physio_file = f'/mnt/nas2/results/Results/systematicReview/distant_pico/partitions/{candgen_version}/{picos}/test_physio_candidate_generation/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "19e8b404",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mv(L, break_ties, abstain=-1):\n",
    "    \"\"\"Simple majority vote\"\"\"\n",
    "    from statistics import mode\n",
    "    y_hat = []\n",
    "    for row in L:\n",
    "        # get non abstain votes\n",
    "        row = row[row != abstain]\n",
    "        try:\n",
    "            l = mode(row)\n",
    "        except:\n",
    "            l = break_ties\n",
    "        y_hat.append(l)\n",
    "    return np.array(y_hat).astype(np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2eabf50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict2metrics(cr_dict):\n",
    "    \n",
    "    # accuracy: 89.70 | precision: 14.80 | recall: 36.10 | f1: 20.99 | f1_macro: 57.74\n",
    "    \n",
    "    accuracy = round( cr_dict['accuracy'] * 100, 2) \n",
    "    precision = round( cr_dict['1']['precision'] * 100, 2) \n",
    "    recall = round( cr_dict['1']['recall'] * 100, 2) \n",
    "    f1 = round( cr_dict['1']['f1-score'] * 100, 2) \n",
    "    f1_macro = round( cr_dict['macro avg']['f1-score'] * 100, 2) \n",
    "    \n",
    "    string2return = 'accuracy: ' + str(accuracy) + ' | ' + 'precision: ' + str(precision) + ' | ' + 'recall: ' +  str(recall) + ' | ' + 'f1: ' + str(f1) + ' | ' + 'f1_macro: ' + str(f1_macro)\n",
    "    \n",
    "    return string2return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "602295fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search(model_class,\n",
    "                model_class_init,\n",
    "                param_grid,\n",
    "                train=None,\n",
    "                dev=None,\n",
    "                other_train=None,\n",
    "                n_model_search=5,\n",
    "                val_metric='f1_macro',\n",
    "                seed=0,\n",
    "                checkpoint_gt_mv=True,\n",
    "                tag_fmt_ckpnt='IO'):\n",
    "    \n",
    "    \n",
    "    \"\"\"Simple grid search helper function\n",
    "    Parameters\n",
    "    ----------\n",
    "    model_class\n",
    "    model_class_init\n",
    "    param_grid\n",
    "    train\n",
    "    dev\n",
    "    n_model_search\n",
    "    val_metric\n",
    "    seed\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    \"\"\"\n",
    "    \n",
    "    L_train, Y_train = train\n",
    "    L_dev, Y_dev = dev\n",
    "\n",
    "    # sample configs\n",
    "    params = sample_param_grid(param_grid, seed)[:n_model_search]\n",
    "\n",
    "    defaults = {'seed': seed}\n",
    "    best_score, best_score_mv, best_config = 0.0, 0.0, None\n",
    "    print(f\"Grid search over {len(params)} configs\")\n",
    "\n",
    "    for i, config in enumerate(params):\n",
    "        print(f'[{i}] Label Model')\n",
    "        config = dict(zip(param_grid.keys(), config))\n",
    "        config.update({param: value for param, value in defaults.items() if param not in config})\n",
    "\n",
    "        model = model_class(**model_class_init)\n",
    "        model.fit(L_train, Y_dev, **config)\n",
    "        \n",
    "        y_pred = model.predict(L_dev)\n",
    "        \n",
    "        if tag_fmt_ckpnt == 'IO':\n",
    "            y_gold = np.array([0 if y == 0 else 1 for y in Y_dev])\n",
    "        else:\n",
    "            y_gold = Y_dev\n",
    "            \n",
    "            \n",
    "        if -1 in y_pred:\n",
    "            print(\"Label model predicted -1 (TODO: this happens inconsistently)\")\n",
    "            continue\n",
    "            \n",
    "        # use internal label model scorer to score the prediction\n",
    "        metrics = model.score(L=L_dev,\n",
    "                              Y=y_gold,\n",
    "                              metrics=['accuracy', 'precision', 'recall', 'f1', 'f1_macro'],\n",
    "                              tie_break_policy='random')\n",
    "\n",
    "        # compare learned model against MV on same labeled dev set\n",
    "        # skip if LM less than MV\n",
    "        #if checkpoint_gt_mv:\n",
    "        mv_y_pred = mv(L_dev, 0)\n",
    "        cr_mv = classification_report( y_gold, mv_y_pred, digits=4, output_dict = True  )\n",
    "        mv_metrics = cr_mv['macro avg']['f1-score']\n",
    "\n",
    "        #if metrics[val_metric] < mv_metrics:\n",
    "        #    continue\n",
    "                \n",
    "        if not best_score or metrics[val_metric] > best_score[val_metric]:\n",
    "            print(config)\n",
    "            best_score = metrics\n",
    "            best_score_mv = mv_metrics\n",
    "            best_config = config\n",
    "            \n",
    "            # print training set score if we have labeled data\n",
    "            if np.any(Y_train):\n",
    "                y_pred = model.predict(L_train)\n",
    "\n",
    "                if tag_fmt_ckpnt == 'IO':\n",
    "                    y_gold = np.array([0 if y == 0 else 1 for y in Y_train])\n",
    "                else:\n",
    "                    y_gold = Y_train\n",
    "\n",
    "                metrics = model.score(L=L_train,\n",
    "                                      Y=y_gold,\n",
    "                                      metrics=['accuracy', 'precision', 'recall', 'f1', 'f1_macro'],\n",
    "                                      tie_break_policy='random')\n",
    "\n",
    "                print('[TRAIN] {}'.format(' | '.join([f'{m}: {v * 100:2.2f}' for m, v in metrics.items()])))\n",
    "\n",
    "            print('[DEV]   {}'.format(' | '.join([f'{m}: {v * 100:2.2f}' for m, v in best_score.items()])))\n",
    "            print( '[DEVMV]   {}'.format( dict2metrics(cr_mv) ) )\n",
    "            print('-' * 88)\n",
    "            \n",
    "            \n",
    "    # retrain best model\n",
    "    print('BEST')\n",
    "    print(best_config)\n",
    "    model = model_class(**model_class_init)   \n",
    "    model.fit(L_train, Y_dev, **best_config)\n",
    "    \n",
    "    return model, best_config, best_score, best_score_mv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ea78fc26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(part, cands, best_model, gt_labels, exp_l):\n",
    "    \n",
    "    if exp_l == 'UMLS':\n",
    "    \n",
    "        combined_lf = getLFs( part, cands[0], len(gt_labels) ) # level 1 UMLS\n",
    "        assert len(part) == len(combined_lf)\n",
    "        print( 'Total number of UMLS partitions: ', len(part) )\n",
    "        \n",
    "    elif exp_l == 'UMLS_Ontology':\n",
    "    \n",
    "        combined_lf = getLFs( part, cands[0], len(gt_labels) ) # level 1 UMLS\n",
    "        assert len(part) == len(combined_lf)\n",
    "        print( 'Total number of UMLS partitions: ', len(part) )\n",
    "        combined_lf.extend( list(cands[1].values()) ) # level 2 non-UMLS\n",
    "        \n",
    "    elif exp_l == 'UMLS_Ontology_Rules':\n",
    "\n",
    "        combined_lf = getLFs( part, cands[0], len(gt_labels) ) # level 1 UMLS\n",
    "        assert len(part) == len(combined_lf)\n",
    "        print( 'Total number of UMLS partitions: ', len(part) )\n",
    "        combined_lf.extend( list(cands[1].values()) ) # level 2 non-UMLS\n",
    "        combined_lf.extend( list(cands[2].values()) ) # level 3 DS - Heur\n",
    "        combined_lf.extend( list(cands[3].values()) ) # level 4 dict - Heur \n",
    "        combined_lf.extend( list(cands[4].values()) ) # level 4 ReGeX, Abb - Heur\n",
    "\n",
    "\n",
    "    L = np.array( combined_lf )\n",
    "    L = np.transpose(L)\n",
    "    \n",
    "    predictions_probablities = best_model.predict_proba(L)\n",
    "    predictions = best_model.predict(L)\n",
    "    groundtruth = np.array(gt_labels) \n",
    "    groundtruth_ = [1 if x != 0 else x for x in gt_labels] # XXX if \"test_ebm_correct\"\n",
    "    groundtruth = np.array(groundtruth_)\n",
    "\n",
    "    cr = classification_report( groundtruth, predictions, digits=4 )\n",
    "    print( cr )\n",
    "    \n",
    "    return predictions_probablities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78a1e865",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train( candidates, Y_d, picos, paramgrid, mode ):\n",
    "    \n",
    "    train_cands, test_cands, test_corr_cands, test_physio = candidates\n",
    "  \n",
    "    gold_labels = ''\n",
    "    gold_labels_fine = ''\n",
    "    \n",
    "    \n",
    "    model_class_init = {\n",
    "        'cardinality': 2, \n",
    "        'verbose': True\n",
    "    }\n",
    "\n",
    "    num_hyperparams = functools.reduce(lambda x,y:x*y, [len(x) for x in param_grid.values()])\n",
    "    print(\"Hyperparamater Search Space:\", num_hyperparams)\n",
    "    n_model_search = 50\n",
    "    \n",
    "\n",
    "    '''#########################################################################\n",
    "    # Choosing the number of LF's from UMLS all\n",
    "    #########################################################################'''\n",
    "    \n",
    "    partition_contributions = dict()\n",
    "    partition_contributions_mv = dict()\n",
    "    \n",
    "    for l in exp_level:\n",
    "        print( 'Executing the experiment level: ', l )\n",
    "        \n",
    "        best_f1_macro = 0.0\n",
    "        best_overall_model = ''\n",
    "        best_overall_config = ''\n",
    "        best_overall_partition = 0\n",
    "        overall_L = ''\n",
    "        \n",
    "        best_score_parts = [ ]\n",
    "        best_score_mv_parts = [ ]\n",
    "        \n",
    "        # list all files from a dir\n",
    "        onlyfiles = sorted( [ int(str(f).replace('.json', '')) for f in listdir(training_file) if isfile(join(training_file, f))] )\n",
    "        \n",
    "        for partition in onlyfiles:\n",
    "            \n",
    "            partition_file = training_file + str(partition) + str('.json')\n",
    "            \n",
    "            with open( partition_file, 'r' ) as rf:        \n",
    "            \n",
    "                partition_i = json.load(rf)           \n",
    "                                \n",
    "                for k, v in partition_i.items():\n",
    "\n",
    "                    if l == 'UMLS' and k < 2:\n",
    "                        continue\n",
    "\n",
    "                    if l == 'UMLS':\n",
    "\n",
    "                        combined_lf = list(v)\n",
    "                        assert int(k)+1 == len(combined_lf)\n",
    "                        print( 'Total number of UMLS partitions: ', len(combined_lf) )\n",
    "\n",
    "                    if l == 'UMLS_Ontology':\n",
    "\n",
    "                        combined_lf = list(v)\n",
    "                        assert int(k)+1 == len(combined_lf)\n",
    "                        print( 'Total number of UMLS partitions: ', len(combined_lf) )\n",
    "                        combined_lf.extend( list(train_cands[1].values()) ) # level 2 non-UMLS\n",
    "\n",
    "                    if l == 'UMLS_Ontology_Rules':\n",
    "\n",
    "                        combined_lf = list(v)\n",
    "                        assert int(k)+1 == len(combined_lf)\n",
    "                        print( 'Total number of UMLS partitions: ', len(combined_lf) )\n",
    "                        combined_lf.extend( list(train_cands[1].values()) ) # level 2 non-UMLS\n",
    "                        combined_lf.extend( list(train_cands[2].values()) ) # level 3 DS - Heur\n",
    "                        combined_lf.extend( list(train_cands[3].values()) ) # level 4 dict - Heur \n",
    "                        combined_lf.extend( list(train_cands[4].values()) ) # level 4 ReGeX, Abb - Heur\n",
    "\n",
    "\n",
    "                    L = np.array( combined_lf )\n",
    "                    L = np.transpose(L)\n",
    "                    L_train, L_val = train_test_split(L, test_size=0.20, shuffle=False)\n",
    "                    Y_train, Y_val = train_test_split( np.array(Y_d[0]), test_size=0.20, shuffle=False)\n",
    "                    Y_train_fine, Y_val_fine = train_test_split( np.array(Y_d[1]), test_size=0.20, shuffle=False)\n",
    "\n",
    "                    # convert the fine labels to 0 and 1\n",
    "                    Y_train_fine = [1 if x != 0 else x for x in Y_train_fine]\n",
    "                    Y_val_fine = [1 if x != 0 else x for x in Y_val_fine]\n",
    "\n",
    "                    Y = np.concatenate([Y_train, Y_val])\n",
    "                    Y_fine = np.concatenate([Y_train_fine, Y_val_fine])\n",
    "\n",
    "                    best_model, best_config, best_score, best_score_mv = grid_search(LMsnorkel, \n",
    "                                                           model_class_init, \n",
    "                                                           paramgrid,\n",
    "                                                           train = (L_train, Y_train_fine),\n",
    "                                                           dev = (L_val, Y_val_fine),\n",
    "                                                           n_model_search=n_model_search, \n",
    "                                                           val_metric='f1_macro', \n",
    "                                                           seed=seed_i,\n",
    "                                                           tag_fmt_ckpnt='IO')\n",
    "\n",
    "                    best_score_parts.append( best_score['f1_macro'] )\n",
    "                    best_score_mv_parts.append( best_score_mv )\n",
    "\n",
    "                    if best_score['f1_macro'] > best_f1_macro:\n",
    "                        best_f1_macro = best_score['f1_macro']\n",
    "                        best_overall_model = best_model\n",
    "                        best_overall_config = best_config\n",
    "                        best_overall_partition = k\n",
    "                        overall_L = L\n",
    "                        gold_labels = Y_d[0]\n",
    "                        gold_labels_fine = Y_d[1]\n",
    "\n",
    "\n",
    "                    print('Best overall macro F1 score: ', best_f1_macro)\n",
    "                    print('Best overall configuration: ', best_overall_config)\n",
    "\n",
    "        partition_contributions[ l ] = best_score_parts\n",
    "        partition_contributions_mv[ l ] = best_score_mv_parts\n",
    "\n",
    "        print('Save the best overall model, configuration and partition for this experiment level')\n",
    "        # Save your model or results\n",
    "        save_dir = f'/mnt/nas2/results/Results/systematicReview/distant_pico/models/LabelModels/{picos}/v4/{l}/{seed_i}'\n",
    "        filename = 'stpartition_' + str(best_overall_partition) + '_epoch_' + str(best_config['n_epochs'])\n",
    "        joblib.dump(best_overall_model, f'{save_dir}/{filename}.pkl') \n",
    "        joblib.dump(best_overall_config, f'{save_dir}/{filename}.json')\n",
    "        \n",
    "        return partition_contributions_mv, partition_contributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2111d3e4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_i_candidates' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-5d40e4b73f2b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Seed 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpartition_contributions_mv_0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpartition_contributions_0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mcandidates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain_i_candidates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_i_ebm_corr_candidates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_i_ebm_candidates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_i_physio_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_d\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mY_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpicos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'i'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparamgrid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'pred'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'train_i_candidates' is not defined"
     ]
    }
   ],
   "source": [
    "# Seed 0\n",
    "partition_contributions_mv_0, partition_contributions_0 = train( candidates = (train_i_candidates, test_i_ebm_corr_candidates, test_i_ebm_candidates, test_i_physio_candidates), Y_d = Y_i, picos = 'i', paramgrid = param_grid, mode = 'pred')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc6fc9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seed 1\n",
    "seed_i = 1\n",
    "partition_contributions_mv_1, partition_contributions_1 = train( candidates = (train_i_candidates, test_i_ebm_corr_candidates, test_i_ebm_candidates, test_i_physio_candidates), Y_d = Y_i, picos = 'i', paramgrid = param_grid, mode = 'pred')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c4e740",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seed 42\n",
    "seed_i = 42\n",
    "partition_contributions_mv_42, partition_contributions_42 = train( candidates = (train_i_candidates, test_i_ebm_corr_candidates, test_i_ebm_candidates, test_i_physio_candidates), Y_d = Y_i, picos = 'i', paramgrid = param_grid, mode = 'pred')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9a7ddc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f537a752",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

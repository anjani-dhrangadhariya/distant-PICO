{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b3b4e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import enum\n",
    "import glob\n",
    "import os\n",
    "from hashlib import new\n",
    "from pathlib import Path\n",
    "import time\n",
    "\n",
    "import functools\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "from flyingsquid.label_model import LabelModel as LMsquid\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from snorkel.labeling.model import LabelModel as LMsnorkel\n",
    "from snorkel.labeling.model import MajorityLabelVoter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32865c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.exceptions import UndefinedMetricWarning\n",
    "\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31488955",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple, Dict\n",
    "\n",
    "\n",
    "class Document(object):\n",
    "\n",
    "    def __init__(self, name, sentences):\n",
    "        self.name = name\n",
    "        self.sentences = sentences\n",
    "        for s in sentences:\n",
    "            s.document = self\n",
    "        self.annotations = {i:{} for i in range(len(sentences))}\n",
    "        self.props = {}\n",
    "        self._text = None\n",
    "\n",
    "    @property\n",
    "    def text(self):\n",
    "        if not self._text:\n",
    "            t = \"\"\n",
    "            for s in self.sentences:\n",
    "                if len(t) != s.abs_char_offsets[0]:\n",
    "                    t += ' ' * (s.abs_char_offsets[0] - len(t))\n",
    "                t += s.text\n",
    "            self._text = t\n",
    "        return self._text\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return \"Document({})\".format(self.name)\n",
    "        \n",
    "        \n",
    "class Sentence(object):\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        self.document = None\n",
    "        self.__dict__.update(kwargs)\n",
    "        self._text = None\n",
    "\n",
    "    @property\n",
    "    def text(self):\n",
    "        if not self._text:\n",
    "            txt = \"\"\n",
    "            offset = self.abs_char_offsets[0]\n",
    "            for i,w in enumerate(self.words):\n",
    "                if len(txt) != self.abs_char_offsets[i] - offset:\n",
    "                    txt += ' ' * (self.abs_char_offsets[i] - offset - len(txt))\n",
    "                txt += w\n",
    "            self._text = txt\n",
    "        return self._text\n",
    "\n",
    "    @property\n",
    "    def position(self):\n",
    "        return self.i\n",
    "    \n",
    "    @property\n",
    "    def char_offsets(self):\n",
    "        offset = self.abs_char_offsets[0]\n",
    "        return [i - offset for i in self.abs_char_offsets]\n",
    "               \n",
    "    def __repr__(self):\n",
    "        max_len = 25\n",
    "        s = self.text.strip().replace(\"\\n\",\" \")\n",
    "        return \"Sentence({})\".format(\n",
    "            s if len(s) < max_len else s[0:max_len] + '...'\n",
    "        )\n",
    "        \n",
    "\n",
    "class Span(object):\n",
    "\n",
    "    def __init__(self, char_start, char_end, sentence, attrib='words'):\n",
    "        self.sentence   = sentence\n",
    "        self.char_start = char_start\n",
    "        self.char_end   = char_end\n",
    "        self.attrib     = attrib\n",
    "        self.props      = {}\n",
    "        self.normalized = None\n",
    "    \n",
    "    @property\n",
    "    def abs_char_start(self):\n",
    "        return self.char_start + self.sentence.abs_char_offsets[0]\n",
    "\n",
    "    @property\n",
    "    def abs_char_end(self):\n",
    "        return self.abs_char_start + (self.char_end - self.char_start)\n",
    "    \n",
    "    @property\n",
    "    def text(self):\n",
    "        return self.sentence.text[self.char_start:self.char_end + 1]\n",
    "\n",
    "    def get_word_start(self):\n",
    "        return self.char_to_word_index(self.char_start)\n",
    "\n",
    "    def get_word_end(self):\n",
    "        return self.char_to_word_index(self.char_end)\n",
    "\n",
    "    def get_n(self):\n",
    "        return self.get_word_end() - self.get_word_start() + 1\n",
    "\n",
    "    def char_to_word_index(self, ci):\n",
    "        i = None\n",
    "        for i, co in enumerate(self.sentence.char_offsets):\n",
    "            if ci == co:\n",
    "                return i\n",
    "            elif ci < co:\n",
    "                return i-1\n",
    "        return i\n",
    "\n",
    "    def word_to_char_index(self, wi):\n",
    "        return self.sentence.char_offsets[wi]\n",
    "\n",
    "    def get_attrib_tokens(self, a):\n",
    "        return self.sentence.__getattribute__(a)[self.get_word_start():self.get_word_end() + 1]\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return \"Span({})\".format(self.text.replace(\"\\n\",\" \"))\n",
    "     \n",
    "    def get_attrib_span(self, a, sep=\" \"):\n",
    "        if a == 'words':\n",
    "            return self.sentence.text[self.char_start:self.char_end + 1]\n",
    "        else:\n",
    "            return sep.join(self.get_attrib_tokens(a))\n",
    "\n",
    "    def get_span(self, sep=\" \"):\n",
    "        return self.get_attrib_span('words', sep)\n",
    "\n",
    "    def __contains__(self, other_span):\n",
    "        return other_span.abs_char_start >= self.abs_char_start and other_span.abs_char_end <= self.abs_char_end\n",
    "    \n",
    "    \n",
    "class Candidate(object):\n",
    "    \"\"\"A collection of spans\"\"\"\n",
    "    def __init__(self, spans):\n",
    "        self.spans = spans\n",
    "\n",
    "\n",
    "class Relation(object):\n",
    "\n",
    "    def __init__(self,\n",
    "                 type_name:str,\n",
    "                 args: Dict[str, Span]) -> None:\n",
    "        self.type_name = type_name\n",
    "        self.args = args\n",
    "        self.__dict__.update(args)\n",
    "\n",
    "    def __iter__(self):\n",
    "        for span in self.args.values():\n",
    "            yield span\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        return list(self.args.values())[item]\n",
    "\n",
    "    def __repr__(self):\n",
    "        strs = [span.__repr__() for span in self.args.values()]\n",
    "        return f\"Relation[{self.type_name}]({','.join(strs)})\"\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        hashes = {name:span.__hash__() for name,span in self.args.items()}\n",
    "        other = {name:span.__hash__() for name,span in other.args.items()}\n",
    "        return hashes == other\n",
    "\n",
    "    def __hash__(self):\n",
    "        return hash(sum([s.__hash__() for s in self.args.values()]))\n",
    "\n",
    "    @property\n",
    "    def sentence(self):\n",
    "        \"\"\"We assume spans all live in the same sentence\"\"\"\n",
    "        return self.__dict__[self.arg_names[0]].sentence\n",
    "\n",
    "\n",
    "\n",
    "class Annotation(object):\n",
    "    def __init__(self, doc_name: str,\n",
    "                 span: Tuple[Tuple[int,int], ...],\n",
    "                 etype: str,\n",
    "                 text: str = None,\n",
    "                 cid: str = None) -> None:\n",
    "        \"\"\"\n",
    "\n",
    "        :param doc_name:\n",
    "        :param span:\n",
    "        :param etype:\n",
    "        :param text:\n",
    "        :param cid:\n",
    "        \"\"\"\n",
    "        self.abs_char_start = span[0][0]\n",
    "        self.abs_char_end = span[0][-1]\n",
    "\n",
    "        self.doc_name = doc_name\n",
    "        self.span = tuple([tuple(s) for s in span])\n",
    "        self.text = text\n",
    "        self.etype = etype\n",
    "        self.cid = cid\n",
    "        \n",
    "    def __repr__(self):\n",
    "        text = self.text.replace('\\n',' ') + '|' if self.text else ''\n",
    "        i,j = self.abs_char_start, self.abs_char_end\n",
    "        sep = '...' if len(self.span) > 1 else '-'\n",
    "        return f\"Annotation[{self.etype}]({text}{i}{sep}{j})\"\n",
    "\n",
    "    @property\n",
    "    def type(self):\n",
    "        return self.etype\n",
    "\n",
    "    def __hash__(self):\n",
    "        return hash((self.etype, self.doc_name, self.span))\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        return False if not isinstance(other, type(self)) else True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ea98395",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import gzip\n",
    "import json\n",
    "import glob\n",
    "import numpy as np\n",
    "import logging\n",
    "import itertools\n",
    "import collections\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "def parse_doc(d) -> Document:\n",
    "    \"\"\"\n",
    "    Convert JSON into container objects. Transforming to\n",
    "    Document/Sentence objects comes at ~13% overhead.\n",
    "    \"\"\"\n",
    "    sents = [Sentence(**s) for s in d['sentences']]\n",
    "    doc = Document(d['name'], sents)\n",
    "    if 'metadata' in d:\n",
    "        for key,value in d['metadata'].items():\n",
    "            doc.props[key] = value\n",
    "    return doc\n",
    "\n",
    "\n",
    "class DocumentLoader:\n",
    "\n",
    "    def __init__(self, fpath):\n",
    "        self.fpath = fpath\n",
    "        self.formatter = parse_doc\n",
    "\n",
    "    def filelist(self):\n",
    "        return glob.glob(f'{self.fpath}/*.json') \\\n",
    "            if os.path.isdir(self.fpath) else [self.fpath]\n",
    "\n",
    "    def __iter__(self):\n",
    "        for fpath in self.filelist():\n",
    "            fopen = gzip.open if fpath.split(\".\")[-1] == 'gz' else open\n",
    "            with fopen(fpath, 'rb') as fp:\n",
    "                for line in fp:\n",
    "                    yield self.formatter(json.loads(line))\n",
    "\n",
    "\n",
    "def load_json_dataset(fpath,\n",
    "                      tokenizer,\n",
    "                      tag_fmt = 'IO',\n",
    "                      contiguous_only = False):\n",
    "    \"\"\"Load JSON dataset and initialize sequence tagged labels.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    fpath\n",
    "        JSON file path\n",
    "    tokenizer\n",
    "\n",
    "    tag_fmt\n",
    "        token tagging scheme with values in {'IO','IOB', 'IOBES'}\n",
    "    \"\"\"\n",
    "    documents, entities = [], {}\n",
    "    fopen = gzip.open if fpath.split(\".\")[-1] == 'gz' else open\n",
    "    with fopen(fpath, 'rb') as fp:\n",
    "        for line in fp:\n",
    "            # initialize context objects\n",
    "            d = json.loads(line)\n",
    "            doc = Document(d['name'], [Sentence(**s) for s in d['sentences']])\n",
    "            documents.append(doc)\n",
    "            # load entities\n",
    "            entities[doc.name] = set()\n",
    "            if 'entities' not in d:\n",
    "                continue\n",
    "            for entity in d['entities']:\n",
    "                del entity['abs_char_start']\n",
    "                del entity['abs_char_end']\n",
    "                if 'doc_name' not in entity:\n",
    "                    entity['doc_name'] = doc.name\n",
    "                anno = Annotation(**entity)\n",
    "                if len(anno.span) > 1 and contiguous_only:\n",
    "                    continue\n",
    "                entities[doc.name].add(Annotation(**entity))\n",
    "\n",
    "    return NerDocumentDataset(documents,\n",
    "                              entities,\n",
    "                              tag_fmt=tag_fmt,\n",
    "                              tokenizer=tokenizer)\n",
    "\n",
    "\n",
    "#################################################################################\n",
    "#\n",
    "#  Sequence Tag Creation\n",
    "#\n",
    "#################################################################################\n",
    "\n",
    "def entity_tag(length, tag_fmt=\"IOB\"):\n",
    "    \"\"\"\n",
    "    IO, IOB, or IOBES (equiv. to BILOU) tagging\n",
    "\n",
    "    :param tokens:\n",
    "    :param is_heads:\n",
    "    :param tag_fmt:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    tags = ['O'] * length\n",
    "    tag_fmt = set(tag_fmt)\n",
    "\n",
    "    if tag_fmt == set(\"IOB\"):\n",
    "        tags[0] = 'B'\n",
    "        tags[1:] = len(tags[1:]) * \"I\"\n",
    "\n",
    "    elif tag_fmt == set(\"IOBES\") or tag_fmt == set(\"BILOU\"):\n",
    "        if len(tags) == 1:\n",
    "            tags[0] = 'S'\n",
    "        else:\n",
    "            tags[0] = 'B'\n",
    "            tags[1:-1] = len(tags[1:-1]) * \"I\"\n",
    "            tags[-1:] = \"E\"\n",
    "\n",
    "    elif tag_fmt == set(\"IO\"):\n",
    "        tags = ['I'] * len(tags)\n",
    "    return tags\n",
    "\n",
    "\n",
    "def map_sent_entities(document, entities, verbose=True):\n",
    "    \"\"\"\n",
    "    Given (1) a document split into sentences and (2) a list of entities\n",
    "    defined by absolute char offsets, map each entity to it's parent sentence.\n",
    "\n",
    "    :param:\n",
    "    :param:\n",
    "    :return tuple of sentence index and tag,\n",
    "    \"\"\"\n",
    "    errors = 0\n",
    "    spans = []\n",
    "    char_index = [s.abs_char_offsets[0] for s in document.sentences]\n",
    "\n",
    "    for t in entities:\n",
    "        position = None\n",
    "        for i in range(len(char_index) - 1):\n",
    "            if t.abs_char_start >= char_index[i] and t.abs_char_end <= char_index[i + 1]:\n",
    "                position = i\n",
    "                break\n",
    "\n",
    "        if position == None and t.abs_char_start >= char_index[-1]:\n",
    "            position = len(char_index) - 1\n",
    "\n",
    "        if position == None:\n",
    "            values = (document.name, t.abs_char_start, t.abs_char_end)\n",
    "            if verbose:\n",
    "                msg = f\"{[t.text]} {t.span} {t.doc_name}\"\n",
    "                logger.warning(f\"Cross-sentence mention {msg}\")\n",
    "            errors += 1\n",
    "            continue\n",
    "        try:\n",
    "            shift = document.sentences[position].abs_char_offsets[0]\n",
    "            span = document.sentences[position].text[t.abs_char_start - shift:t.abs_char_end - shift]\n",
    "            spans.append((position, t, span))\n",
    "        except Exception as e:\n",
    "            logger.error(f'{e}')\n",
    "\n",
    "    idx = collections.defaultdict(list)\n",
    "    for i, entity, _ in spans:\n",
    "        idx[i].append(entity)\n",
    "\n",
    "    return idx, errors\n",
    "\n",
    "\n",
    "def retokenize(sent, tokenizer, subword='##'):\n",
    "    \"\"\"\n",
    "    Given a default tokenization, compute absolute character offsets for\n",
    "    a new tokenization (e.g., BPE). By convention, wordpiece tokens are\n",
    "    prefixed by ##.\n",
    "\n",
    "    \"\"\"\n",
    "    tokens = []\n",
    "    abs_char_offsets = []\n",
    "\n",
    "    for i in range(len(sent.words)):\n",
    "        toks = tokenizer.tokenize(sent.words[i])\n",
    "        offsets = [sent.abs_char_offsets[i]]\n",
    "        for w in toks[0:-1]:\n",
    "            offsets.append(\n",
    "                len(w if w[:len(subword)] != subword else w[len(subword):]) + offsets[-1]\n",
    "            )\n",
    "        abs_char_offsets.extend(offsets)\n",
    "        tokens.extend(toks)\n",
    "\n",
    "    return tokens, abs_char_offsets\n",
    "\n",
    "\n",
    "def tokens_to_tags(sent,\n",
    "                   entities,\n",
    "                   tag_fmt='BIO',\n",
    "                   tokenizer=None,\n",
    "                   max_seq_len=512):\n",
    "    \"\"\"\n",
    "\n",
    "    :param sent:\n",
    "    :param entities:\n",
    "    :param tag_fmt:\n",
    "    :param tokenizer:\n",
    "    :param max_seq_len:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    toks, abs_char_offsets = retokenize(sent, tokenizer) if tokenizer \\\n",
    "        else (sent.words, sent.abs_char_offsets)\n",
    "\n",
    "    # truncate long sequences\n",
    "    if len(toks) > max_seq_len - 2:\n",
    "        toks = toks[0:max_seq_len - 2]\n",
    "        abs_char_offsets = abs_char_offsets[0:max_seq_len - 2]\n",
    "\n",
    "    # use original tokenization to assign token heads\n",
    "    is_heads = [1 if i in sent.abs_char_offsets else 0 for i in abs_char_offsets]\n",
    "    tags = ['O'] * len(toks)\n",
    "\n",
    "    errs = 0\n",
    "    for entity in entities:\n",
    "\n",
    "        # currently we only support contiguous entity spans\n",
    "        if len(entity.span) != 1:\n",
    "            logger.warning(f\"Non-contiguous entities not supported {entity} {sent.document.name}\")\n",
    "            continue\n",
    "\n",
    "        head = entity.span[0]\n",
    "        if head[0] in abs_char_offsets:\n",
    "            start = abs_char_offsets.index(head[0])\n",
    "            end = len(abs_char_offsets)\n",
    "\n",
    "            for j, offset in enumerate(abs_char_offsets):\n",
    "                if head[-1] > offset:\n",
    "                    continue\n",
    "                end = j\n",
    "                break\n",
    "\n",
    "            # tokenization error\n",
    "            if is_heads[start] == 0:\n",
    "                errs += 1\n",
    "                logger.warning(f\"Tokenization Error: Token is not a head token {entity} {sent.document.name}\")\n",
    "                continue\n",
    "\n",
    "            tok_len = is_heads[start:end].count(1)\n",
    "            head_tags = entity_tag(tok_len, tag_fmt=tag_fmt)\n",
    "            head_tags = [f'{t}-{entity.type}' for t in head_tags]\n",
    "            io_tags = ['O'] * len(toks[start:end])\n",
    "\n",
    "            for i in range(len(io_tags)):\n",
    "                if is_heads[start:end][i] == 1:\n",
    "                    t = head_tags.pop(0)\n",
    "                io_tags[i] = t\n",
    "\n",
    "            tags[start:end] = io_tags\n",
    "\n",
    "            # Error Checking: do spans match?\n",
    "            s1 = ''.join([w if w[:2] != '##' else w[2:] for w in toks[start:end]]).lower()\n",
    "            s2 = re.sub(r'''(\\s)+''', '', entity.text).lower()\n",
    "\n",
    "\n",
    "            if s1 != s2:\n",
    "                if len(entity.span) == 1:\n",
    "                    msg = f\"{s1} != {s2}\"\n",
    "                    logger.error(f\"Span does not match {msg}\")\n",
    "                errs += 1\n",
    "        else:\n",
    "            errs += 1\n",
    "            logger.error(f\"Tokenization Error: Token head not found in abs_char_offsets {entity}\")\n",
    "\n",
    "    return (toks, tags, is_heads), errs\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#################################################################################\n",
    "#\n",
    "#  Datasets\n",
    "#\n",
    "#################################################################################\n",
    "\n",
    "\n",
    "class NerDocumentDataset(object):\n",
    "    \"\"\"\n",
    "    Document + Annotation objects\n",
    "    entities are defined as abs char offsets per document\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, documents: dict,\n",
    "                 entities: dict,\n",
    "                 tag_fmt: str = 'IO',\n",
    "                 tokenizer=None) -> None:\n",
    "        \"\"\"\n",
    "        Convert Document objects with a corresponding\n",
    "        entity set into tagged sequences\n",
    "\n",
    "        :param documents:\n",
    "        :param entities:\n",
    "        :param tag_fmt:\n",
    "        :param tokenizer:\n",
    "        \"\"\"\n",
    "        self.documents = documents\n",
    "        self.entities = entities\n",
    "        self.tag_fmt = tag_fmt\n",
    "        self.tokenizer = tokenizer\n",
    "        self.tag2idx = self._get_tag_index(entities, tag_fmt)\n",
    "\n",
    "        self._init_sequences(documents)\n",
    "\n",
    "    def _get_tag_index(self, entities, tag_fmt):\n",
    "        \"\"\"\n",
    "        Given a collection of entity types, initialize an integer tag mapping\n",
    "        e.g., B-Drug I-Drug O\n",
    "\n",
    "        :param entities:\n",
    "        :param tag_fmt:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        entity_types = {t.type for doc_name in entities for t in entities[doc_name]}\n",
    "        tags = [t for t in list(tag_fmt) if t != 'O']\n",
    "        tags = [f'{tag}-{etype}' for tag, etype in itertools.product(tags, entity_types)]\n",
    "        tags = ['X', 'O', ] + tags\n",
    "        return {t: i for i, t in enumerate(tags)}\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.data)\n",
    "\n",
    "    def tagged(self, idx):\n",
    "        \"\"\"\n",
    "        Return tagged words\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        X, _, _, Y, _, _ = self.__getitem__(idx)\n",
    "        return X[1:-1], Y[1:-1]\n",
    "\n",
    "    def _init_sequences(self, documents):\n",
    "        \"\"\"\n",
    "        Transform Documents into labeled sequences.\n",
    "\n",
    "        :param documents:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        self.data = []\n",
    "        self.sentences = []\n",
    "        num_errors, num_missing_heads, num_entities = 0, 0, 0\n",
    "\n",
    "        for doc in documents:\n",
    "            self.sentences.extend(doc.sentences)\n",
    "            annotations = self.entities[doc.name] if doc.name in self.entities else {}\n",
    "            num_entities += len(annotations)\n",
    "            # tag sentences\n",
    "            sent_entities, errs = map_sent_entities(doc, annotations)\n",
    "            num_errors += errs\n",
    "\n",
    "            for sentence in doc.sentences:\n",
    "                entities = sent_entities[sentence.i] if sentence.i in sent_entities else []\n",
    "                seqs, errs = tokens_to_tags(sentence, entities, self.tag_fmt, tokenizer=self.tokenizer)\n",
    "                num_errors += errs\n",
    "\n",
    "                x, y, is_heads = seqs\n",
    "                if not (len(x) == len(y) == len(is_heads)):\n",
    "                    print(seqs)\n",
    "\n",
    "                self.data.append(seqs)\n",
    "\n",
    "        assert len(self.data) == len(self.sentences)\n",
    "        if num_errors:\n",
    "            msg = f'Errors: Span Alignment: {num_errors}/{num_entities} ({num_errors / num_entities * 100:2.1f}%)'\n",
    "            logger.warning(msg)\n",
    "\n",
    "        print(f'Tagged Entities: {num_entities - num_errors}')\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        toks, tags, is_heads = self.data[idx]\n",
    "\n",
    "        words = [w for w in self.sentences[idx].words if w.strip()]\n",
    "        words = self.sentences[idx].words\n",
    "        # original tags (head words only)\n",
    "        tags = [t for i, t in enumerate(tags) if is_heads[i] == 1]\n",
    "\n",
    "        if len(words) != len(tags):\n",
    "            print(len(words), len(tags))\n",
    "            print(words)\n",
    "            print(tags)\n",
    "            print('-' * 50)\n",
    "\n",
    "        words = ['[CLS]'] + words + ['[SEP]']\n",
    "        toks = ['[CLS]'] + toks + ['[SEP]']\n",
    "        tags = ['X'] + tags + ['X']\n",
    "\n",
    "        X = self.tokenizer.convert_tokens_to_ids(toks)\n",
    "        Y = [self.tag2idx[t] if h == 1 else self.tag2idx['X'] for t, h in zip(tags, is_heads)]\n",
    "\n",
    "        return words, X, is_heads, tags, Y, len(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "adeb266c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def mv(L, break_ties, abstain=-1):\n",
    "    \"\"\"Simple majority vote\"\"\"\n",
    "    from statistics import mode\n",
    "    y_hat = []\n",
    "    for row in L:\n",
    "        # get non abstain votes\n",
    "        row = row[row != abstain]\n",
    "        try:\n",
    "            l = mode(row)\n",
    "        except:\n",
    "            l = break_ties\n",
    "        y_hat.append(l)\n",
    "    return np.array(y_hat).astype(np.int)\n",
    "\n",
    "def smv(L, abstain=-1, uncovered=0):\n",
    "    \"\"\"Soft majority vote\"\"\"\n",
    "    y_hat = []\n",
    "    k = np.unique(L[L != abstain]).astype(int)\n",
    "    k = list(range(min(k), max(k) + 1))\n",
    "    for row in L:\n",
    "        # get non abstain votes\n",
    "        row = list(row[row != abstain])\n",
    "        N = len(row)\n",
    "        if not N:\n",
    "            y_hat.append([1.0, 0])\n",
    "        else:\n",
    "            p = []\n",
    "            for i in k:\n",
    "                p.append(row.count(i) / N)\n",
    "            y_hat.append(p)\n",
    "    return np.array(y_hat).astype(np.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62ddf21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "from typing import List, Set, Dict, Tuple, Pattern, Match, Iterable\n",
    "import seqeval.metrics\n",
    "\n",
    "\n",
    "def split_by_seq_len(X, X_lens) -> np.ndarray:\n",
    "    \"\"\"Given a matrix X of M elements, partition into N variable length\n",
    "    sequences where [xi, ..., xN] lengths are defined by X_lens[i].\n",
    "\n",
    "    This is used to partition a stacked matrix of words back into sentences.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X\n",
    "    X_lens\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "\n",
    "    \"\"\"\n",
    "    splits = [np.sum(X_lens[0:i]) for i in range(1, X_lens.shape[0])]\n",
    "    return np.split(X, splits)\n",
    "\n",
    "\n",
    "def convert_tag_fmt(\n",
    "        seq: List[str],\n",
    "        etype: str,\n",
    "        tag_fmt: str = 'IOB') -> List[str]:\n",
    "    \"\"\"Convert between tagging schemes. This is a lossy conversion\n",
    "    when converting to IO, i.e., mapping {IOB, IOBES} -> IO\n",
    "    drops information on adjacent entities.\n",
    "\n",
    "    IOB -> O B I I B I O\n",
    "    IO  -> O I I I I I O\n",
    "    IOB -> O B I I I I O\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    seq\n",
    "    etype\n",
    "    tag_fmt\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "\n",
    "    \"\"\"\n",
    "    # TODO: Only works for IO -> {IOB, IOBES}\n",
    "    assert set(seq).issubset(set('IO'))\n",
    "    # divide into contiguous chunks\n",
    "    chunks = [list(g) for _, g in itertools.groupby(seq)]\n",
    "    # remap to new tagging scheme\n",
    "    seq = list(itertools.chain.from_iterable(\n",
    "        [tags if 'O' in tags else entity_tag(len(tags), tag_fmt)\n",
    "         for tags in chunks]\n",
    "    ))\n",
    "    return [t if t == 'O' else f'{t}-{etype}' for t in seq]\n",
    "\n",
    "\n",
    "def tokens_to_sequences(y_gold,\n",
    "                        y_pred,\n",
    "                        seq_lens,\n",
    "                        idx2tag=None,\n",
    "                        tag_fmt=None):\n",
    "    \"\"\"Convert token labels to sentences for sequence model evaluation.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y_gold\n",
    "    y_pred\n",
    "    seq_lens\n",
    "    idx2tag\n",
    "    tag_fmt\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "\n",
    "    \"\"\"\n",
    "    idx2tag = {1: 'I', 0: 'O'} if not idx2tag else idx2tag\n",
    "    y_gold_seqs = []\n",
    "    for s in split_by_seq_len(y_gold, seq_lens):\n",
    "        y = [idx2tag[i] for i in s]\n",
    "        if tag_fmt is not None:\n",
    "            y_hat = convert_tag_fmt(y, etype='ENTITY', tag_fmt='IOB')\n",
    "        else:\n",
    "            y_hat = y\n",
    "        y_gold_seqs.append(y_hat)\n",
    "\n",
    "    y_pred_seqs = []\n",
    "    for s in split_by_seq_len(y_pred, seq_lens):\n",
    "        # Sometimes -1 labels make it into evaluation due to Snorkel\n",
    "        # label model. Just treat these as 'O'\n",
    "        y = [idx2tag[i] if i in idx2tag else 'O' for i in s]\n",
    "        if tag_fmt is not None:\n",
    "            y_hat = convert_tag_fmt(y, etype='ENTITY', tag_fmt='IOB')\n",
    "        else:\n",
    "            y_hat = y\n",
    "        y_pred_seqs.append(y_hat)\n",
    "\n",
    "    return y_gold_seqs, y_pred_seqs\n",
    "\n",
    "\n",
    "def score_sequences(y_true: List[List[int]],\n",
    "                    y_pred: List[List[int]],\n",
    "                    metrics: Set[str] = None) -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Sequence model evaluation using seqeval\n",
    "    https://github.com/chakki-works/seqeval\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y_gold\n",
    "    y_pred\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "\n",
    "    \"\"\"\n",
    "    scorers = {\n",
    "        'accuracy': sklearn.metrics.accuracy_score,\n",
    "        'precision': sklearn.metrics.precision_score,\n",
    "        'recall': sklearn.metrics.recall_score,\n",
    "        'f1': sklearn.metrics.f1_score\n",
    "    }\n",
    "    metrics = metrics if metrics is not None else scorers\n",
    "    try:\n",
    "        return {name: scorers[name](y_true, y_pred, average='macro') for name in metrics}\n",
    "    except:\n",
    "        return {name: 0.0 for name in metrics}\n",
    "\n",
    "\n",
    "def eval_label_model(model, L, Y, seq_lens):\n",
    "\n",
    "    idx2tag = {0: 'O', 1: 'I-X', 2: 'B-X'}\n",
    "\n",
    "    # label model\n",
    "    y_pred = model.predict(L)\n",
    "    scores = score_sequences(*tokens_to_sequences(Y, y_pred, seq_lens, idx2tag=idx2tag))\n",
    "    print('[Label Model]   {}'.format(\n",
    "        ' | '.join([f'{m}: {v * 100:2.2f}' for m, v in scores.items()]))\n",
    "    )\n",
    "\n",
    "    # MV baseline\n",
    "    y_pred = mv(L, 0)\n",
    "    scores = score_sequences(*tokens_to_sequences(Y, y_pred, seq_lens, idx2tag=idx2tag))\n",
    "    print('[Majority Vote] {}'.format(\n",
    "        ' | '.join([f'{m}: {v * 100:2.2f}' for m, v in scores.items()]))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c6c6a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from itertools import product\n",
    "from sklearn.metrics import (\n",
    "    precision_score, recall_score,\n",
    "    f1_score, accuracy_score,\n",
    "    precision_recall_fscore_support\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def sample_param_grid(param_grid, seed):\n",
    "    \"\"\" Sample parameter grid\n",
    "\n",
    "    :param param_grid:\n",
    "    :param seed:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    rstate = np.random.get_state()\n",
    "    np.random.seed(seed)\n",
    "    params = list(product(*[param_grid[name] for name in param_grid]))\n",
    "    np.random.shuffle(params)\n",
    "    np.random.set_state(rstate)\n",
    "    return params\n",
    "\n",
    "\n",
    "def compute_metrics(y_gold, y_pred, average='binary'):\n",
    "    \"\"\"\n",
    "\n",
    "    :param y_gold:\n",
    "    :param y_pred:\n",
    "    :param average:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    return {\n",
    "        'accuracy': accuracy_score(y_gold, y_pred),\n",
    "        'precision': precision_score(y_gold, y_pred, average=average),\n",
    "        'recall': recall_score(y_gold, y_pred, average=average),\n",
    "        'f1': f1_score(y_gold, y_pred, average=average)\n",
    "    }\n",
    "\n",
    "\n",
    "def grid_search_span(model_class,\n",
    "                     model_class_init,\n",
    "                     param_grid,\n",
    "                     train=None,\n",
    "                     dev=None,\n",
    "                     n_model_search=5,\n",
    "                     val_metric='f1',\n",
    "                     seed=1234,\n",
    "                     verbose=True):\n",
    "    \"\"\"Simple grid search helper function\n",
    "\n",
    "    \"\"\"\n",
    "    L_train, Y_train = train if len(train) == 2 else (train[0], None)\n",
    "    L_dev, Y_dev = dev\n",
    "\n",
    "    # sample configs\n",
    "    params = sample_param_grid(param_grid, seed)[:n_model_search]\n",
    "\n",
    "    defaults = {'seed': seed}\n",
    "    best_score, best_config = 0.0, None\n",
    "    # set scoring mode based on the number of classes\n",
    "    average = 'binary' if np.unique(Y_dev).shape[0] == 2 else 'micro'\n",
    "\n",
    "    print(f\"Grid search over {len(params)} configs\")\n",
    "    print(f'Averaging: {average}')\n",
    "\n",
    "    for i, config in enumerate(params):\n",
    "        print(f'[{i}] Label Model')\n",
    "        config = dict(zip(param_grid.keys(), config))\n",
    "        # update default params if not specified\n",
    "        config.update({\n",
    "            param: value for param, value in defaults.items() \\\n",
    "            if param not in config})\n",
    "\n",
    "        model = model_class(**model_class_init)\n",
    "        # fit (estimate class balance with Y_dev)\n",
    "        model.fit(L_train, Y_dev, **config)\n",
    "\n",
    "        y_pred = model.predict(L_dev)\n",
    "        y_gold = Y_dev\n",
    "\n",
    "        # Snorkel sometimes emits -1 predictions\n",
    "        if -1 in y_pred:\n",
    "            continue\n",
    "\n",
    "        # only evaluate dev score\n",
    "        mask = []\n",
    "        for i in range(L_dev.shape[0]):\n",
    "            if not np.all(L_dev[i] == -1):\n",
    "                mask.append(i)\n",
    "\n",
    "        mask = np.array(mask)\n",
    "        metrics = compute_metrics(Y_dev[mask], model.predict(L_dev[mask]))\n",
    "\n",
    "        msgs = []\n",
    "        if not best_score or metrics[val_metric] > best_score[val_metric]:\n",
    "            print(config)\n",
    "            best_score = metrics\n",
    "            best_config = config\n",
    "\n",
    "            # mask uncovered data points\n",
    "            mask = [i for i in range(L_train.shape[0]) \\\n",
    "                    if not np.all(L_train[i] == -1)]\n",
    "            msgs.append(\n",
    "                f'Coverage: {(len(mask) / L_train.shape[0] * 100):2.1f}%'\n",
    "            )\n",
    "\n",
    "            if Y_train is not None:\n",
    "                # filter out candidate spans without gold labels\n",
    "                y_mask = [i for i in range(len(Y_train)) if Y_train[i] != -1]\n",
    "                mask = np.array(sorted(list(set(y_mask).intersection(mask))))\n",
    "                metrics = compute_metrics(Y_train[mask],\n",
    "                                          model.predict(L_train[mask]))\n",
    "                msgs.append(\n",
    "                    'TRAIN {}'.format(' | '.join(\n",
    "                        [f'{m}: {v * 100:2.2f}' for m, v in metrics.items()])\n",
    "                    )\n",
    "                )\n",
    "\n",
    "            msgs.append(\n",
    "                'DEV   {}'.format(' | '.join(\n",
    "                    [f'{m}: {v * 100:2.2f}' for m, v in best_score.items()]))\n",
    "            )\n",
    "\n",
    "        if verbose and msgs:\n",
    "            print('\\n'.join(msgs) + ('\\n' + '-' * 80))\n",
    "\n",
    "        if i % 50 == 0:\n",
    "            print(f'[{i}] Label Model')\n",
    "\n",
    "    # retrain best model\n",
    "    if verbose:\n",
    "        print('BEST')\n",
    "        print(best_config)\n",
    "    model = model_class(**model_class_init)\n",
    "    model.fit(L_train, Y_dev, **best_config)\n",
    "    return model, best_config\n",
    "\n",
    "\n",
    "def grid_search(model_class,\n",
    "                model_class_init,\n",
    "                param_grid,\n",
    "                train=None,\n",
    "                dev=None,\n",
    "                other_train=None,\n",
    "                n_model_search=5,\n",
    "                val_metric='f1',\n",
    "                seed=1234,\n",
    "                seq_eval=True,\n",
    "                checkpoint_gt_mv=True,\n",
    "                tag_fmt_ckpnt='BIO'):\n",
    "    \"\"\"Simple grid search helper function\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model_class\n",
    "    model_class_init\n",
    "    param_grid\n",
    "    train\n",
    "    dev\n",
    "    n_model_search\n",
    "    val_metric\n",
    "    seed\n",
    "    seq_eval\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "\n",
    "    \"\"\"\n",
    "    print(f\"Using {'TOKEN' if not seq_eval else 'SEQUENCE'} dev checkpointing\")\n",
    "    if seq_eval:\n",
    "        print(f\"Using {tag_fmt_ckpnt} dev checkpointing\")\n",
    "\n",
    "    idx2tag = {0:'O', 1:'I-X', 2:'B-X'}\n",
    "\n",
    "    L_train, Y_train, X_train_lens = train\n",
    "    L_dev, Y_dev, X_dev_lens = dev\n",
    "\n",
    "    # sample configs\n",
    "    params = sample_param_grid(param_grid, seed)[:n_model_search]\n",
    "\n",
    "    defaults = {'seed': seed}\n",
    "    best_score, best_config = 0.0, None\n",
    "    print(f\"Grid search over {len(params)} configs\")\n",
    "\n",
    "    for i, config in enumerate(params):\n",
    "        print(f'[{i}] Label Model')\n",
    "        config = dict(zip(param_grid.keys(), config))\n",
    "        # update default params if not specified\n",
    "        config.update({param: value for param, value in defaults.items() if param not in config})\n",
    "\n",
    "        model = model_class(**model_class_init)\n",
    "        # fit (estimate class balance with Y_dev)\n",
    "        # HACK for BIO tag evaluation\n",
    "        if len(np.unique(Y_dev)) != 2:\n",
    "            Y_dev_hat = np.array([0 if y == 0 else 1 for y in Y_dev])\n",
    "        else:\n",
    "            Y_dev_hat = Y_dev\n",
    "        model.fit(L_train, Y_dev_hat, **config)\n",
    "\n",
    "        y_pred = model.predict(L_dev)\n",
    "\n",
    "        # set gold tags for evaluation\n",
    "        if tag_fmt_ckpnt == 'IO':\n",
    "            y_gold = np.array([0 if y == 0 else 1 for y in Y_dev])\n",
    "        else:\n",
    "            y_gold = Y_dev\n",
    "\n",
    "        if -1 in y_pred:\n",
    "            print(\"Label model predicted -1 (TODO: this happens inconsistently)\")\n",
    "            continue\n",
    "\n",
    "        # score on dev set (token or sequence-level)\n",
    "        if seq_eval:\n",
    "            metrics = score_sequences(*tokens_to_sequences(y_gold, y_pred, X_dev_lens, idx2tag=idx2tag))\n",
    "        else:\n",
    "            # use internal label model scorer\n",
    "            metrics = model.score(L=L_dev,\n",
    "                                  Y=y_gold,\n",
    "                                  metrics=['accuracy', 'precision', 'recall', 'f1'],\n",
    "                                  tie_break_policy=0)\n",
    "\n",
    "        # compare learned model against MV on same labeled dev set\n",
    "        # skip if LM less than MV\n",
    "        if checkpoint_gt_mv:\n",
    "            if seq_eval:\n",
    "                mv_y_pred = mv(L_dev, 0)\n",
    "                mv_metrics = score_sequences(\n",
    "                    *tokens_to_sequences(y_gold, mv_y_pred, X_dev_lens, idx2tag=idx2tag)\n",
    "                )\n",
    "            else:\n",
    "                metrics = model.score(L=L_dev,\n",
    "                                      Y=y_gold,\n",
    "                                      metrics=['accuracy', 'precision', 'recall', 'f1'],\n",
    "                                      tie_break_policy=0)\n",
    "\n",
    "            if metrics[val_metric] < metrics[val_metric]:\n",
    "                continue\n",
    "\n",
    "        if not best_score or metrics[val_metric] > best_score[val_metric]:\n",
    "            print(config)\n",
    "            best_score = metrics\n",
    "            best_config = config\n",
    "\n",
    "            # print training set score if we have labeled data\n",
    "            if np.any(Y_train):\n",
    "                y_pred = model.predict(L_train)\n",
    "\n",
    "                if tag_fmt_ckpnt == 'IO':\n",
    "                    y_gold = np.array([0 if y == 0 else 1 for y in Y_train])\n",
    "                else:\n",
    "                    y_gold = Y_train\n",
    "\n",
    "                if seq_eval:\n",
    "                    metrics = score_sequences(*tokens_to_sequences(y_gold, y_pred, X_train_lens, idx2tag=idx2tag))\n",
    "                else:\n",
    "                    metrics = model.score(L=L_train,\n",
    "                                          Y=y_gold,\n",
    "                                          metrics=['accuracy', 'precision', 'recall', 'f1'],\n",
    "                                          tie_break_policy=0)\n",
    "\n",
    "                print('[TRAIN] {}'.format(' | '.join([f'{m}: {v * 100:2.2f}' for m, v in metrics.items()])))\n",
    "\n",
    "            print('[DEV]   {}'.format(' | '.join([f'{m}: {v * 100:2.2f}' for m, v in best_score.items()])))\n",
    "            print('-' * 88)\n",
    "\n",
    "    # retrain best model\n",
    "    print('BEST')\n",
    "    print(best_config)\n",
    "    model = model_class(**model_class_init)\n",
    "\n",
    "    # HACK for BIO tag evaluation\n",
    "    if len(np.unique(Y_dev)) != 2:\n",
    "        Y_dev_hat = np.array([0 if y == 0 else 1 for y in Y_dev])\n",
    "    else:\n",
    "        Y_dev_hat = Y_dev\n",
    "    model.fit(L_train, Y_dev_hat, **best_config)\n",
    "    return model, best_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d1d2219",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list2Nested(l, nested_length):\n",
    "    return [l[i:i+nested_length] for i in range(0, len(l), nested_length)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "736e7d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch UMLS ranks\n",
    "\n",
    "sum_lf_p = '/mnt/nas2/results/Results/systematicReview/distant_pico/EBM_PICO_GT/lf_p_summary_train.csv'\n",
    "sum_lf_i = '/mnt/nas2/results/Results/systematicReview/distant_pico/EBM_PICO_GT/lf_i_summary_train.csv'\n",
    "sum_lf_o = '/mnt/nas2/results/Results/systematicReview/distant_pico/EBM_PICO_GT/lf_o_summary_train.csv'\n",
    "\n",
    "\n",
    "def fetchRank(sum_lf_d):\n",
    "    \n",
    "    ranked_umls_coverage = dict()    \n",
    "    umls_coverage_ = dict()\n",
    "    \n",
    "    data=pd.read_csv(sum_lf_d, sep='\\t')\n",
    "    \n",
    "    for index, row in data.iterrows():\n",
    "        if row[0].startswith('UMLS_fuzzy_'):\n",
    "            umls_coverage_[row[0]] = row[3]\n",
    "    \n",
    "    umls_coverage_sorted = sorted(umls_coverage_.items(), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    for i in umls_coverage_sorted:\n",
    "        k = str(i[0]).split('_')[-1]\n",
    "        ranked_umls_coverage[k] = i[1]\n",
    "\n",
    "    return ranked_umls_coverage\n",
    "\n",
    "ranksorted_p_umls = fetchRank(sum_lf_p)\n",
    "ranksorted_i_umls = fetchRank(sum_lf_i)\n",
    "ranksorted_o_umls = fetchRank(sum_lf_o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a8976e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Partition LF's\n",
    "\n",
    "def partitionLFs(umls_d):\n",
    "    \n",
    "    keys = list(umls_d.keys())\n",
    "\n",
    "    partitioned_lfs = [ ]\n",
    "    \n",
    "    for i in range( 0, len(keys) ):\n",
    "\n",
    "        if i == 0 or i == len(keys):\n",
    "            if i == 0:\n",
    "                partitioned_lfs.append( [keys] )\n",
    "            if i ==len(keys):\n",
    "                temp3 = list2Nested(keys, 1)\n",
    "                partitioned_lfs.append( temp3 )\n",
    "        else:\n",
    "            temp1, temp2 = keys[:i] , keys[i:]\n",
    "            temp3 = list2Nested( keys[:i], 1)\n",
    "            temp3.append( keys[i:] )\n",
    "            partitioned_lfs.append( temp3 )\n",
    "    \n",
    "    return partitioned_lfs\n",
    "\n",
    "\n",
    "partitioned_p_umls = partitionLFs(ranksorted_p_umls)\n",
    "partitioned_i_umls = partitionLFs(ranksorted_i_umls)\n",
    "partitioned_o_umls = partitionLFs(ranksorted_o_umls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0638a0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import LMutils\n",
    "\n",
    "# validation_labels   \n",
    "# validation_labels_tui_pio2   \n",
    "file = '/mnt/nas2/results/Results/systematicReview/distant_pico/EBM_PICO_GT/validation_labels_tui_pio2.tsv'\n",
    "df_data = pd.read_csv(file, sep='\\t', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4ea04a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_tokens = df_data['tokens']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0c7fe1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_tokens = df_data['tokens']\n",
    "#Y_p = df_data['p']\n",
    "#Y_i = df_data['i']\n",
    "#Y_o = df_data['o']\n",
    "df_data_train, df_data_val = train_test_split(df_data, test_size=0.20, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ce0e5ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = ['train', 'dev']\n",
    "X_sents = [\n",
    "    df_data_train.tokens,\n",
    "    df_data_val.tokens,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dc29465e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_seq_lens = [\n",
    "    np.array([len(str(s)) for s in X_sents[i]])\n",
    "    for i,name in enumerate(splits)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6b5b641a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_seq_lens = [\n",
    "    np.array( [ len(X_sents[i]) ] )\n",
    "    for i,name in enumerate(splits)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a1119c42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of tokens in validation set:  1354953\n",
      "Total number of LFs in the dictionary 617\n"
     ]
    }
   ],
   "source": [
    "# Read Candidate labels from multiple LFs\n",
    "indir = '/mnt/nas2/results/Results/systematicReview/distant_pico/candidate_generation'\n",
    "pathlist = Path(indir).glob('**/*.tsv')\n",
    "\n",
    "tokens = []\n",
    "\n",
    "lfs = dict()\n",
    "\n",
    "for file in pathlist:\n",
    "\n",
    "    k = str( file ).split('candidate_generation/')[-1].replace('.tsv', '').replace('/', '_')\n",
    "    mypath = Path(file)\n",
    "    if mypath.stat().st_size != 0:\n",
    "        data = pd.read_csv(file, sep='\\t', header=0)\n",
    "    if len(tokens) == 0:\n",
    "        tokens.extend( list(data.tokens) )\n",
    "    \n",
    "    sab = data.columns[-1]\n",
    "    if len(list( data[sab] )) == 1354953:\n",
    "        lfs[str(k)] = list( data[sab] )[:len(Y_tokens)]\n",
    "\n",
    "\n",
    "print( 'Total number of tokens in validation set: ', len(tokens) )\n",
    "print( 'Total number of LFs in the dictionary', len(lfs) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "001d73ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lf_levels(umls_d:dict, pattern:str, picos:str):\n",
    "\n",
    "    umls_level = dict()\n",
    "\n",
    "    for key, value in umls_d.items():   # iter on both keys and values\n",
    "        search_pattern = pattern + picos\n",
    "        if key.startswith(search_pattern):\n",
    "            k = str(key).split('_')[-1]\n",
    "            umls_level[ k ] = value\n",
    "\n",
    "    return umls_level\n",
    "\n",
    "# Level 1: UMLS\n",
    "umls_p = lf_levels(lfs, 'UMLS_fuzzy_', 'p')\n",
    "umls_i = lf_levels(lfs, 'UMLS_fuzzy_', 'i')\n",
    "umls_o = lf_levels(lfs, 'UMLS_fuzzy_', 'o')\n",
    "\n",
    "# Level 2: non UMLS\n",
    "nonumls_p = lf_levels(lfs, 'nonUMLS_fuzzy_', 'P')\n",
    "nonumls_i = lf_levels(lfs, 'nonUMLS_fuzzy_', 'I')\n",
    "nonumls_o = lf_levels(lfs, 'nonUMLS_fuzzy_', 'O')\n",
    "\n",
    "# Level 3: DS\n",
    "ds_p = lf_levels(lfs, 'DS_fuzzy_', 'P')\n",
    "ds_i = lf_levels(lfs, 'DS_fuzzy_', 'I')\n",
    "ds_o = lf_levels(lfs, 'DS_fuzzy_', 'O')\n",
    "\n",
    "# Level 4: dictionary, rules, heuristics\n",
    "heur_p = lf_levels(lfs, 'heuristics_direct_', 'P')\n",
    "heur_i = lf_levels(lfs, 'heuristics_direct_', 'I')\n",
    "heur_o = lf_levels(lfs, 'heuristics_direct_', 'O')\n",
    "\n",
    "dict_p = lf_levels(lfs, 'dictionary_direct_', 'P')\n",
    "dict_i = lf_levels(lfs, 'dictionary_direct_', 'I')\n",
    "dict_o = lf_levels(lfs, 'dictionary_direct_', 'O')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c0cc37ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare(s, t):\n",
    "    return sorted(s) == sorted(t)\n",
    "\n",
    "def getLFs(partition:list, umls_d:dict, seed_len:int):\n",
    "\n",
    "    all_lfs_combined = []\n",
    "    \n",
    "    for lf in partition: # for each lf in a partition\n",
    "        \n",
    "        combine_here = [0] * seed_len\n",
    "\n",
    "        for sab in lf:\n",
    "            new_a = umls_d[sab]\n",
    "            old_a = combine_here\n",
    "            temp_a = []\n",
    "            for o_a, n_a in zip(old_a, new_a):\n",
    "                if compare([o_a, n_a] ,[-1, 1]) == True:\n",
    "                    replace_a = max( o_a, n_a )\n",
    "                    temp_a.append( replace_a )\n",
    "                elif compare([o_a, n_a] ,[0, 1]) == True:\n",
    "                    replace_a = max( o_a, n_a )\n",
    "                    temp_a.append( replace_a )\n",
    "                elif compare([o_a, n_a] ,[-1, 0]) == True:\n",
    "                    replace_a = min( o_a, n_a )\n",
    "                    temp_a.append( replace_a )\n",
    "                else:\n",
    "                    temp_a.append( o_a )\n",
    "\n",
    "            combine_here = temp_a\n",
    "\n",
    "        all_lfs_combined.append( combine_here )\n",
    "\n",
    "    return all_lfs_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d35df6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search(model_class,\n",
    "                model_class_init,\n",
    "                param_grid,\n",
    "                train=None,\n",
    "                dev=None,\n",
    "                other_train=None,\n",
    "                n_model_search=5,\n",
    "                val_metric='f1',\n",
    "                seed=1234,\n",
    "                checkpoint_gt_mv=True,\n",
    "                tag_fmt_ckpnt='BIO'):\n",
    "    \n",
    "    \n",
    "    \"\"\"Simple grid search helper function\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model_class\n",
    "    model_class_init\n",
    "    param_grid\n",
    "    train\n",
    "    dev\n",
    "    n_model_search\n",
    "    val_metric\n",
    "    seed\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    \n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    L_train, Y_train = train\n",
    "    L_dev, Y_dev = dev\n",
    "    \n",
    "    # sample configs\n",
    "    params = sample_param_grid(param_grid, seed)[:n_model_search]\n",
    "    \n",
    "    defaults = {'seed': seed}\n",
    "    best_score, best_config = 0.0, None\n",
    "    print(f\"Grid search over {len(params)} configs\")\n",
    "    \n",
    "    for i, config in enumerate(params):\n",
    "        print(f'[{i}] Label Model')\n",
    "        config = dict(zip(param_grid.keys(), config))\n",
    "        # update default params if not specified\n",
    "        config.update({param: value for param, value in defaults.items() if param not in config})\n",
    "\n",
    "        model = model_class(**model_class_init)\n",
    "        \n",
    "        \n",
    "        Y_dev_hat = Y_dev\n",
    "        model.fit(L_train, Y_dev_hat, **config)\n",
    "        \n",
    "        y_pred = model.predict(L_dev)\n",
    "        \n",
    "        # set gold tags for evaluation\n",
    "        if tag_fmt_ckpnt == 'IO':\n",
    "            y_gold = np.array([0 if y == 0 else 1 for y in Y_dev])\n",
    "        else:\n",
    "            y_gold = Y_dev\n",
    "            \n",
    "            \n",
    "        if -1 in y_pred:\n",
    "            print(\"Label model predicted -1 (TODO: this happens inconsistently)\")\n",
    "            continue\n",
    "            \n",
    "        # use internal label model scorer to score the prediction\n",
    "        metrics = model.score(L=L_dev,\n",
    "                              Y=y_gold,\n",
    "                              metrics=['accuracy', 'precision', 'recall', 'f1', 'f1_macro'],\n",
    "                              tie_break_policy=0)\n",
    "        \n",
    "    \n",
    "        # compare learned model against MV on same labeled dev set\n",
    "        # skip if LM less than MV\n",
    "        if checkpoint_gt_mv:\n",
    "            mv_metrics = model.score(L=L_dev,\n",
    "                                  Y=y_gold,\n",
    "                                  metrics=['accuracy', 'precision', 'recall', 'f1', 'f1_macro'],\n",
    "                                  tie_break_policy=0)\n",
    "\n",
    "            if metrics[val_metric] < mv_metrics[val_metric]:\n",
    "                continue\n",
    "                \n",
    "        if not best_score or metrics[val_metric] > best_score[val_metric]:\n",
    "            print(config)\n",
    "            best_score = metrics\n",
    "            best_config = config\n",
    "            \n",
    "            # print training set score if we have labeled data\n",
    "            if np.any(Y_train):\n",
    "                y_pred = model.predict(L_train)\n",
    "\n",
    "                if tag_fmt_ckpnt == 'IO':\n",
    "                    y_gold = np.array([0 if y == 0 else 1 for y in Y_train])\n",
    "                else:\n",
    "                    y_gold = Y_train\n",
    "\n",
    "                metrics = model.score(L=L_train,\n",
    "                                      Y=y_gold,\n",
    "                                      metrics=['accuracy', 'precision', 'recall', 'f1', 'f1_macro'],\n",
    "                                      tie_break_policy=0)\n",
    "\n",
    "                print('[TRAIN] {}'.format(' | '.join([f'{m}: {v * 100:2.2f}' for m, v in metrics.items()])))\n",
    "\n",
    "            print('[DEV]   {}'.format(' | '.join([f'{m}: {v * 100:2.2f}' for m, v in best_score.items()])))\n",
    "            print('-' * 88)\n",
    "            \n",
    "            \n",
    "    # retrain best model\n",
    "    print('BEST')\n",
    "    print(best_config)\n",
    "    model = model_class(**model_class_init)\n",
    "    \n",
    "    \n",
    "    Y_dev_hat = Y_dev\n",
    "    model.fit(L_train, Y_dev_hat, **best_config)\n",
    "    return model, best_config, best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "78a1e865",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(partitioned_d_umls, umls_d, non_umls_d, ds_d, heur_d, dict_d, df_data_train, df_data_val, picos, paramgrid):\n",
    "   \n",
    "\n",
    "    best_f1_macro = 0.0\n",
    "    best_overall_model = ''\n",
    "    best_overall_config = ''\n",
    "    \n",
    "    \n",
    "    model_class_init = {\n",
    "        'cardinality': 2, \n",
    "        'verbose': True\n",
    "    }\n",
    "\n",
    "    num_hyperparams = functools.reduce(lambda x,y:x*y, [len(x) for x in param_grid.values()])\n",
    "    print(\"Hyperparamater Search Space:\", num_hyperparams)\n",
    "    n_model_search = num_hyperparams\n",
    "    \n",
    "\n",
    "\n",
    "    '''#########################################################################\n",
    "    # Choosing the number of LF's from UMLS all\n",
    "    #########################################################################'''\n",
    "    \n",
    "    for i, partition in enumerate(partitioned_d_umls):\n",
    "\n",
    "        combined_lf = getLFs(partition, umls_d, len(Y_tokens))\n",
    "        assert len(partition) == len(combined_lf)\n",
    "\n",
    "        print( 'Total number of UMLS partitions: ', len(partition) )\n",
    "        #print( 'Only UMLS: ', len(combined_lf) )\n",
    "        combined_lf.extend( list(non_umls_d.values()) ) # Combine with level 2\n",
    "        #print( 'Added nonUMLS: ', len(combined_lf) )\n",
    "        combined_lf.extend( list(ds_d.values()) ) # Combine with level 3\n",
    "        #print( 'Added DS: ', len(combined_lf) )\n",
    "        combined_lf.extend( list(heur_d.values()) ) # Combine with level 4\n",
    "        combined_lf.extend( list(dict_d.values()) ) # combine with level 4\n",
    "        #print( 'Added ReGeX and rules: ', len(combined_lf) )\n",
    "\n",
    "        L = np.array(combined_lf)\n",
    "        #print('Full array before split before transpose: ', L.shape)\n",
    "        L = np.transpose(L)\n",
    "        #print('Full array before split: ', L.shape)\n",
    "        L_train, L_val = train_test_split(L, test_size=0.20, shuffle=False)\n",
    "        #print('Full train array after split: ', L_train.shape)\n",
    "        #print('Full validation array after split: ', L_val.shape)\n",
    "\n",
    "        Y_train = df_data_train[picos]\n",
    "        Y_val = df_data_val[picos]\n",
    "\n",
    "        #print( len( L_train ) )\n",
    "        #print( len( L_val ) )\n",
    "        #print( len( Y_train ) )\n",
    "        #print( len( Y_val ) )\n",
    "        \n",
    "        best_model, best_config, best_score = grid_search(LMsnorkel, \n",
    "                                           model_class_init, \n",
    "                                           paramgrid,\n",
    "                                           train = (L_train, Y_train),\n",
    "                                           dev = (L_val, Y_val),\n",
    "                                           n_model_search=n_model_search, \n",
    "                                           val_metric='f1_macro', \n",
    "                                           seed=1234,\n",
    "                                           tag_fmt_ckpnt='IO')\n",
    "        \n",
    "        if best_score['f1_macro'] > best_f1_macro:\n",
    "            best_f1_macro = best_score['f1_macro']\n",
    "            best_overall_model = best_model\n",
    "            best_overall_config = best_config\n",
    "            \n",
    "        \n",
    "        print('Best overall macro F1 score: ', best_f1_macro)\n",
    "        print('Best overall configuration: ', best_overall_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "471b80b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'lr': [0.001, 0.0001],\n",
    "    'l2': [0.001, 0.0001],\n",
    "    'n_epochs': [50, 100, 200, 600, 700, 1000, 2000],\n",
    "    'prec_init': [0.6, 0.7, 0.8, 0.9],\n",
    "    'optimizer': [\"adamax\", \"adam\", \"sgd\"],\n",
    "    'lr_scheduler': ['constant'],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46eac91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparamater Search Space: 336\n",
      "Total number of UMLS partitions:  1\n",
      "Grid search over 336 configs\n",
      "[0] Label Model\n",
      "{'lr': 0.001, 'l2': 0.0001, 'n_epochs': 200, 'prec_init': 0.8, 'optimizer': 'adam', 'lr_scheduler': 'constant', 'seed': 1234}\n",
      "[TRAIN] accuracy: 87.89 | precision: 0.00 | recall: 0.00 | f1: 0.00 | f1_macro: 46.78\n",
      "[DEV]   accuracy: 87.70 | precision: 0.00 | recall: 0.00 | f1: 0.00 | f1_macro: 46.72\n",
      "----------------------------------------------------------------------------------------\n",
      "[1] Label Model\n",
      "[2] Label Model\n",
      "[3] Label Model\n",
      "{'lr': 0.001, 'l2': 0.0001, 'n_epochs': 700, 'prec_init': 0.9, 'optimizer': 'adamax', 'lr_scheduler': 'constant', 'seed': 1234}\n",
      "[TRAIN] accuracy: 87.05 | precision: 32.19 | recall: 6.29 | f1: 10.52 | f1_macro: 51.77\n",
      "[DEV]   accuracy: 86.93 | precision: 33.68 | recall: 6.46 | f1: 10.84 | f1_macro: 51.89\n",
      "----------------------------------------------------------------------------------------\n",
      "[4] Label Model\n",
      "{'lr': 0.001, 'l2': 0.001, 'n_epochs': 600, 'prec_init': 0.6, 'optimizer': 'adam', 'lr_scheduler': 'constant', 'seed': 1234}\n",
      "[TRAIN] accuracy: 85.21 | precision: 24.33 | recall: 10.51 | f1: 14.67 | f1_macro: 53.29\n",
      "[DEV]   accuracy: 85.14 | precision: 25.40 | recall: 10.73 | f1: 15.09 | f1_macro: 53.47\n",
      "----------------------------------------------------------------------------------------\n",
      "[5] Label Model\n",
      "[6] Label Model\n",
      "[7] Label Model\n",
      "[8] Label Model\n",
      "[9] Label Model\n",
      "[10] Label Model\n",
      "[11] Label Model\n",
      "[12] Label Model\n",
      "[13] Label Model\n",
      "[14] Label Model\n",
      "[15] Label Model\n",
      "[16] Label Model\n",
      "[17] Label Model\n",
      "[18] Label Model\n",
      "[19] Label Model\n",
      "[20] Label Model\n",
      "[21] Label Model\n",
      "[22] Label Model\n",
      "[23] Label Model\n",
      "[24] Label Model\n",
      "{'lr': 0.001, 'l2': 0.001, 'n_epochs': 2000, 'prec_init': 0.6, 'optimizer': 'adam', 'lr_scheduler': 'constant', 'seed': 1234}\n",
      "[TRAIN] accuracy: 77.83 | precision: 20.20 | recall: 28.16 | f1: 23.53 | f1_macro: 55.28\n",
      "[DEV]   accuracy: 77.83 | precision: 20.68 | recall: 28.31 | f1: 23.90 | f1_macro: 55.46\n",
      "----------------------------------------------------------------------------------------\n",
      "[25] Label Model\n",
      "[26] Label Model\n",
      "[27] Label Model\n",
      "[28] Label Model\n",
      "[29] Label Model\n",
      "[30] Label Model\n",
      "[31] Label Model\n",
      "[32] Label Model\n",
      "[33] Label Model\n",
      "[34] Label Model\n",
      "[35] Label Model\n",
      "[36] Label Model\n",
      "[37] Label Model\n",
      "[38] Label Model\n",
      "[39] Label Model\n",
      "[40] Label Model\n",
      "[41] Label Model\n",
      "[42] Label Model\n",
      "[43] Label Model\n",
      "[44] Label Model\n",
      "[45] Label Model\n",
      "[46] Label Model\n",
      "[47] Label Model\n",
      "[48] Label Model\n",
      "[49] Label Model\n",
      "[50] Label Model\n",
      "[51] Label Model\n",
      "[52] Label Model\n",
      "[53] Label Model\n",
      "[54] Label Model\n",
      "[55] Label Model\n",
      "[56] Label Model\n",
      "[57] Label Model\n",
      "[58] Label Model\n",
      "[59] Label Model\n",
      "[60] Label Model\n",
      "[61] Label Model\n",
      "[62] Label Model\n",
      "[63] Label Model\n",
      "[64] Label Model\n",
      "[65] Label Model\n",
      "[66] Label Model\n",
      "[67] Label Model\n",
      "[68] Label Model\n",
      "[69] Label Model\n",
      "[70] Label Model\n",
      "[71] Label Model\n",
      "[72] Label Model\n",
      "[73] Label Model\n",
      "[74] Label Model\n",
      "[75] Label Model\n",
      "[76] Label Model\n",
      "[77] Label Model\n",
      "[78] Label Model\n",
      "[79] Label Model\n",
      "[80] Label Model\n",
      "[81] Label Model\n",
      "[82] Label Model\n",
      "[83] Label Model\n",
      "[84] Label Model\n",
      "[85] Label Model\n",
      "[86] Label Model\n",
      "[87] Label Model\n",
      "[88] Label Model\n",
      "[89] Label Model\n",
      "[90] Label Model\n",
      "[91] Label Model\n",
      "[92] Label Model\n",
      "[93] Label Model\n",
      "[94] Label Model\n",
      "[95] Label Model\n",
      "[96] Label Model\n",
      "[97] Label Model\n",
      "[98] Label Model\n",
      "[99] Label Model\n",
      "[100] Label Model\n",
      "[101] Label Model\n",
      "[102] Label Model\n",
      "[103] Label Model\n",
      "[104] Label Model\n",
      "[105] Label Model\n",
      "[106] Label Model\n",
      "[107] Label Model\n",
      "[108] Label Model\n",
      "[109] Label Model\n",
      "[110] Label Model\n",
      "[111] Label Model\n",
      "[112] Label Model\n",
      "[113] Label Model\n",
      "[114] Label Model\n",
      "[115] Label Model\n",
      "[116] Label Model\n",
      "[117] Label Model\n",
      "[118] Label Model\n",
      "[119] Label Model\n",
      "[120] Label Model\n",
      "[121] Label Model\n",
      "[122] Label Model\n",
      "[123] Label Model\n",
      "{'lr': 0.001, 'l2': 0.0001, 'n_epochs': 2000, 'prec_init': 0.6, 'optimizer': 'adamax', 'lr_scheduler': 'constant', 'seed': 1234}\n",
      "[TRAIN] accuracy: 79.90 | precision: 21.80 | recall: 25.51 | f1: 23.51 | f1_macro: 55.97\n",
      "[DEV]   accuracy: 79.98 | precision: 22.51 | recall: 25.69 | f1: 24.00 | f1_macro: 56.23\n",
      "----------------------------------------------------------------------------------------\n",
      "[124] Label Model\n",
      "[125] Label Model\n",
      "[126] Label Model\n",
      "[127] Label Model\n",
      "[128] Label Model\n",
      "[129] Label Model\n",
      "[130] Label Model\n",
      "[131] Label Model\n",
      "[132] Label Model\n",
      "[133] Label Model\n",
      "[134] Label Model\n",
      "[135] Label Model\n",
      "[136] Label Model\n",
      "[137] Label Model\n",
      "[138] Label Model\n",
      "[139] Label Model\n",
      "[140] Label Model\n",
      "[141] Label Model\n",
      "[142] Label Model\n",
      "[143] Label Model\n",
      "[144] Label Model\n",
      "[145] Label Model\n",
      "[146] Label Model\n",
      "[147] Label Model\n",
      "[148] Label Model\n",
      "[149] Label Model\n",
      "[150] Label Model\n",
      "[151] Label Model\n",
      "[152] Label Model\n",
      "[153] Label Model\n",
      "[154] Label Model\n",
      "[155] Label Model\n",
      "[156] Label Model\n",
      "[157] Label Model\n",
      "[158] Label Model\n",
      "[159] Label Model\n",
      "[160] Label Model\n",
      "[161] Label Model\n",
      "[162] Label Model\n",
      "[163] Label Model\n",
      "[164] Label Model\n",
      "[165] Label Model\n",
      "[166] Label Model\n",
      "[167] Label Model\n",
      "[168] Label Model\n",
      "[169] Label Model\n",
      "[170] Label Model\n",
      "[171] Label Model\n",
      "[172] Label Model\n",
      "[173] Label Model\n",
      "[174] Label Model\n",
      "[175] Label Model\n",
      "[176] Label Model\n",
      "[177] Label Model\n",
      "[178] Label Model\n",
      "[179] Label Model\n",
      "[180] Label Model\n",
      "[181] Label Model\n",
      "[182] Label Model\n",
      "[183] Label Model\n",
      "[184] Label Model\n",
      "[185] Label Model\n",
      "[186] Label Model\n",
      "[187] Label Model\n",
      "[188] Label Model\n",
      "[189] Label Model\n",
      "[190] Label Model\n",
      "[191] Label Model\n",
      "[192] Label Model\n",
      "[193] Label Model\n",
      "[194] Label Model\n",
      "[195] Label Model\n",
      "[196] Label Model\n",
      "[197] Label Model\n",
      "[198] Label Model\n",
      "[199] Label Model\n",
      "[200] Label Model\n",
      "[201] Label Model\n",
      "[202] Label Model\n",
      "[203] Label Model\n",
      "[204] Label Model\n",
      "[205] Label Model\n",
      "[206] Label Model\n",
      "[207] Label Model\n",
      "[208] Label Model\n",
      "[209] Label Model\n",
      "[210] Label Model\n",
      "[211] Label Model\n",
      "[212] Label Model\n",
      "[213] Label Model\n",
      "[214] Label Model\n",
      "[215] Label Model\n",
      "[216] Label Model\n",
      "[217] Label Model\n",
      "[218] Label Model\n",
      "[219] Label Model\n",
      "[220] Label Model\n",
      "[221] Label Model\n",
      "[222] Label Model\n",
      "[223] Label Model\n",
      "[224] Label Model\n",
      "[225] Label Model\n",
      "[226] Label Model\n",
      "[227] Label Model\n",
      "[228] Label Model\n",
      "[229] Label Model\n",
      "[230] Label Model\n",
      "[231] Label Model\n",
      "[232] Label Model\n",
      "[233] Label Model\n",
      "[234] Label Model\n",
      "[235] Label Model\n",
      "[236] Label Model\n",
      "[237] Label Model\n",
      "[238] Label Model\n",
      "[239] Label Model\n",
      "[240] Label Model\n",
      "[241] Label Model\n",
      "[242] Label Model\n",
      "[243] Label Model\n",
      "[244] Label Model\n",
      "[245] Label Model\n",
      "[246] Label Model\n",
      "[247] Label Model\n",
      "[248] Label Model\n",
      "[249] Label Model\n",
      "[250] Label Model\n",
      "[251] Label Model\n",
      "[252] Label Model\n",
      "[253] Label Model\n",
      "[254] Label Model\n",
      "[255] Label Model\n",
      "[256] Label Model\n",
      "[257] Label Model\n",
      "[258] Label Model\n",
      "[259] Label Model\n",
      "[260] Label Model\n",
      "[261] Label Model\n",
      "[262] Label Model\n",
      "[263] Label Model\n",
      "[264] Label Model\n",
      "[265] Label Model\n",
      "[266] Label Model\n",
      "[267] Label Model\n",
      "[268] Label Model\n",
      "[269] Label Model\n",
      "[270] Label Model\n",
      "[271] Label Model\n",
      "[272] Label Model\n",
      "[273] Label Model\n",
      "[274] Label Model\n",
      "[275] Label Model\n",
      "[276] Label Model\n",
      "[277] Label Model\n",
      "[278] Label Model\n",
      "[279] Label Model\n",
      "[280] Label Model\n",
      "[281] Label Model\n",
      "[282] Label Model\n",
      "[283] Label Model\n",
      "[284] Label Model\n",
      "[285] Label Model\n",
      "[286] Label Model\n",
      "[287] Label Model\n",
      "[288] Label Model\n",
      "[289] Label Model\n",
      "[290] Label Model\n",
      "[291] Label Model\n",
      "[292] Label Model\n",
      "[293] Label Model\n",
      "[294] Label Model\n",
      "[295] Label Model\n",
      "[296] Label Model\n",
      "[297] Label Model\n",
      "[298] Label Model\n",
      "[299] Label Model\n",
      "[300] Label Model\n",
      "[301] Label Model\n",
      "[302] Label Model\n",
      "[303] Label Model\n",
      "[304] Label Model\n",
      "[305] Label Model\n",
      "[306] Label Model\n",
      "[307] Label Model\n",
      "[308] Label Model\n",
      "[309] Label Model\n",
      "[310] Label Model\n",
      "[311] Label Model\n",
      "[312] Label Model\n",
      "[313] Label Model\n",
      "[314] Label Model\n",
      "[315] Label Model\n",
      "[316] Label Model\n",
      "[317] Label Model\n",
      "[318] Label Model\n",
      "[319] Label Model\n",
      "[320] Label Model\n",
      "[321] Label Model\n",
      "[322] Label Model\n",
      "[323] Label Model\n",
      "[324] Label Model\n",
      "[325] Label Model\n",
      "[326] Label Model\n",
      "[327] Label Model\n",
      "[328] Label Model\n",
      "[329] Label Model\n",
      "[330] Label Model\n",
      "[331] Label Model\n",
      "[332] Label Model\n",
      "[333] Label Model\n",
      "[334] Label Model\n",
      "[335] Label Model\n",
      "BEST\n",
      "{'lr': 0.001, 'l2': 0.0001, 'n_epochs': 2000, 'prec_init': 0.6, 'optimizer': 'adamax', 'lr_scheduler': 'constant', 'seed': 1234}\n",
      "Best overall macro F1 score:  0.5623404464548678\n",
      "Best overall configuration:  {'lr': 0.001, 'l2': 0.0001, 'n_epochs': 2000, 'prec_init': 0.6, 'optimizer': 'adamax', 'lr_scheduler': 'constant', 'seed': 1234}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of UMLS partitions:  2\n",
      "Grid search over 336 configs\n",
      "[0] Label Model\n",
      "{'lr': 0.001, 'l2': 0.0001, 'n_epochs': 200, 'prec_init': 0.8, 'optimizer': 'adam', 'lr_scheduler': 'constant', 'seed': 1234}\n",
      "[TRAIN] accuracy: 87.95 | precision: 74.77 | recall: 0.76 | f1: 1.50 | f1_macro: 47.54\n",
      "[DEV]   accuracy: 87.78 | precision: 74.09 | recall: 0.98 | f1: 1.93 | f1_macro: 47.71\n",
      "----------------------------------------------------------------------------------------\n",
      "[1] Label Model\n",
      "[2] Label Model\n",
      "[3] Label Model\n",
      "{'lr': 0.001, 'l2': 0.0001, 'n_epochs': 700, 'prec_init': 0.9, 'optimizer': 'adamax', 'lr_scheduler': 'constant', 'seed': 1234}\n",
      "[TRAIN] accuracy: 87.04 | precision: 32.14 | recall: 6.32 | f1: 10.57 | f1_macro: 51.79\n",
      "[DEV]   accuracy: 86.91 | precision: 33.44 | recall: 6.50 | f1: 10.88 | f1_macro: 51.91\n",
      "----------------------------------------------------------------------------------------\n",
      "[4] Label Model\n",
      "{'lr': 0.001, 'l2': 0.001, 'n_epochs': 600, 'prec_init': 0.6, 'optimizer': 'adam', 'lr_scheduler': 'constant', 'seed': 1234}\n",
      "[TRAIN] accuracy: 85.18 | precision: 24.24 | recall: 10.54 | f1: 14.69 | f1_macro: 53.29\n",
      "[DEV]   accuracy: 85.10 | precision: 25.22 | recall: 10.76 | f1: 15.08 | f1_macro: 53.46\n",
      "----------------------------------------------------------------------------------------\n",
      "[5] Label Model\n",
      "[6] Label Model\n",
      "[7] Label Model\n",
      "[8] Label Model\n",
      "[9] Label Model\n",
      "[10] Label Model\n",
      "[11] Label Model\n",
      "[12] Label Model\n",
      "[13] Label Model\n",
      "[14] Label Model\n",
      "[15] Label Model\n",
      "[16] Label Model\n",
      "[17] Label Model\n",
      "{'lr': 0.001, 'l2': 0.001, 'n_epochs': 1000, 'prec_init': 0.8, 'optimizer': 'adamax', 'lr_scheduler': 'constant', 'seed': 1234}\n",
      "[TRAIN] accuracy: 85.33 | precision: 24.86 | recall: 10.45 | f1: 14.71 | f1_macro: 53.35\n",
      "[DEV]   accuracy: 85.25 | precision: 25.81 | recall: 10.65 | f1: 15.07 | f1_macro: 53.50\n",
      "----------------------------------------------------------------------------------------\n",
      "[18] Label Model\n",
      "[19] Label Model\n",
      "[20] Label Model\n",
      "[21] Label Model\n",
      "[22] Label Model\n",
      "[23] Label Model\n",
      "[24] Label Model\n",
      "{'lr': 0.001, 'l2': 0.001, 'n_epochs': 2000, 'prec_init': 0.6, 'optimizer': 'adam', 'lr_scheduler': 'constant', 'seed': 1234}\n",
      "[TRAIN] accuracy: 77.83 | precision: 20.20 | recall: 28.16 | f1: 23.53 | f1_macro: 55.28\n",
      "[DEV]   accuracy: 77.83 | precision: 20.68 | recall: 28.31 | f1: 23.90 | f1_macro: 55.46\n",
      "----------------------------------------------------------------------------------------\n",
      "[25] Label Model\n",
      "[26] Label Model\n",
      "[27] Label Model\n",
      "[28] Label Model\n",
      "[29] Label Model\n",
      "[30] Label Model\n",
      "[31] Label Model\n",
      "[32] Label Model\n",
      "[33] Label Model\n",
      "[34] Label Model\n",
      "[35] Label Model\n",
      "[36] Label Model\n",
      "[37] Label Model\n",
      "[38] Label Model\n",
      "[39] Label Model\n",
      "[40] Label Model\n",
      "[41] Label Model\n",
      "[42] Label Model\n",
      "[43] Label Model\n",
      "[44] Label Model\n",
      "[45] Label Model\n",
      "[46] Label Model\n",
      "[47] Label Model\n",
      "[48] Label Model\n",
      "[49] Label Model\n",
      "[50] Label Model\n",
      "[51] Label Model\n",
      "[52] Label Model\n",
      "[53] Label Model\n",
      "[54] Label Model\n",
      "[55] Label Model\n",
      "[56] Label Model\n",
      "[57] Label Model\n",
      "[58] Label Model\n",
      "[59] Label Model\n",
      "[60] Label Model\n",
      "[61] Label Model\n",
      "[62] Label Model\n",
      "[63] Label Model\n",
      "[64] Label Model\n",
      "[65] Label Model\n",
      "[66] Label Model\n",
      "[67] Label Model\n",
      "[68] Label Model\n",
      "[69] Label Model\n",
      "[70] Label Model\n",
      "[71] Label Model\n",
      "[72] Label Model\n",
      "[73] Label Model\n",
      "[74] Label Model\n",
      "[75] Label Model\n",
      "[76] Label Model\n",
      "[77] Label Model\n",
      "[78] Label Model\n",
      "[79] Label Model\n",
      "[80] Label Model\n",
      "[81] Label Model\n",
      "[82] Label Model\n",
      "[83] Label Model\n",
      "[84] Label Model\n",
      "[85] Label Model\n",
      "[86] Label Model\n",
      "[87] Label Model\n",
      "[88] Label Model\n",
      "[89] Label Model\n",
      "[90] Label Model\n",
      "[91] Label Model\n",
      "[92] Label Model\n",
      "[93] Label Model\n",
      "[94] Label Model\n",
      "[95] Label Model\n",
      "[96] Label Model\n",
      "[97] Label Model\n",
      "[98] Label Model\n",
      "[99] Label Model\n",
      "[100] Label Model\n",
      "[101] Label Model\n",
      "[102] Label Model\n",
      "[103] Label Model\n",
      "[104] Label Model\n",
      "[105] Label Model\n",
      "[106] Label Model\n",
      "[107] Label Model\n",
      "[108] Label Model\n",
      "[109] Label Model\n",
      "[110] Label Model\n",
      "[111] Label Model\n",
      "[112] Label Model\n",
      "[113] Label Model\n",
      "[114] Label Model\n",
      "[115] Label Model\n",
      "[116] Label Model\n",
      "[117] Label Model\n",
      "[118] Label Model\n",
      "[119] Label Model\n",
      "[120] Label Model\n",
      "[121] Label Model\n",
      "[122] Label Model\n",
      "[123] Label Model\n",
      "{'lr': 0.001, 'l2': 0.0001, 'n_epochs': 2000, 'prec_init': 0.6, 'optimizer': 'adamax', 'lr_scheduler': 'constant', 'seed': 1234}\n",
      "[TRAIN] accuracy: 79.88 | precision: 21.68 | recall: 25.32 | f1: 23.36 | f1_macro: 55.89\n",
      "[DEV]   accuracy: 79.96 | precision: 22.41 | recall: 25.56 | f1: 23.88 | f1_macro: 56.17\n",
      "----------------------------------------------------------------------------------------\n",
      "[124] Label Model\n",
      "[125] Label Model\n",
      "[126] Label Model\n",
      "[127] Label Model\n",
      "[128] Label Model\n",
      "[129] Label Model\n",
      "[130] Label Model\n",
      "[131] Label Model\n",
      "[132] Label Model\n",
      "[133] Label Model\n",
      "[134] Label Model\n",
      "[135] Label Model\n",
      "[136] Label Model\n",
      "[137] Label Model\n",
      "[138] Label Model\n",
      "[139] Label Model\n",
      "[140] Label Model\n",
      "[141] Label Model\n",
      "[142] Label Model\n",
      "[143] Label Model\n",
      "[144] Label Model\n",
      "[145] Label Model\n",
      "[146] Label Model\n",
      "[147] Label Model\n",
      "[148] Label Model\n",
      "[149] Label Model\n",
      "[150] Label Model\n",
      "[151] Label Model\n",
      "[152] Label Model\n",
      "[153] Label Model\n",
      "[154] Label Model\n",
      "[155] Label Model\n",
      "[156] Label Model\n",
      "[157] Label Model\n",
      "[158] Label Model\n",
      "[159] Label Model\n",
      "[160] Label Model\n",
      "[161] Label Model\n",
      "[162] Label Model\n",
      "[163] Label Model\n",
      "[164] Label Model\n",
      "[165] Label Model\n",
      "[166] Label Model\n",
      "[167] Label Model\n",
      "[168] Label Model\n",
      "[169] Label Model\n",
      "[170] Label Model\n",
      "[171] Label Model\n",
      "[172] Label Model\n",
      "[173] Label Model\n",
      "[174] Label Model\n",
      "[175] Label Model\n",
      "[176] Label Model\n",
      "[177] Label Model\n",
      "[178] Label Model\n",
      "[179] Label Model\n",
      "[180] Label Model\n",
      "[181] Label Model\n",
      "[182] Label Model\n",
      "[183] Label Model\n",
      "[184] Label Model\n",
      "[185] Label Model\n",
      "[186] Label Model\n",
      "[187] Label Model\n",
      "[188] Label Model\n",
      "[189] Label Model\n",
      "[190] Label Model\n",
      "[191] Label Model\n",
      "[192] Label Model\n",
      "[193] Label Model\n",
      "[194] Label Model\n",
      "[195] Label Model\n",
      "[196] Label Model\n",
      "[197] Label Model\n",
      "[198] Label Model\n",
      "[199] Label Model\n",
      "[200] Label Model\n",
      "[201] Label Model\n",
      "[202] Label Model\n",
      "[203] Label Model\n",
      "[204] Label Model\n",
      "[205] Label Model\n",
      "[206] Label Model\n",
      "[207] Label Model\n",
      "[208] Label Model\n",
      "[209] Label Model\n",
      "[210] Label Model\n",
      "[211] Label Model\n",
      "[212] Label Model\n",
      "[213] Label Model\n",
      "[214] Label Model\n",
      "[215] Label Model\n",
      "[216] Label Model\n",
      "[217] Label Model\n",
      "[218] Label Model\n",
      "[219] Label Model\n",
      "[220] Label Model\n",
      "[221] Label Model\n",
      "[222] Label Model\n",
      "[223] Label Model\n",
      "[224] Label Model\n",
      "[225] Label Model\n",
      "[226] Label Model\n",
      "[227] Label Model\n",
      "[228] Label Model\n",
      "[229] Label Model\n",
      "[230] Label Model\n",
      "[231] Label Model\n",
      "[232] Label Model\n",
      "[233] Label Model\n",
      "[234] Label Model\n",
      "[235] Label Model\n",
      "[236] Label Model\n",
      "[237] Label Model\n",
      "[238] Label Model\n",
      "[239] Label Model\n",
      "[240] Label Model\n",
      "[241] Label Model\n",
      "[242] Label Model\n",
      "[243] Label Model\n",
      "[244] Label Model\n",
      "[245] Label Model\n",
      "[246] Label Model\n",
      "[247] Label Model\n",
      "[248] Label Model\n",
      "[249] Label Model\n",
      "[250] Label Model\n",
      "[251] Label Model\n",
      "[252] Label Model\n",
      "[253] Label Model\n",
      "[254] Label Model\n",
      "[255] Label Model\n",
      "[256] Label Model\n",
      "[257] Label Model\n",
      "[258] Label Model\n",
      "[259] Label Model\n",
      "[260] Label Model\n",
      "[261] Label Model\n",
      "[262] Label Model\n",
      "[263] Label Model\n",
      "[264] Label Model\n",
      "[265] Label Model\n",
      "[266] Label Model\n",
      "[267] Label Model\n",
      "[268] Label Model\n",
      "[269] Label Model\n",
      "[270] Label Model\n",
      "[271] Label Model\n",
      "[272] Label Model\n",
      "[273] Label Model\n",
      "[274] Label Model\n",
      "[275] Label Model\n",
      "[276] Label Model\n",
      "[277] Label Model\n",
      "[278] Label Model\n",
      "[279] Label Model\n",
      "[280] Label Model\n",
      "[281] Label Model\n",
      "[282] Label Model\n",
      "[283] Label Model\n",
      "[284] Label Model\n",
      "[285] Label Model\n",
      "[286] Label Model\n",
      "[287] Label Model\n",
      "[288] Label Model\n",
      "[289] Label Model\n",
      "[290] Label Model\n",
      "[291] Label Model\n",
      "[292] Label Model\n",
      "[293] Label Model\n",
      "[294] Label Model\n",
      "[295] Label Model\n",
      "[296] Label Model\n",
      "[297] Label Model\n",
      "[298] Label Model\n",
      "[299] Label Model\n",
      "[300] Label Model\n",
      "[301] Label Model\n",
      "[302] Label Model\n",
      "[303] Label Model\n",
      "[304] Label Model\n",
      "[305] Label Model\n",
      "[306] Label Model\n",
      "[307] Label Model\n",
      "[308] Label Model\n",
      "[309] Label Model\n",
      "[310] Label Model\n",
      "[311] Label Model\n",
      "[312] Label Model\n",
      "[313] Label Model\n",
      "[314] Label Model\n",
      "[315] Label Model\n",
      "[316] Label Model\n",
      "[317] Label Model\n",
      "[318] Label Model\n",
      "[319] Label Model\n",
      "[320] Label Model\n",
      "[321] Label Model\n",
      "[322] Label Model\n",
      "[323] Label Model\n",
      "[324] Label Model\n",
      "[325] Label Model\n",
      "[326] Label Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[327] Label Model\n",
      "[328] Label Model\n",
      "[329] Label Model\n",
      "[330] Label Model\n",
      "[331] Label Model\n",
      "[332] Label Model\n",
      "[333] Label Model\n",
      "[334] Label Model\n",
      "[335] Label Model\n",
      "BEST\n",
      "{'lr': 0.001, 'l2': 0.0001, 'n_epochs': 2000, 'prec_init': 0.6, 'optimizer': 'adamax', 'lr_scheduler': 'constant', 'seed': 1234}\n",
      "Best overall macro F1 score:  0.5623404464548678\n",
      "Best overall configuration:  {'lr': 0.001, 'l2': 0.0001, 'n_epochs': 2000, 'prec_init': 0.6, 'optimizer': 'adamax', 'lr_scheduler': 'constant', 'seed': 1234}\n",
      "Total number of UMLS partitions:  3\n",
      "Grid search over 336 configs\n",
      "[0] Label Model\n",
      "{'lr': 0.001, 'l2': 0.0001, 'n_epochs': 200, 'prec_init': 0.8, 'optimizer': 'adam', 'lr_scheduler': 'constant', 'seed': 1234}\n",
      "[TRAIN] accuracy: 87.89 | precision: 49.11 | recall: 0.90 | f1: 1.77 | f1_macro: 47.66\n",
      "[DEV]   accuracy: 87.74 | precision: 58.27 | recall: 1.15 | f1: 2.26 | f1_macro: 47.86\n",
      "----------------------------------------------------------------------------------------\n",
      "[1] Label Model\n",
      "[2] Label Model\n",
      "[3] Label Model\n",
      "{'lr': 0.001, 'l2': 0.0001, 'n_epochs': 700, 'prec_init': 0.9, 'optimizer': 'adamax', 'lr_scheduler': 'constant', 'seed': 1234}\n",
      "[TRAIN] accuracy: 87.15 | precision: 33.45 | recall: 6.21 | f1: 10.48 | f1_macro: 51.78\n",
      "[DEV]   accuracy: 87.01 | precision: 34.70 | recall: 6.36 | f1: 10.75 | f1_macro: 51.87\n",
      "----------------------------------------------------------------------------------------\n",
      "[4] Label Model\n",
      "{'lr': 0.001, 'l2': 0.001, 'n_epochs': 600, 'prec_init': 0.6, 'optimizer': 'adam', 'lr_scheduler': 'constant', 'seed': 1234}\n",
      "[TRAIN] accuracy: 85.33 | precision: 24.96 | recall: 10.55 | f1: 14.83 | f1_macro: 53.40\n",
      "[DEV]   accuracy: 85.25 | precision: 25.92 | recall: 10.74 | f1: 15.19 | f1_macro: 53.55\n",
      "----------------------------------------------------------------------------------------\n",
      "[5] Label Model\n",
      "[6] Label Model\n",
      "[7] Label Model\n",
      "[8] Label Model\n",
      "[9] Label Model\n",
      "[10] Label Model\n",
      "[11] Label Model\n",
      "[12] Label Model\n",
      "[13] Label Model\n",
      "[14] Label Model\n",
      "[15] Label Model\n",
      "[16] Label Model\n",
      "[17] Label Model\n",
      "{'lr': 0.001, 'l2': 0.001, 'n_epochs': 1000, 'prec_init': 0.8, 'optimizer': 'adamax', 'lr_scheduler': 'constant', 'seed': 1234}\n",
      "[TRAIN] accuracy: 86.12 | precision: 28.56 | recall: 9.75 | f1: 14.53 | f1_macro: 53.49\n",
      "[DEV]   accuracy: 86.04 | precision: 29.82 | recall: 10.01 | f1: 14.98 | f1_macro: 53.69\n",
      "----------------------------------------------------------------------------------------\n",
      "[18] Label Model\n",
      "[19] Label Model\n",
      "[20] Label Model\n",
      "[21] Label Model\n",
      "[22] Label Model\n",
      "[23] Label Model\n",
      "[24] Label Model\n",
      "{'lr': 0.001, 'l2': 0.001, 'n_epochs': 2000, 'prec_init': 0.6, 'optimizer': 'adam', 'lr_scheduler': 'constant', 'seed': 1234}\n",
      "[TRAIN] accuracy: 77.83 | precision: 20.20 | recall: 28.16 | f1: 23.53 | f1_macro: 55.28\n",
      "[DEV]   accuracy: 77.83 | precision: 20.68 | recall: 28.31 | f1: 23.90 | f1_macro: 55.46\n",
      "----------------------------------------------------------------------------------------\n",
      "[25] Label Model\n",
      "[26] Label Model\n",
      "[27] Label Model\n",
      "[28] Label Model\n",
      "[29] Label Model\n",
      "[30] Label Model\n",
      "[31] Label Model\n",
      "[32] Label Model\n",
      "[33] Label Model\n",
      "[34] Label Model\n",
      "[35] Label Model\n",
      "[36] Label Model\n",
      "[37] Label Model\n",
      "[38] Label Model\n",
      "[39] Label Model\n",
      "[40] Label Model\n",
      "[41] Label Model\n",
      "[42] Label Model\n",
      "[43] Label Model\n",
      "[44] Label Model\n",
      "[45] Label Model\n",
      "[46] Label Model\n",
      "[47] Label Model\n",
      "[48] Label Model\n",
      "[49] Label Model\n",
      "[50] Label Model\n",
      "[51] Label Model\n",
      "[52] Label Model\n",
      "[53] Label Model\n",
      "[54] Label Model\n",
      "[55] Label Model\n",
      "[56] Label Model\n",
      "[57] Label Model\n",
      "[58] Label Model\n",
      "[59] Label Model\n",
      "[60] Label Model\n",
      "[61] Label Model\n",
      "[62] Label Model\n",
      "[63] Label Model\n",
      "[64] Label Model\n",
      "[65] Label Model\n",
      "[66] Label Model\n",
      "[67] Label Model\n",
      "[68] Label Model\n",
      "[69] Label Model\n",
      "[70] Label Model\n",
      "[71] Label Model\n",
      "[72] Label Model\n",
      "[73] Label Model\n",
      "[74] Label Model\n",
      "[75] Label Model\n",
      "[76] Label Model\n",
      "[77] Label Model\n",
      "[78] Label Model\n",
      "[79] Label Model\n",
      "[80] Label Model\n",
      "[81] Label Model\n",
      "[82] Label Model\n",
      "[83] Label Model\n",
      "[84] Label Model\n",
      "[85] Label Model\n",
      "[86] Label Model\n",
      "[87] Label Model\n",
      "[88] Label Model\n",
      "[89] Label Model\n",
      "[90] Label Model\n",
      "[91] Label Model\n",
      "[92] Label Model\n",
      "[93] Label Model\n",
      "[94] Label Model\n",
      "[95] Label Model\n",
      "[96] Label Model\n",
      "[97] Label Model\n",
      "[98] Label Model\n",
      "[99] Label Model\n",
      "[100] Label Model\n",
      "[101] Label Model\n",
      "[102] Label Model\n",
      "[103] Label Model\n",
      "[104] Label Model\n",
      "[105] Label Model\n",
      "[106] Label Model\n",
      "[107] Label Model\n",
      "[108] Label Model\n",
      "{'lr': 0.001, 'l2': 0.0001, 'n_epochs': 2000, 'prec_init': 0.6, 'optimizer': 'adam', 'lr_scheduler': 'constant', 'seed': 1234}\n",
      "[TRAIN] accuracy: 77.83 | precision: 20.20 | recall: 28.16 | f1: 23.53 | f1_macro: 55.28\n",
      "[DEV]   accuracy: 77.83 | precision: 20.68 | recall: 28.31 | f1: 23.90 | f1_macro: 55.46\n",
      "----------------------------------------------------------------------------------------\n",
      "[109] Label Model\n",
      "[110] Label Model\n",
      "[111] Label Model\n",
      "[112] Label Model\n",
      "[113] Label Model\n",
      "[114] Label Model\n",
      "[115] Label Model\n",
      "[116] Label Model\n",
      "[117] Label Model\n",
      "[118] Label Model\n",
      "[119] Label Model\n",
      "[120] Label Model\n",
      "[121] Label Model\n",
      "[122] Label Model\n",
      "[123] Label Model\n",
      "[124] Label Model\n",
      "[125] Label Model\n",
      "[126] Label Model\n",
      "[127] Label Model\n",
      "[128] Label Model\n",
      "[129] Label Model\n",
      "[130] Label Model\n",
      "[131] Label Model\n",
      "[132] Label Model\n",
      "[133] Label Model\n",
      "[134] Label Model\n",
      "[135] Label Model\n",
      "[136] Label Model\n",
      "[137] Label Model\n",
      "[138] Label Model\n",
      "[139] Label Model\n",
      "[140] Label Model\n",
      "[141] Label Model\n",
      "[142] Label Model\n",
      "[143] Label Model\n",
      "[144] Label Model\n",
      "[145] Label Model\n",
      "[146] Label Model\n",
      "[147] Label Model\n",
      "[148] Label Model\n",
      "[149] Label Model\n",
      "[150] Label Model\n",
      "[151] Label Model\n",
      "[152] Label Model\n",
      "[153] Label Model\n",
      "[154] Label Model\n",
      "[155] Label Model\n",
      "[156] Label Model\n",
      "[157] Label Model\n",
      "[158] Label Model\n",
      "[159] Label Model\n",
      "[160] Label Model\n",
      "[161] Label Model\n",
      "[162] Label Model\n",
      "[163] Label Model\n",
      "[164] Label Model\n",
      "{'lr': 0.001, 'l2': 0.0001, 'n_epochs': 2000, 'prec_init': 0.9, 'optimizer': 'adam', 'lr_scheduler': 'constant', 'seed': 1234}\n",
      "[TRAIN] accuracy: 78.16 | precision: 20.47 | recall: 27.83 | f1: 23.59 | f1_macro: 55.42\n",
      "[DEV]   accuracy: 78.16 | precision: 21.00 | recall: 28.07 | f1: 24.02 | f1_macro: 55.64\n",
      "----------------------------------------------------------------------------------------\n",
      "[165] Label Model\n",
      "[166] Label Model\n",
      "[167] Label Model\n",
      "[168] Label Model\n",
      "[169] Label Model\n",
      "[170] Label Model\n",
      "[171] Label Model\n",
      "[172] Label Model\n",
      "[173] Label Model\n",
      "[174] Label Model\n",
      "[175] Label Model\n",
      "[176] Label Model\n",
      "[177] Label Model\n",
      "[178] Label Model\n",
      "[179] Label Model\n",
      "[180] Label Model\n",
      "[181] Label Model\n",
      "[182] Label Model\n",
      "[183] Label Model\n",
      "[184] Label Model\n",
      "[185] Label Model\n",
      "[186] Label Model\n",
      "[187] Label Model\n",
      "[188] Label Model\n",
      "[189] Label Model\n",
      "[190] Label Model\n",
      "[191] Label Model\n",
      "[192] Label Model\n",
      "[193] Label Model\n",
      "[194] Label Model\n",
      "[195] Label Model\n",
      "[196] Label Model\n",
      "[197] Label Model\n",
      "[198] Label Model\n",
      "[199] Label Model\n",
      "[200] Label Model\n",
      "[201] Label Model\n",
      "[202] Label Model\n",
      "[203] Label Model\n",
      "[204] Label Model\n",
      "[205] Label Model\n",
      "[206] Label Model\n",
      "[207] Label Model\n",
      "[208] Label Model\n",
      "[209] Label Model\n",
      "[210] Label Model\n",
      "[211] Label Model\n",
      "[212] Label Model\n",
      "[213] Label Model\n",
      "[214] Label Model\n",
      "[215] Label Model\n",
      "[216] Label Model\n",
      "[217] Label Model\n",
      "[218] Label Model\n",
      "[219] Label Model\n",
      "[220] Label Model\n",
      "[221] Label Model\n",
      "[222] Label Model\n",
      "[223] Label Model\n",
      "[224] Label Model\n",
      "[225] Label Model\n",
      "[226] Label Model\n",
      "[227] Label Model\n",
      "[228] Label Model\n",
      "[229] Label Model\n",
      "[230] Label Model\n",
      "[231] Label Model\n",
      "[232] Label Model\n",
      "[233] Label Model\n",
      "[234] Label Model\n",
      "[235] Label Model\n",
      "[236] Label Model\n",
      "[237] Label Model\n",
      "[238] Label Model\n",
      "[239] Label Model\n",
      "[240] Label Model\n",
      "[241] Label Model\n",
      "[242] Label Model\n",
      "[243] Label Model\n",
      "[244] Label Model\n",
      "[245] Label Model\n",
      "[246] Label Model\n",
      "[247] Label Model\n",
      "[248] Label Model\n",
      "[249] Label Model\n",
      "[250] Label Model\n",
      "[251] Label Model\n",
      "[252] Label Model\n",
      "[253] Label Model\n",
      "[254] Label Model\n",
      "[255] Label Model\n",
      "[256] Label Model\n",
      "[257] Label Model\n",
      "[258] Label Model\n",
      "[259] Label Model\n",
      "[260] Label Model\n",
      "[261] Label Model\n",
      "[262] Label Model\n",
      "[263] Label Model\n",
      "[264] Label Model\n",
      "[265] Label Model\n",
      "[266] Label Model\n"
     ]
    }
   ],
   "source": [
    "train(partitioned_p_umls, umls_p, nonumls_p, ds_p, heur_p, dict_p, df_data_train, df_data_val, 'p', paramgrid = param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a059dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "train(partitioned_i_umls, umls_i, nonumls_i, ds_i, heur_i, dict_i, df_data_train, df_data_val, 'i', paramgrid = param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62116a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "train(partitioned_o_umls, umls_o, nonumls_o, ds_o, heur_o, dict_o, df_data_train, df_data_val, 'o', paramgrid = param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d204a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186b2a49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e7a40d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3003ed1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b693257e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb9a418e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "804ce646",
   "metadata": {},
   "source": [
    "# LF summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "43213204",
   "metadata": {},
   "outputs": [],
   "source": [
    "import enum\n",
    "import glob\n",
    "import os\n",
    "from hashlib import new\n",
    "from pathlib import Path\n",
    "import time\n",
    "from itertools import product\n",
    "\n",
    "import functools\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from snorkel.labeling.model import LabelModel as LMsnorkel\n",
    "from snorkel.labeling.model import MajorityLabelVoter\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import itertools\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "c8ad8635",
   "metadata": {},
   "outputs": [],
   "source": [
    "candgen_version = 'v4' # version = {v3, v4, ...}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "4a83b27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import json\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "c1640c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.exceptions import UndefinedMetricWarning\n",
    "\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "65582fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list2Nested(l, nested_length):\n",
    "    return [l[i:i+nested_length] for i in range(0, len(l), nested_length)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "0fb01e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import scipy.sparse as sparse\n",
    "from scipy.sparse import issparse\n",
    "from pandas import DataFrame, Series\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "\n",
    "def arraylike_to_numpy(array_like):\n",
    "    \"\"\"Convert a 1d array-like (e.g,. list, tensor, etc.) to an np.ndarray\"\"\"\n",
    "    \n",
    "    orig_type = type(array_like)\n",
    "    \n",
    "    # Convert to np.ndarray\n",
    "    if isinstance(array_like, np.ndarray):\n",
    "        pass\n",
    "    elif isinstance(array_like, list):\n",
    "        array_like = np.array(array_like)\n",
    "    elif issparse(array_like):\n",
    "        array_like = array_like.toarray()\n",
    "    elif isinstance(array_like, torch.Tensor):\n",
    "        array_like = array_like.numpy()\n",
    "    elif not isinstance(array_like, np.ndarray):\n",
    "        array_like = np.array(array_like)\n",
    "    else:\n",
    "        msg = f\"Input of type {orig_type} could not be converted to 1d \" \"np.ndarray\"\n",
    "        raise ValueError(msg)\n",
    "    \n",
    "    # Correct shape\n",
    "    if (array_like.ndim > 1) and (1 in array_like.shape):\n",
    "        array_like = array_like.flatten()\n",
    "    if array_like.ndim != 1:\n",
    "        raise ValueError(\"Input could not be converted to 1d np.array\")\n",
    "    \n",
    "    # Convert to ints\n",
    "    if any(array_like % 1):\n",
    "        raise ValueError(\"Input contains at least one non-integer value.\")\n",
    "    array_like = array_like.astype(np.dtype(int))\n",
    "\n",
    "    return array_like\n",
    "\n",
    "\n",
    "############################################################\n",
    "# Label Matrix Diagnostics\n",
    "############################################################\n",
    "def _covered_data_points(L):\n",
    "    \"\"\"Returns an indicator vector where ith element = 1 if x_i is labeled by at\n",
    "    least one LF.\"\"\"\n",
    "    return np.ravel(np.where(L.sum(axis=1) != 0, 1, 0))\n",
    "\n",
    "\n",
    "def _overlapped_data_points(L):\n",
    "    \"\"\"Returns an indicator vector where ith element = 1 if x_i is labeled by\n",
    "    more than one LF.\"\"\"\n",
    "    return np.where(np.ravel((L != 0).sum(axis=1)) > 1, 1, 0)\n",
    "\n",
    "\n",
    "def _conflicted_data_points(L):\n",
    "    \"\"\"Returns an indicator vector where ith element = 1 if x_i is labeled by\n",
    "    at least two LFs that give it disagreeing labels.\"\"\"\n",
    "    m = sparse.diags(np.ravel(L.max(axis=1).todense()))\n",
    "    return np.ravel(np.max(m @ (L != 0) != L, axis=1).astype(int).todense())\n",
    "\n",
    "\n",
    "def label_coverage(L):\n",
    "    \"\"\"Returns the **fraction of data points with > 0 (non-zero) labels**\n",
    "    Args:\n",
    "        L: an n x m scipy.sparse matrix where L_{i,j} is the label given by the\n",
    "            jth LF to the ith item\n",
    "    \"\"\"\n",
    "    return _covered_data_points(L).sum() / L.shape[0]\n",
    "\n",
    "\n",
    "def label_overlap(L):\n",
    "    \"\"\"Returns the **fraction of data points with > 1 (non-zero) labels**\n",
    "    Args:\n",
    "        L: an n x m scipy.sparse matrix where L_{i,j} is the label given by the\n",
    "            jth LF to the ith item\n",
    "    \"\"\"\n",
    "    return _overlapped_data_points(L).sum() / L.shape[0]\n",
    "\n",
    "\n",
    "def label_conflict(L):\n",
    "    \"\"\"Returns the **fraction of data points with conflicting (disagreeing)\n",
    "    lablels.**\n",
    "    Args:\n",
    "        L: an n x m scipy.sparse matrix where L_{i,j} is the label given by the\n",
    "            jth LF to the ith item\n",
    "    \"\"\"\n",
    "    return _conflicted_data_points(L).sum() / L.shape[0]\n",
    "\n",
    "\n",
    "def lf_polarities(L):\n",
    "    \"\"\"Return the polarities of each LF based on evidence in a label matrix.\n",
    "\n",
    "    Args:\n",
    "        L: an n x m scipy.sparse matrix where L_{i,j} is the label given by the\n",
    "            jth LF to the ith candidate\n",
    "    \"\"\"\n",
    "    polarities = [sorted(list(set(L[:, i].data))) for i in range(L.shape[1])]\n",
    "    return [p[0] if len(p) == 1 else p for p in polarities]\n",
    "\n",
    "\n",
    "def lf_coverages(L):\n",
    "    \"\"\"Return the **fraction of data points that each LF labels.**\n",
    "    Args:\n",
    "        L: an n x m scipy.sparse matrix where L_{i,j} is the label given by the\n",
    "            jth LF to the ith candidate\n",
    "    \"\"\"\n",
    "    return np.ravel((L != 0).sum(axis=0)) / L.shape[0]\n",
    "\n",
    "\n",
    "def lf_raw_coverages(L):\n",
    "    \"\"\"Raw number of covered instances\"\"\"\n",
    "    return np.ravel((L != 0).sum(axis=0))\n",
    "\n",
    "\n",
    "def lf_overlaps(L, normalize_by_coverage=False):\n",
    "    \"\"\"Return the **fraction of items each LF labels that are also labeled by at\n",
    "     least one other LF.**\n",
    "\n",
    "    Note that the maximum possible overlap fraction for an LF is the LF's\n",
    "    coverage, unless `normalize_by_coverage=True`, in which case it is 1.\n",
    "\n",
    "    Args:\n",
    "        L: an n x m scipy.sparse matrix where L_{i,j} is the label given by the\n",
    "            jth LF to the ith candidate\n",
    "        normalize_by_coverage: Normalize by coverage of the LF, so that it\n",
    "            returns the percent of LF labels that have overlaps.\n",
    "    \"\"\"\n",
    "    overlaps = (L != 0).T @ _overlapped_data_points(L) / L.shape[0]\n",
    "    if normalize_by_coverage:\n",
    "        overlaps /= lf_coverages(L)\n",
    "    return np.nan_to_num(overlaps)\n",
    "\n",
    "\n",
    "def lf_conflicts(L, normalize_by_overlaps=False):\n",
    "    \"\"\"Return the **fraction of items each LF labels that are also given a\n",
    "    different (non-abstain) label by at least one other LF.**\n",
    "\n",
    "    Note that the maximum possible conflict fraction for an LF is the LF's\n",
    "        overlaps fraction, unless `normalize_by_overlaps=True`, in which case it\n",
    "        is 1.\n",
    "\n",
    "    Args:\n",
    "        L: an n x m scipy.sparse matrix where L_{i,j} is the label given by the\n",
    "            jth LF to the ith candidate\n",
    "        normalize_by_overlaps: Normalize by overlaps of the LF, so that it\n",
    "            returns the percent of LF overlaps that have conflicts.\n",
    "    \"\"\"\n",
    "    conflicts = (L != 0).T @ _conflicted_data_points(L) / L.shape[0]\n",
    "    if normalize_by_overlaps:\n",
    "        conflicts /= lf_overlaps(L)\n",
    "    return np.nan_to_num(conflicts)\n",
    "\n",
    "\n",
    "\n",
    "def lf_empirical_accuracies(L, Y):\n",
    "    \"\"\"Return the **empirical accuracy** against a set of labels Y (e.g. dev\n",
    "    set) for each LF.\n",
    "    Args:\n",
    "        L: an n x m scipy.sparse matrix where L_{i,j} is the label given by the\n",
    "            jth LF to the ith candidate\n",
    "        Y: an [n] or [n, 1] np.ndarray of gold labels\n",
    "    \"\"\"\n",
    "    # Assume labeled set is small, work with dense matrices\n",
    "    Y = arraylike_to_numpy(Y)\n",
    "    L = L.toarray()\n",
    "    X = np.where(\n",
    "        L == 0,\n",
    "        0,\n",
    "        np.where(L == np.vstack([Y] * L.shape[1]).T, 1, -1)\n",
    "    )\n",
    "    return 0.5 * (X.sum(axis=0) / (L != 0).sum(axis=0) + 1)\n",
    "\n",
    "\n",
    "def lf_summary(L, Y=None, lf_names=None, est_accs=None):\n",
    "    \"\"\"Returns a pandas DataFrame with the various per-LF statistics.\n",
    "\n",
    "    Args:\n",
    "        L: an n x m scipy.sparse matrix where L_{i,j} is the label given by the\n",
    "            jth LF to the ith candidate\n",
    "        Y: an [n] or [n, 1] np.ndarray of gold labels.\n",
    "            If provided, the empirical accuracy for each LF will be calculated\n",
    "    \"\"\"\n",
    "    n, m = L.shape\n",
    "    if lf_names is not None:\n",
    "        col_names = [\"j\"]\n",
    "        d = {\"j\": list(range(m))}\n",
    "    else:\n",
    "        lf_names = list(range(m))\n",
    "        col_names = []\n",
    "        d = {}\n",
    "\n",
    "    # Default LF stats\n",
    "    col_names.extend([\"Polarity\", \"Coverage%\", \"Overlaps%\", \"Conflicts%\", \"Coverage\"])\n",
    "    d[\"Polarity\"] = Series(data=lf_polarities(L), index=lf_names)\n",
    "    d[\"Coverage%\"] = Series(data=lf_coverages(L), index=lf_names)\n",
    "    d[\"Overlaps%\"] = Series(data=lf_overlaps(L), index=lf_names)\n",
    "    d[\"Conflicts%\"] = Series(data=lf_conflicts(L), index=lf_names)\n",
    "\n",
    "    d[\"Coverage\"] = Series(data=lf_raw_coverages(L), index=lf_names)\n",
    "    \n",
    "\n",
    "    if Y is not None:\n",
    "        col_names.extend([\"Correct\", \"Incorrect\", \"Emp. Acc.\"])\n",
    "        confusions = [\n",
    "            confusion_matrix(Y, L[:, i], pretty_print=False) for i in range(m)\n",
    "        ]\n",
    "        corrects = [np.diagonal(conf).sum() for conf in confusions]\n",
    "        incorrects = [\n",
    "            conf.sum() - correct for conf, correct in zip(confusions, corrects)\n",
    "        ]\n",
    "        accs = lf_empirical_accuracies(L, Y)\n",
    "        d[\"Correct\"] = Series(data=corrects, index=lf_names)\n",
    "        d[\"Incorrect\"] = Series(data=incorrects, index=lf_names)\n",
    "        d[\"Emp. Acc.\"] = Series(data=accs, index=lf_names)\n",
    "\n",
    "    if est_accs is not None:\n",
    "        col_names.append(\"Learned Acc.\")\n",
    "        d[\"Learned Acc.\"] = Series(est_accs, index=lf_names)\n",
    "\n",
    "    return DataFrame(data=d, index=lf_names)[col_names]\n",
    "\n",
    "\n",
    "def single_lf_summary(Y_p, Y=None):\n",
    "    \"\"\"Calculates coverage, overlap, conflicts, and accuracy for a single LF\n",
    "\n",
    "    Args:\n",
    "        Y_p: a np.array or torch.Tensor of predicted labels\n",
    "        Y: a np.array or torch.Tensor of true labels (if known)\n",
    "    \"\"\"\n",
    "    L = sparse.csr_matrix(arraylike_to_numpy(Y_p).reshape(-1, 1))\n",
    "    return lf_summary(L, Y)\n",
    "\n",
    "\n",
    "def error_buckets(gold, pred, X=None):\n",
    "    \"\"\"Group items by error buckets\n",
    "\n",
    "    Args:\n",
    "        gold: an array-like of gold labels (ints)\n",
    "        pred: an array-like of predictions (ints)\n",
    "        X: an iterable of items\n",
    "    Returns:\n",
    "        buckets: A dict of items where buckets[i,j] is a list of items with\n",
    "            predicted label i and true label j. If X is None, return indices\n",
    "            instead.\n",
    "\n",
    "    For a binary problem with (1=positive, 2=negative):\n",
    "        buckets[1,1] = true positives\n",
    "        buckets[1,2] = false positives\n",
    "        buckets[2,1] = false negatives\n",
    "        buckets[2,2] = true negatives\n",
    "    \"\"\"\n",
    "    buckets = defaultdict(list)\n",
    "    gold = arraylike_to_numpy(gold)\n",
    "    pred = arraylike_to_numpy(pred)\n",
    "    for i, (y, l) in enumerate(zip(pred, gold)):\n",
    "        buckets[y, l].append(X[i] if X is not None else i)\n",
    "    return buckets\n",
    "\n",
    "\n",
    "def confusion_matrix(\n",
    "    gold, pred, null_pred=False, null_gold=False, normalize=False, pretty_print=True\n",
    "):\n",
    "    \"\"\"A shortcut method for building a confusion matrix all at once.\n",
    "\n",
    "    Args:\n",
    "        gold: an array-like of gold labels (ints)\n",
    "        pred: an array-like of predictions (ints)\n",
    "        null_pred: If True, include the row corresponding to null predictions\n",
    "        null_gold: If True, include the col corresponding to null gold labels\n",
    "        normalize: if True, divide counts by the total number of items\n",
    "        pretty_print: if True, pretty-print the matrix before returning\n",
    "    \"\"\"\n",
    "    conf = ConfusionMatrix(null_pred=null_pred, null_gold=null_gold)\n",
    "    gold = arraylike_to_numpy(gold)\n",
    "    pred = arraylike_to_numpy(pred)\n",
    "    conf.add(gold, pred)\n",
    "    mat = conf.compile()\n",
    "\n",
    "    if normalize:\n",
    "        mat = mat / len(gold)\n",
    "\n",
    "    if pretty_print:\n",
    "        conf.display(normalize=normalize)\n",
    "\n",
    "    return mat\n",
    "\n",
    "\n",
    "class ConfusionMatrix(object):\n",
    "    \"\"\"\n",
    "    An iteratively built abstention-aware confusion matrix with pretty printing\n",
    "\n",
    "    Assumed axes are true label on top, predictions on the side.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, null_pred=False, null_gold=False):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            null_pred: If True, include the row corresponding to null\n",
    "                predictions\n",
    "            null_gold: If True, include the col corresponding to null gold\n",
    "                labels\n",
    "\n",
    "        \"\"\"\n",
    "        self.counter = Counter()\n",
    "        self.mat = None\n",
    "        self.null_pred = null_pred\n",
    "        self.null_gold = null_gold\n",
    "\n",
    "    def __repr__(self):\n",
    "        if self.mat is None:\n",
    "            self.compile()\n",
    "        return str(self.mat)\n",
    "\n",
    "    def add(self, gold, pred):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            gold: a np.ndarray of gold labels (ints)\n",
    "            pred: a np.ndarray of predictions (ints)\n",
    "        \"\"\"\n",
    "        self.counter.update(zip(gold, pred))\n",
    "\n",
    "    def compile(self, trim=True):\n",
    "        k = max([max(tup) for tup in self.counter.keys()]) + 1  # include 0\n",
    "\n",
    "        mat = np.zeros((k, k), dtype=int)\n",
    "        for (y, l), v in self.counter.items():\n",
    "            mat[l, y] = v\n",
    "\n",
    "        if trim and not self.null_pred:\n",
    "            mat = mat[1:, :]\n",
    "        if trim and not self.null_gold:\n",
    "            mat = mat[:, 1:]\n",
    "\n",
    "        self.mat = mat\n",
    "        return mat\n",
    "\n",
    "    def display(self, normalize=False, indent=0, spacing=2, decimals=3, mark_diag=True):\n",
    "        mat = self.compile(trim=False)\n",
    "        m, n = mat.shape\n",
    "        tab = \" \" * spacing\n",
    "        margin = \" \" * indent\n",
    "\n",
    "        # Print headers\n",
    "        s = margin + \" \" * (5 + spacing)\n",
    "        for j in range(n):\n",
    "            if j == 0 and not self.null_gold:\n",
    "                continue\n",
    "            s += f\" y={j} \" + tab\n",
    "        print(s)\n",
    "\n",
    "        # Print data\n",
    "        for i in range(m):\n",
    "            # Skip null predictions row if necessary\n",
    "            if i == 0 and not self.null_pred:\n",
    "                continue\n",
    "            s = margin + f\" l={i} \" + tab\n",
    "            for j in range(n):\n",
    "                # Skip null gold if necessary\n",
    "                if j == 0 and not self.null_gold:\n",
    "                    continue\n",
    "                else:\n",
    "                    if i == j and mark_diag and normalize:\n",
    "                        s = s[:-1] + \"*\"\n",
    "                    if normalize:\n",
    "                        s += f\"{mat[i,j]/sum(mat[i,1:]):>5.3f}\" + tab\n",
    "                    else:\n",
    "                        s += f\"{mat[i,j]:^5d}\" + tab\n",
    "            print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "b807154b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from LabelModelTrain import LMutils\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "86d6a2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_mapper_GT = {1:1, 0:2}\n",
    "label_mapper_LF = {1:1, -1:2, 0:0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "27400774",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapTrueLabels(l):\n",
    "    \n",
    "    updated_values = []\n",
    "    for l_i in l:\n",
    "        updated_values.append( label_mapper[l_i] )\n",
    "        \n",
    "    return updated_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "9d6f3ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = f'/mnt/nas2/results/Results/systematicReview/distant_pico/EBM_PICO_GT/{candgen_version}/gt/train_ebm_labels_tui_pio3.tsv'\n",
    "training_data = pd.read_csv(train_file, sep='\\t', header=0)\n",
    "\n",
    "ebm_test_file = f'/mnt/nas2/results/Results/systematicReview/distant_pico/EBM_PICO_GT/{candgen_version}/gt/test_ebm_labels_tui_pio3.tsv'\n",
    "test_ebm_data = pd.read_csv(ebm_test_file, sep='\\t', header=0)\n",
    "test_ebm_data.rename( columns={'Unnamed: 0':'series'}, inplace=True )\n",
    "\n",
    "physio_test_file = f'/mnt/nas2/results/Results/systematicReview/distant_pico/EBM_PICO_GT/{candgen_version}/gt/test_physio_labels_tui_pio3.tsv'\n",
    "test_physio_data = pd.read_csv(physio_test_file, sep='\\t', header=0)\n",
    "test_physio_data.rename( columns={'Unnamed: 0':'series'}, inplace=True )\n",
    "\n",
    "ebm_test_corrected_file = f'/mnt/nas2/results/Results/systematicReview/distant_pico/EBM_PICO_GT/{candgen_version}/gt/test_ebm_correctedlabels_tui_pio3.tsv'\n",
    "test_ebm_corrected_data = pd.read_csv(ebm_test_corrected_file, sep='\\t', header=0)\n",
    "test_ebm_corrected_data.rename( columns={'Unnamed: 0':'series'}, inplace=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "466736e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_df(df):\n",
    "\n",
    "    df_series = [ index for index, value in df.tokens.items() for word in ast.literal_eval(value) ]\n",
    "    df_tokens = [ word for index, value in df.tokens.items() for word in ast.literal_eval(value) ]\n",
    "    df_pos = [ word for index, value in df.pos.items() for word in ast.literal_eval(value) ]\n",
    "    df_offsets = [ word for index, value in df.offsets.items() for word in ast.literal_eval(value) ]\n",
    "\n",
    "\n",
    "    df_p = [ int(lab) for index, value in df.p.items() for lab in ast.literal_eval(value) ]\n",
    "    df_p_fine = [ int(lab) for index, value in df.p_f.items() for lab in ast.literal_eval(value) ]\n",
    "    df_i = [ int(lab) for index, value in df.i.items() for lab in ast.literal_eval(value) ]\n",
    "    df_i_fine = [ int(lab) for index, value in df.i_f.items() for lab in ast.literal_eval(value) ]\n",
    "    df_o = [ int(lab) for index, value in df.o.items() for lab in ast.literal_eval(value) ]\n",
    "    df_o_fine = [ int(lab) for index, value in df.o_f.items() for lab in ast.literal_eval(value) ]\n",
    "    df_s = [ int(lab) for index, value in df.s.items() for lab in ast.literal_eval(value) ]\n",
    "    df_s_fine = [ int(lab) for index, value in df.s_f.items() for lab in ast.literal_eval(value) ]\n",
    "    \n",
    "    df_flattened = pd.DataFrame({ 'series': df_series,\n",
    "                        'tokens' : df_tokens,\n",
    "                        'offsets': df_offsets,\n",
    "                        'pos': df_pos,\n",
    "                        'p' : df_p,\n",
    "                        'i' : df_i,\n",
    "                        'o' : df_o,\n",
    "                        's' : df_s,\n",
    "                        'p_f' : df_p_fine,\n",
    "                        'i_f' : df_i_fine,\n",
    "                        'o_f' : df_o_fine,\n",
    "                        's_f' : df_s_fine})\n",
    "    \n",
    "    return df_flattened"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "afb257b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten the dataframes (currently only the training dataframe and test ebm dataframe with corrected labels can be flattened)\n",
    "data_df = flatten_df(training_data)\n",
    "test_ebm_data = flatten_df(test_ebm_data)\n",
    "test_ebm_corr_df = flatten_df(test_ebm_corrected_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "94f87d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "series = [\n",
    "    data_df.series.to_numpy() ,\n",
    "    test_ebm_data.series.to_numpy() ,\n",
    "    test_physio_data.series.to_numpy(),   \n",
    "    test_ebm_corr_df.series.to_numpy()\n",
    "]\n",
    "\n",
    "\n",
    "sents = [\n",
    "    data_df.tokens.to_numpy() ,\n",
    "    test_ebm_data.tokens.to_numpy() ,\n",
    "    test_physio_data.tokens.to_numpy(),   \n",
    "    test_ebm_corr_df.tokens.to_numpy()    \n",
    "]\n",
    "\n",
    "\n",
    "part_of_speech = [\n",
    "    data_df.pos.to_numpy() ,\n",
    "    test_ebm_data.pos.to_numpy() ,\n",
    "    test_physio_data.pos.to_numpy(),   \n",
    "    test_ebm_corr_df.pos.to_numpy()     \n",
    "]\n",
    "\n",
    "\n",
    "offsets = [\n",
    "    data_df.offsets.to_numpy() ,\n",
    "    test_ebm_data.offsets.to_numpy() ,\n",
    "    test_physio_data.offsets.to_numpy(),   \n",
    "    test_ebm_corr_df.offsets.to_numpy() \n",
    "]\n",
    "\n",
    "\n",
    "Y_p = [\n",
    "    data_df.p.to_numpy() , # 0 -7\n",
    "    data_df.p_f.to_numpy() , # 1 -6\n",
    "    test_ebm_data.p.to_numpy() , # 2 -5\n",
    "    test_ebm_data.p_f.to_numpy() , # 3 -4\n",
    "    test_physio_data.p.to_numpy(),  # 4 -3\n",
    "    test_ebm_corr_df.p.to_numpy(),   # 5 -2\n",
    "    test_ebm_corr_df.p_f.to_numpy() # 6 -1\n",
    "]\n",
    "\n",
    "\n",
    "Y_i = [\n",
    "    data_df.i.to_numpy() , # 0 -7\n",
    "    data_df.i_f.to_numpy() , # 1 -6\n",
    "    test_ebm_data.i.to_numpy() , # 2 -5\n",
    "    test_ebm_data.i_f.to_numpy() , # 3 -4\n",
    "    test_physio_data.i.to_numpy(),  # 4 -3\n",
    "    test_ebm_corr_df.i.to_numpy(),   # 5 -2\n",
    "    test_ebm_corr_df.i_f.to_numpy() # 6 -1\n",
    "]\n",
    "\n",
    "\n",
    "Y_o = [\n",
    "    data_df.o.to_numpy() , # 0 -7\n",
    "    data_df.o_f.to_numpy() , # 1 -6\n",
    "    test_ebm_data.o.to_numpy() , # 2 -5\n",
    "    test_ebm_data.o_f.to_numpy() , # 3 -4\n",
    "    test_physio_data.o.to_numpy(),  # 4 -3\n",
    "    test_ebm_corr_df.o.to_numpy(),   # 5 -2\n",
    "    test_ebm_corr_df.o_f.to_numpy() # 6 -1\n",
    "]\n",
    "\n",
    "Y_s = [\n",
    "    data_df.s.to_numpy() , # 0 -7\n",
    "    data_df.s_f.to_numpy() , # 1 -6\n",
    "    test_ebm_data.s.to_numpy() , # 2 -5\n",
    "    test_ebm_data.s_f.to_numpy() , # 3 -4\n",
    "    test_physio_data.s.to_numpy(),  # 4 -3\n",
    "    test_ebm_corr_df.s.to_numpy(),   # 5 -2\n",
    "    test_ebm_corr_df.s_f.to_numpy() # 6 -1\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "79471b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_list(data_column):\n",
    "    return [ word for index, value in data_column.items() for word in ast.literal_eval(value) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "2e7d4903",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_array(data_column):\n",
    "    return np.array( [ word for index, value in data_column.items() for word in ast.literal_eval(value) ] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "6ce75c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_to_array(label_column):\n",
    "    return np.array( [ labelModel_mapper_LF[int(lab)] for index, value in label_column.items() for k, lab in ast.literal_eval(value).items() ] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "7be69b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1:1 positive to positive\n",
    "# -1:0 negative cand_gen to negative in label model\n",
    "# 0:-1 Abstain cand_gen to abstain in label model\n",
    "\n",
    "# In study type, abstain is actually a negative instance \n",
    "#labelModel_mapper_LF = {1:1, 0:0, -1:-1}\n",
    "#labelModel_mapper_LF = {1:1, -1:0, 0:-1}\n",
    "\n",
    "labelModel_mapper_LF = {1:1, 0:2, -1:0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "a2fc0bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lfs(indir):\n",
    "    \n",
    "    pathlist = Path(indir).glob('**/*.tsv')\n",
    "\n",
    "    tokens = ''\n",
    "\n",
    "    lfs = dict()\n",
    "    lfs_lm = dict()\n",
    "\n",
    "    for counter, file in enumerate(pathlist):\n",
    "        \n",
    "        if '/S/' in str(file):\n",
    "\n",
    "            k = str( file ).split(f'/{candgen_version}/')[-1].replace('.tsv', '').replace('/', '_')\n",
    "            mypath = Path(file)\n",
    "            if mypath.stat().st_size != 0:\n",
    "                data = pd.read_csv(file, sep='\\t', header=0)\n",
    "\n",
    "                data_tokens = data.tokens\n",
    "                if len(tokens) < 5:\n",
    "                    tokens = df_to_array(data_tokens)\n",
    "\n",
    "                data_labels = data.labels\n",
    "                #print(data_labels[1:2])\n",
    "                labels = dict_to_array(data_labels)\n",
    "                #print(labels)\n",
    "                if len(labels) != len(tokens):\n",
    "                    print(k, len(labels) , len(tokens) )\n",
    "                #assert len(labels) == len(tokens)\n",
    "                lfs[k] = labels\n",
    "\n",
    "\n",
    "    print( 'Total number of tokens in validation set: ', len(tokens) )\n",
    "    print( 'Total number of LFs in the dictionary', len(lfs) )\n",
    "    \n",
    "    return lfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "c25f7f3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of tokens in validation set:  1303169\n",
      "Total number of LFs in the dictionary 19\n"
     ]
    }
   ],
   "source": [
    "indir = f'/mnt/nas2/results/Results/systematicReview/distant_pico/training_ebm_candidate_generation/{candgen_version}'\n",
    "train_ebm_lfs = get_lfs(indir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "22694193",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of tokens in validation set:  52582\n",
      "Total number of LFs in the dictionary 19\n"
     ]
    }
   ],
   "source": [
    "indir_test_ebm_corr = f'/mnt/nas2/results/Results/systematicReview/distant_pico/test_ebm_anjani_candidate_generation/{candgen_version}'\n",
    "test_ebm_corr_lfs = get_lfs(indir_test_ebm_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "ff3f7a44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of tokens in validation set:  51784\n",
      "Total number of LFs in the dictionary 19\n"
     ]
    }
   ],
   "source": [
    "indir_test_ebm = f'/mnt/nas2/results/Results/systematicReview/distant_pico/test_ebm_candidate_generation/{candgen_version}'\n",
    "test_ebm_lfs = get_lfs(indir_test_ebm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "6c97280d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_lfs = pd.DataFrame({ key:pd.Series(value) for key, value in train_ebm_lfs.items() })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "5d529feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_lf, val_lf = train_test_split(dict_lfs, test_size=0.20, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "7236b023",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y, val_y = train_test_split(data_df.s_f.to_numpy(), test_size=0.20, shuffle=False)\n",
    "\n",
    "# Map \n",
    "\n",
    "label_mapper_GT = {1:1, 0:2}\n",
    "\n",
    "train_y_mapped = [ label_mapper_GT[i] for i in train_y]\n",
    "val_y_mapped = [ label_mapper_GT[i] for i in val_y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "871bbf2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_lf_names = [*train_lf]\n",
    "val_lf_names = [*val_lf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "d55aa899",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSummary_and_write(df, df_col_head, true_labels, file_path):\n",
    "    \n",
    "    #convert to sciy matrix\n",
    "    scipy_mat = scipy.sparse.csr_matrix(df.values)\n",
    "    \n",
    "    lf_summary_df = lf_summary(scipy_mat, Y=true_labels, lf_names=df_col_head)\n",
    "    \n",
    "    lf_summary_df.to_csv(file_path, sep='\\t')\n",
    "    \n",
    "    \n",
    "    return lf_summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "9ba70346",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>j</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Coverage%</th>\n",
       "      <th>Overlaps%</th>\n",
       "      <th>Conflicts%</th>\n",
       "      <th>Coverage</th>\n",
       "      <th>Correct</th>\n",
       "      <th>Incorrect</th>\n",
       "      <th>Emp. Acc.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dictionary_fuzzy_S_lf_dict_s_type</th>\n",
       "      <td>0</td>\n",
       "      <td>[1, 2]</td>\n",
       "      <td>0.635197</td>\n",
       "      <td>0.635197</td>\n",
       "      <td>0.017481</td>\n",
       "      <td>662215</td>\n",
       "      <td>657604</td>\n",
       "      <td>4611</td>\n",
       "      <td>0.993037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dictionary_fuzzy_S_lf_dict_s_comp_type</th>\n",
       "      <td>1</td>\n",
       "      <td>[1, 2]</td>\n",
       "      <td>0.632112</td>\n",
       "      <td>0.632112</td>\n",
       "      <td>0.014397</td>\n",
       "      <td>658999</td>\n",
       "      <td>654232</td>\n",
       "      <td>4767</td>\n",
       "      <td>0.992766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dictionary_direct_S_lf_dict_s_type</th>\n",
       "      <td>2</td>\n",
       "      <td>[1, 2]</td>\n",
       "      <td>0.635197</td>\n",
       "      <td>0.635197</td>\n",
       "      <td>0.017481</td>\n",
       "      <td>662215</td>\n",
       "      <td>657604</td>\n",
       "      <td>4611</td>\n",
       "      <td>0.993037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dictionary_direct_S_lf_dict_s_comp_type</th>\n",
       "      <td>3</td>\n",
       "      <td>[1, 2]</td>\n",
       "      <td>0.632112</td>\n",
       "      <td>0.632112</td>\n",
       "      <td>0.014397</td>\n",
       "      <td>658999</td>\n",
       "      <td>654232</td>\n",
       "      <td>4767</td>\n",
       "      <td>0.992766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nonUMLS_fuzzy_S_lf_s_cto</th>\n",
       "      <td>4</td>\n",
       "      <td>[1, 2]</td>\n",
       "      <td>0.634536</td>\n",
       "      <td>0.634536</td>\n",
       "      <td>0.016821</td>\n",
       "      <td>661526</td>\n",
       "      <td>657282</td>\n",
       "      <td>4244</td>\n",
       "      <td>0.993585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nonUMLS_fuzzy_S_lf_s_cto_syn</th>\n",
       "      <td>5</td>\n",
       "      <td>[1, 2]</td>\n",
       "      <td>0.637401</td>\n",
       "      <td>0.637401</td>\n",
       "      <td>0.019686</td>\n",
       "      <td>664513</td>\n",
       "      <td>657594</td>\n",
       "      <td>6919</td>\n",
       "      <td>0.989588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nonUMLS_direct_S_lf_s_cto</th>\n",
       "      <td>6</td>\n",
       "      <td>[1, 2]</td>\n",
       "      <td>0.634536</td>\n",
       "      <td>0.634536</td>\n",
       "      <td>0.016821</td>\n",
       "      <td>661526</td>\n",
       "      <td>657282</td>\n",
       "      <td>4244</td>\n",
       "      <td>0.993585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nonUMLS_direct_S_lf_s_cto_syn</th>\n",
       "      <td>7</td>\n",
       "      <td>[1, 2]</td>\n",
       "      <td>0.637401</td>\n",
       "      <td>0.637401</td>\n",
       "      <td>0.019686</td>\n",
       "      <td>664513</td>\n",
       "      <td>657594</td>\n",
       "      <td>6919</td>\n",
       "      <td>0.989588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>heuristics_direct_S_lf_lf_lf_s_heurpattern_labels</th>\n",
       "      <td>8</td>\n",
       "      <td>[1, 2]</td>\n",
       "      <td>0.630851</td>\n",
       "      <td>0.630851</td>\n",
       "      <td>0.013135</td>\n",
       "      <td>657684</td>\n",
       "      <td>656222</td>\n",
       "      <td>1462</td>\n",
       "      <td>0.997777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>heuristics_direct_S_lf_regex_stdtype</th>\n",
       "      <td>9</td>\n",
       "      <td>[1, 2]</td>\n",
       "      <td>0.630851</td>\n",
       "      <td>0.630851</td>\n",
       "      <td>0.013135</td>\n",
       "      <td>657684</td>\n",
       "      <td>655894</td>\n",
       "      <td>1790</td>\n",
       "      <td>0.997278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>heuristics_direct_S_lf_regex_stdtype_proc</th>\n",
       "      <td>10</td>\n",
       "      <td>[1, 2]</td>\n",
       "      <td>0.630851</td>\n",
       "      <td>0.630851</td>\n",
       "      <td>0.013135</td>\n",
       "      <td>657684</td>\n",
       "      <td>655664</td>\n",
       "      <td>2020</td>\n",
       "      <td>0.996929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>heuristics_direct_S_lf_regex_phase</th>\n",
       "      <td>11</td>\n",
       "      <td>[1, 2]</td>\n",
       "      <td>0.630851</td>\n",
       "      <td>0.630851</td>\n",
       "      <td>0.013135</td>\n",
       "      <td>657684</td>\n",
       "      <td>657556</td>\n",
       "      <td>128</td>\n",
       "      <td>0.999805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>heuristics_direct_S_lf_regex_stdtype_types</th>\n",
       "      <td>12</td>\n",
       "      <td>[1, 2]</td>\n",
       "      <td>0.630851</td>\n",
       "      <td>0.630851</td>\n",
       "      <td>0.013135</td>\n",
       "      <td>657684</td>\n",
       "      <td>657038</td>\n",
       "      <td>646</td>\n",
       "      <td>0.999018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>heuristics_direct_S_lf_regex_stdtype_basic</th>\n",
       "      <td>13</td>\n",
       "      <td>[1, 2]</td>\n",
       "      <td>0.630851</td>\n",
       "      <td>0.630851</td>\n",
       "      <td>0.013135</td>\n",
       "      <td>657684</td>\n",
       "      <td>655894</td>\n",
       "      <td>1790</td>\n",
       "      <td>0.997278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>heuristics_direct_S_lf_regex_placebo</th>\n",
       "      <td>14</td>\n",
       "      <td>[1, 2]</td>\n",
       "      <td>0.630851</td>\n",
       "      <td>0.630851</td>\n",
       "      <td>0.013135</td>\n",
       "      <td>657684</td>\n",
       "      <td>653439</td>\n",
       "      <td>4245</td>\n",
       "      <td>0.993546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>heuristics_direct_S_lf_lf_lf_s_heurpattern_labels_2</th>\n",
       "      <td>15</td>\n",
       "      <td>[1, 2]</td>\n",
       "      <td>0.630851</td>\n",
       "      <td>0.630851</td>\n",
       "      <td>0.013135</td>\n",
       "      <td>657684</td>\n",
       "      <td>650487</td>\n",
       "      <td>7197</td>\n",
       "      <td>0.989057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>heuristics_direct_S_lf_regex_blinding</th>\n",
       "      <td>16</td>\n",
       "      <td>[1, 2]</td>\n",
       "      <td>0.630851</td>\n",
       "      <td>0.630851</td>\n",
       "      <td>0.013135</td>\n",
       "      <td>657684</td>\n",
       "      <td>656481</td>\n",
       "      <td>1203</td>\n",
       "      <td>0.998171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>heuristics_direct_S_lf_regex_stdtype_basicplus</th>\n",
       "      <td>17</td>\n",
       "      <td>[1, 2]</td>\n",
       "      <td>0.630851</td>\n",
       "      <td>0.630851</td>\n",
       "      <td>0.013135</td>\n",
       "      <td>657684</td>\n",
       "      <td>655890</td>\n",
       "      <td>1794</td>\n",
       "      <td>0.997272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>heuristics_direct_S_lf_dict_s_abb</th>\n",
       "      <td>18</td>\n",
       "      <td>[1, 2]</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.643472</td>\n",
       "      <td>0.025756</td>\n",
       "      <td>1042535</td>\n",
       "      <td>1042469</td>\n",
       "      <td>66</td>\n",
       "      <td>0.999937</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     j Polarity  Coverage%  \\\n",
       "dictionary_fuzzy_S_lf_dict_s_type                    0   [1, 2]   0.635197   \n",
       "dictionary_fuzzy_S_lf_dict_s_comp_type               1   [1, 2]   0.632112   \n",
       "dictionary_direct_S_lf_dict_s_type                   2   [1, 2]   0.635197   \n",
       "dictionary_direct_S_lf_dict_s_comp_type              3   [1, 2]   0.632112   \n",
       "nonUMLS_fuzzy_S_lf_s_cto                             4   [1, 2]   0.634536   \n",
       "nonUMLS_fuzzy_S_lf_s_cto_syn                         5   [1, 2]   0.637401   \n",
       "nonUMLS_direct_S_lf_s_cto                            6   [1, 2]   0.634536   \n",
       "nonUMLS_direct_S_lf_s_cto_syn                        7   [1, 2]   0.637401   \n",
       "heuristics_direct_S_lf_lf_lf_s_heurpattern_labels    8   [1, 2]   0.630851   \n",
       "heuristics_direct_S_lf_regex_stdtype                 9   [1, 2]   0.630851   \n",
       "heuristics_direct_S_lf_regex_stdtype_proc           10   [1, 2]   0.630851   \n",
       "heuristics_direct_S_lf_regex_phase                  11   [1, 2]   0.630851   \n",
       "heuristics_direct_S_lf_regex_stdtype_types          12   [1, 2]   0.630851   \n",
       "heuristics_direct_S_lf_regex_stdtype_basic          13   [1, 2]   0.630851   \n",
       "heuristics_direct_S_lf_regex_placebo                14   [1, 2]   0.630851   \n",
       "heuristics_direct_S_lf_lf_lf_s_heurpattern_labe...  15   [1, 2]   0.630851   \n",
       "heuristics_direct_S_lf_regex_blinding               16   [1, 2]   0.630851   \n",
       "heuristics_direct_S_lf_regex_stdtype_basicplus      17   [1, 2]   0.630851   \n",
       "heuristics_direct_S_lf_dict_s_abb                   18   [1, 2]   1.000000   \n",
       "\n",
       "                                                    Overlaps%  Conflicts%  \\\n",
       "dictionary_fuzzy_S_lf_dict_s_type                    0.635197    0.017481   \n",
       "dictionary_fuzzy_S_lf_dict_s_comp_type               0.632112    0.014397   \n",
       "dictionary_direct_S_lf_dict_s_type                   0.635197    0.017481   \n",
       "dictionary_direct_S_lf_dict_s_comp_type              0.632112    0.014397   \n",
       "nonUMLS_fuzzy_S_lf_s_cto                             0.634536    0.016821   \n",
       "nonUMLS_fuzzy_S_lf_s_cto_syn                         0.637401    0.019686   \n",
       "nonUMLS_direct_S_lf_s_cto                            0.634536    0.016821   \n",
       "nonUMLS_direct_S_lf_s_cto_syn                        0.637401    0.019686   \n",
       "heuristics_direct_S_lf_lf_lf_s_heurpattern_labels    0.630851    0.013135   \n",
       "heuristics_direct_S_lf_regex_stdtype                 0.630851    0.013135   \n",
       "heuristics_direct_S_lf_regex_stdtype_proc            0.630851    0.013135   \n",
       "heuristics_direct_S_lf_regex_phase                   0.630851    0.013135   \n",
       "heuristics_direct_S_lf_regex_stdtype_types           0.630851    0.013135   \n",
       "heuristics_direct_S_lf_regex_stdtype_basic           0.630851    0.013135   \n",
       "heuristics_direct_S_lf_regex_placebo                 0.630851    0.013135   \n",
       "heuristics_direct_S_lf_lf_lf_s_heurpattern_labe...   0.630851    0.013135   \n",
       "heuristics_direct_S_lf_regex_blinding                0.630851    0.013135   \n",
       "heuristics_direct_S_lf_regex_stdtype_basicplus       0.630851    0.013135   \n",
       "heuristics_direct_S_lf_dict_s_abb                    0.643472    0.025756   \n",
       "\n",
       "                                                    Coverage  Correct  \\\n",
       "dictionary_fuzzy_S_lf_dict_s_type                     662215   657604   \n",
       "dictionary_fuzzy_S_lf_dict_s_comp_type                658999   654232   \n",
       "dictionary_direct_S_lf_dict_s_type                    662215   657604   \n",
       "dictionary_direct_S_lf_dict_s_comp_type               658999   654232   \n",
       "nonUMLS_fuzzy_S_lf_s_cto                              661526   657282   \n",
       "nonUMLS_fuzzy_S_lf_s_cto_syn                          664513   657594   \n",
       "nonUMLS_direct_S_lf_s_cto                             661526   657282   \n",
       "nonUMLS_direct_S_lf_s_cto_syn                         664513   657594   \n",
       "heuristics_direct_S_lf_lf_lf_s_heurpattern_labels     657684   656222   \n",
       "heuristics_direct_S_lf_regex_stdtype                  657684   655894   \n",
       "heuristics_direct_S_lf_regex_stdtype_proc             657684   655664   \n",
       "heuristics_direct_S_lf_regex_phase                    657684   657556   \n",
       "heuristics_direct_S_lf_regex_stdtype_types            657684   657038   \n",
       "heuristics_direct_S_lf_regex_stdtype_basic            657684   655894   \n",
       "heuristics_direct_S_lf_regex_placebo                  657684   653439   \n",
       "heuristics_direct_S_lf_lf_lf_s_heurpattern_labe...    657684   650487   \n",
       "heuristics_direct_S_lf_regex_blinding                 657684   656481   \n",
       "heuristics_direct_S_lf_regex_stdtype_basicplus        657684   655890   \n",
       "heuristics_direct_S_lf_dict_s_abb                    1042535  1042469   \n",
       "\n",
       "                                                    Incorrect  Emp. Acc.  \n",
       "dictionary_fuzzy_S_lf_dict_s_type                        4611   0.993037  \n",
       "dictionary_fuzzy_S_lf_dict_s_comp_type                   4767   0.992766  \n",
       "dictionary_direct_S_lf_dict_s_type                       4611   0.993037  \n",
       "dictionary_direct_S_lf_dict_s_comp_type                  4767   0.992766  \n",
       "nonUMLS_fuzzy_S_lf_s_cto                                 4244   0.993585  \n",
       "nonUMLS_fuzzy_S_lf_s_cto_syn                             6919   0.989588  \n",
       "nonUMLS_direct_S_lf_s_cto                                4244   0.993585  \n",
       "nonUMLS_direct_S_lf_s_cto_syn                            6919   0.989588  \n",
       "heuristics_direct_S_lf_lf_lf_s_heurpattern_labels        1462   0.997777  \n",
       "heuristics_direct_S_lf_regex_stdtype                     1790   0.997278  \n",
       "heuristics_direct_S_lf_regex_stdtype_proc                2020   0.996929  \n",
       "heuristics_direct_S_lf_regex_phase                        128   0.999805  \n",
       "heuristics_direct_S_lf_regex_stdtype_types                646   0.999018  \n",
       "heuristics_direct_S_lf_regex_stdtype_basic               1790   0.997278  \n",
       "heuristics_direct_S_lf_regex_placebo                     4245   0.993546  \n",
       "heuristics_direct_S_lf_lf_lf_s_heurpattern_labe...       7197   0.989057  \n",
       "heuristics_direct_S_lf_regex_blinding                    1203   0.998171  \n",
       "heuristics_direct_S_lf_regex_stdtype_basicplus           1794   0.997272  \n",
       "heuristics_direct_S_lf_dict_s_abb                          66   0.999937  "
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# With specified negatives\n",
    "\n",
    "getSummary_and_write(df=train_lf, df_col_head=train_lf_names, true_labels = np.array(train_y_mapped), file_path='/mnt/nas2/results/Results/systematicReview/distant_pico/EBM_PICO_GT/lf_s_summary_tuipio3_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f950464a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa0a6ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "818b51a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1fb6b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb4f0fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abbb99a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53249ac1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c622d1da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>j</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Coverage%</th>\n",
       "      <th>Overlaps%</th>\n",
       "      <th>Conflicts%</th>\n",
       "      <th>Coverage</th>\n",
       "      <th>Correct</th>\n",
       "      <th>Incorrect</th>\n",
       "      <th>Emp. Acc.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dictionary_fuzzy_S_lf_dict_s_type</th>\n",
       "      <td>0</td>\n",
       "      <td>[1, 2]</td>\n",
       "      <td>0.693919</td>\n",
       "      <td>0.693919</td>\n",
       "      <td>0.041719</td>\n",
       "      <td>723435</td>\n",
       "      <td>718706</td>\n",
       "      <td>4729</td>\n",
       "      <td>0.993463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dictionary_fuzzy_S_lf_dict_s_comp_type</th>\n",
       "      <td>1</td>\n",
       "      <td>[1, 2]</td>\n",
       "      <td>0.693932</td>\n",
       "      <td>0.693932</td>\n",
       "      <td>0.041732</td>\n",
       "      <td>723448</td>\n",
       "      <td>718876</td>\n",
       "      <td>4572</td>\n",
       "      <td>0.993680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dictionary_direct_S_lf_dict_s_type</th>\n",
       "      <td>2</td>\n",
       "      <td>[1, 2]</td>\n",
       "      <td>0.693919</td>\n",
       "      <td>0.693919</td>\n",
       "      <td>0.041719</td>\n",
       "      <td>723435</td>\n",
       "      <td>718706</td>\n",
       "      <td>4729</td>\n",
       "      <td>0.993463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dictionary_direct_S_lf_dict_s_comp_type</th>\n",
       "      <td>3</td>\n",
       "      <td>[1, 2]</td>\n",
       "      <td>0.693932</td>\n",
       "      <td>0.693932</td>\n",
       "      <td>0.041732</td>\n",
       "      <td>723448</td>\n",
       "      <td>718876</td>\n",
       "      <td>4572</td>\n",
       "      <td>0.993680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nonUMLS_fuzzy_S_lf_s_cto</th>\n",
       "      <td>4</td>\n",
       "      <td>[1, 2]</td>\n",
       "      <td>0.693917</td>\n",
       "      <td>0.693917</td>\n",
       "      <td>0.041718</td>\n",
       "      <td>723433</td>\n",
       "      <td>715491</td>\n",
       "      <td>7942</td>\n",
       "      <td>0.989022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nonUMLS_fuzzy_S_lf_s_cto_syn</th>\n",
       "      <td>5</td>\n",
       "      <td>[1, 2]</td>\n",
       "      <td>0.693917</td>\n",
       "      <td>0.693917</td>\n",
       "      <td>0.041718</td>\n",
       "      <td>723433</td>\n",
       "      <td>714256</td>\n",
       "      <td>9177</td>\n",
       "      <td>0.987315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nonUMLS_direct_S_lf_s_cto</th>\n",
       "      <td>6</td>\n",
       "      <td>[1, 2]</td>\n",
       "      <td>0.693917</td>\n",
       "      <td>0.693917</td>\n",
       "      <td>0.041718</td>\n",
       "      <td>723433</td>\n",
       "      <td>715491</td>\n",
       "      <td>7942</td>\n",
       "      <td>0.989022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nonUMLS_direct_S_lf_s_cto_syn</th>\n",
       "      <td>7</td>\n",
       "      <td>[1, 2]</td>\n",
       "      <td>0.693917</td>\n",
       "      <td>0.693917</td>\n",
       "      <td>0.041718</td>\n",
       "      <td>723433</td>\n",
       "      <td>714256</td>\n",
       "      <td>9177</td>\n",
       "      <td>0.987315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>heuristics_direct_S_lf_lf_lf_s_heurpattern_labels</th>\n",
       "      <td>8</td>\n",
       "      <td>[1, 2]</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.042394</td>\n",
       "      <td>1042535</td>\n",
       "      <td>1038531</td>\n",
       "      <td>4004</td>\n",
       "      <td>0.996159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>heuristics_direct_S_lf_regex_stdtype</th>\n",
       "      <td>9</td>\n",
       "      <td>[1, 2]</td>\n",
       "      <td>0.718572</td>\n",
       "      <td>0.718572</td>\n",
       "      <td>0.041980</td>\n",
       "      <td>749136</td>\n",
       "      <td>742551</td>\n",
       "      <td>6585</td>\n",
       "      <td>0.991210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>heuristics_direct_S_lf_regex_stdtype_proc</th>\n",
       "      <td>10</td>\n",
       "      <td>[1, 2]</td>\n",
       "      <td>0.718572</td>\n",
       "      <td>0.718572</td>\n",
       "      <td>0.041980</td>\n",
       "      <td>749136</td>\n",
       "      <td>744069</td>\n",
       "      <td>5067</td>\n",
       "      <td>0.993236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>heuristics_direct_S_lf_regex_phase</th>\n",
       "      <td>11</td>\n",
       "      <td>[1, 2]</td>\n",
       "      <td>0.718572</td>\n",
       "      <td>0.718572</td>\n",
       "      <td>0.041980</td>\n",
       "      <td>749136</td>\n",
       "      <td>748204</td>\n",
       "      <td>932</td>\n",
       "      <td>0.998756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>heuristics_direct_S_lf_regex_stdtype_types</th>\n",
       "      <td>12</td>\n",
       "      <td>[1, 2]</td>\n",
       "      <td>0.718572</td>\n",
       "      <td>0.718572</td>\n",
       "      <td>0.041980</td>\n",
       "      <td>749136</td>\n",
       "      <td>746713</td>\n",
       "      <td>2423</td>\n",
       "      <td>0.996766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>heuristics_direct_S_lf_regex_stdtype_basic</th>\n",
       "      <td>13</td>\n",
       "      <td>[1, 2]</td>\n",
       "      <td>0.718572</td>\n",
       "      <td>0.718572</td>\n",
       "      <td>0.041980</td>\n",
       "      <td>749136</td>\n",
       "      <td>742839</td>\n",
       "      <td>6297</td>\n",
       "      <td>0.991594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>heuristics_direct_S_lf_regex_placebo</th>\n",
       "      <td>14</td>\n",
       "      <td>[1, 2]</td>\n",
       "      <td>0.718572</td>\n",
       "      <td>0.718572</td>\n",
       "      <td>0.041980</td>\n",
       "      <td>749136</td>\n",
       "      <td>741907</td>\n",
       "      <td>7229</td>\n",
       "      <td>0.990350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>heuristics_direct_S_lf_lf_lf_s_heurpattern_labels_2</th>\n",
       "      <td>15</td>\n",
       "      <td>[1, 2]</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.042394</td>\n",
       "      <td>1042535</td>\n",
       "      <td>1020717</td>\n",
       "      <td>21818</td>\n",
       "      <td>0.979072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>heuristics_direct_S_lf_regex_blinding</th>\n",
       "      <td>16</td>\n",
       "      <td>[1, 2]</td>\n",
       "      <td>0.718572</td>\n",
       "      <td>0.718572</td>\n",
       "      <td>0.041980</td>\n",
       "      <td>749136</td>\n",
       "      <td>747509</td>\n",
       "      <td>1627</td>\n",
       "      <td>0.997828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>heuristics_direct_S_lf_regex_stdtype_basicplus</th>\n",
       "      <td>17</td>\n",
       "      <td>[1, 2]</td>\n",
       "      <td>0.718572</td>\n",
       "      <td>0.718572</td>\n",
       "      <td>0.041980</td>\n",
       "      <td>749136</td>\n",
       "      <td>742835</td>\n",
       "      <td>6301</td>\n",
       "      <td>0.991589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>heuristics_direct_S_lf_dict_s_abb</th>\n",
       "      <td>18</td>\n",
       "      <td>[1, 2]</td>\n",
       "      <td>0.693917</td>\n",
       "      <td>0.693917</td>\n",
       "      <td>0.041718</td>\n",
       "      <td>723433</td>\n",
       "      <td>723367</td>\n",
       "      <td>66</td>\n",
       "      <td>0.999909</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     j Polarity  Coverage%  \\\n",
       "dictionary_fuzzy_S_lf_dict_s_type                    0   [1, 2]   0.693919   \n",
       "dictionary_fuzzy_S_lf_dict_s_comp_type               1   [1, 2]   0.693932   \n",
       "dictionary_direct_S_lf_dict_s_type                   2   [1, 2]   0.693919   \n",
       "dictionary_direct_S_lf_dict_s_comp_type              3   [1, 2]   0.693932   \n",
       "nonUMLS_fuzzy_S_lf_s_cto                             4   [1, 2]   0.693917   \n",
       "nonUMLS_fuzzy_S_lf_s_cto_syn                         5   [1, 2]   0.693917   \n",
       "nonUMLS_direct_S_lf_s_cto                            6   [1, 2]   0.693917   \n",
       "nonUMLS_direct_S_lf_s_cto_syn                        7   [1, 2]   0.693917   \n",
       "heuristics_direct_S_lf_lf_lf_s_heurpattern_labels    8   [1, 2]   1.000000   \n",
       "heuristics_direct_S_lf_regex_stdtype                 9   [1, 2]   0.718572   \n",
       "heuristics_direct_S_lf_regex_stdtype_proc           10   [1, 2]   0.718572   \n",
       "heuristics_direct_S_lf_regex_phase                  11   [1, 2]   0.718572   \n",
       "heuristics_direct_S_lf_regex_stdtype_types          12   [1, 2]   0.718572   \n",
       "heuristics_direct_S_lf_regex_stdtype_basic          13   [1, 2]   0.718572   \n",
       "heuristics_direct_S_lf_regex_placebo                14   [1, 2]   0.718572   \n",
       "heuristics_direct_S_lf_lf_lf_s_heurpattern_labe...  15   [1, 2]   1.000000   \n",
       "heuristics_direct_S_lf_regex_blinding               16   [1, 2]   0.718572   \n",
       "heuristics_direct_S_lf_regex_stdtype_basicplus      17   [1, 2]   0.718572   \n",
       "heuristics_direct_S_lf_dict_s_abb                   18   [1, 2]   0.693917   \n",
       "\n",
       "                                                    Overlaps%  Conflicts%  \\\n",
       "dictionary_fuzzy_S_lf_dict_s_type                    0.693919    0.041719   \n",
       "dictionary_fuzzy_S_lf_dict_s_comp_type               0.693932    0.041732   \n",
       "dictionary_direct_S_lf_dict_s_type                   0.693919    0.041719   \n",
       "dictionary_direct_S_lf_dict_s_comp_type              0.693932    0.041732   \n",
       "nonUMLS_fuzzy_S_lf_s_cto                             0.693917    0.041718   \n",
       "nonUMLS_fuzzy_S_lf_s_cto_syn                         0.693917    0.041718   \n",
       "nonUMLS_direct_S_lf_s_cto                            0.693917    0.041718   \n",
       "nonUMLS_direct_S_lf_s_cto_syn                        0.693917    0.041718   \n",
       "heuristics_direct_S_lf_lf_lf_s_heurpattern_labels    1.000000    0.042394   \n",
       "heuristics_direct_S_lf_regex_stdtype                 0.718572    0.041980   \n",
       "heuristics_direct_S_lf_regex_stdtype_proc            0.718572    0.041980   \n",
       "heuristics_direct_S_lf_regex_phase                   0.718572    0.041980   \n",
       "heuristics_direct_S_lf_regex_stdtype_types           0.718572    0.041980   \n",
       "heuristics_direct_S_lf_regex_stdtype_basic           0.718572    0.041980   \n",
       "heuristics_direct_S_lf_regex_placebo                 0.718572    0.041980   \n",
       "heuristics_direct_S_lf_lf_lf_s_heurpattern_labe...   1.000000    0.042394   \n",
       "heuristics_direct_S_lf_regex_blinding                0.718572    0.041980   \n",
       "heuristics_direct_S_lf_regex_stdtype_basicplus       0.718572    0.041980   \n",
       "heuristics_direct_S_lf_dict_s_abb                    0.693917    0.041718   \n",
       "\n",
       "                                                    Coverage  Correct  \\\n",
       "dictionary_fuzzy_S_lf_dict_s_type                     723435   718706   \n",
       "dictionary_fuzzy_S_lf_dict_s_comp_type                723448   718876   \n",
       "dictionary_direct_S_lf_dict_s_type                    723435   718706   \n",
       "dictionary_direct_S_lf_dict_s_comp_type               723448   718876   \n",
       "nonUMLS_fuzzy_S_lf_s_cto                              723433   715491   \n",
       "nonUMLS_fuzzy_S_lf_s_cto_syn                          723433   714256   \n",
       "nonUMLS_direct_S_lf_s_cto                             723433   715491   \n",
       "nonUMLS_direct_S_lf_s_cto_syn                         723433   714256   \n",
       "heuristics_direct_S_lf_lf_lf_s_heurpattern_labels    1042535  1038531   \n",
       "heuristics_direct_S_lf_regex_stdtype                  749136   742551   \n",
       "heuristics_direct_S_lf_regex_stdtype_proc             749136   744069   \n",
       "heuristics_direct_S_lf_regex_phase                    749136   748204   \n",
       "heuristics_direct_S_lf_regex_stdtype_types            749136   746713   \n",
       "heuristics_direct_S_lf_regex_stdtype_basic            749136   742839   \n",
       "heuristics_direct_S_lf_regex_placebo                  749136   741907   \n",
       "heuristics_direct_S_lf_lf_lf_s_heurpattern_labe...   1042535  1020717   \n",
       "heuristics_direct_S_lf_regex_blinding                 749136   747509   \n",
       "heuristics_direct_S_lf_regex_stdtype_basicplus        749136   742835   \n",
       "heuristics_direct_S_lf_dict_s_abb                     723433   723367   \n",
       "\n",
       "                                                    Incorrect  Emp. Acc.  \n",
       "dictionary_fuzzy_S_lf_dict_s_type                        4729   0.993463  \n",
       "dictionary_fuzzy_S_lf_dict_s_comp_type                   4572   0.993680  \n",
       "dictionary_direct_S_lf_dict_s_type                       4729   0.993463  \n",
       "dictionary_direct_S_lf_dict_s_comp_type                  4572   0.993680  \n",
       "nonUMLS_fuzzy_S_lf_s_cto                                 7942   0.989022  \n",
       "nonUMLS_fuzzy_S_lf_s_cto_syn                             9177   0.987315  \n",
       "nonUMLS_direct_S_lf_s_cto                                7942   0.989022  \n",
       "nonUMLS_direct_S_lf_s_cto_syn                            9177   0.987315  \n",
       "heuristics_direct_S_lf_lf_lf_s_heurpattern_labels        4004   0.996159  \n",
       "heuristics_direct_S_lf_regex_stdtype                     6585   0.991210  \n",
       "heuristics_direct_S_lf_regex_stdtype_proc                5067   0.993236  \n",
       "heuristics_direct_S_lf_regex_phase                        932   0.998756  \n",
       "heuristics_direct_S_lf_regex_stdtype_types               2423   0.996766  \n",
       "heuristics_direct_S_lf_regex_stdtype_basic               6297   0.991594  \n",
       "heuristics_direct_S_lf_regex_placebo                     7229   0.990350  \n",
       "heuristics_direct_S_lf_lf_lf_s_heurpattern_labe...      21818   0.979072  \n",
       "heuristics_direct_S_lf_regex_blinding                    1627   0.997828  \n",
       "heuristics_direct_S_lf_regex_stdtype_basicplus           6301   0.991589  \n",
       "heuristics_direct_S_lf_dict_s_abb                          66   0.999909  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Without specified negatives\n",
    "\n",
    "getSummary_and_write(df=train_lf, df_col_head=train_lf_names, true_labels = np.array(train_y_mapped), file_path='/mnt/nas2/results/Results/systematicReview/distant_pico/EBM_PICO_GT/lf_s_summary_tuipio3_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a1b16a40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq=[1.1412, 4.3453, 5.8709, 0.1314]\n",
    "seq.index(min(seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35f33a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

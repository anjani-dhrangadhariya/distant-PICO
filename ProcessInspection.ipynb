{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Source statistics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-15 19:00:01.891040: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    }
   ],
   "source": [
    "from elasticsearch import Elasticsearch, helpers\n",
    "from elasticsearch_dsl import Search,  Q\n",
    "from datetime import datetime\n",
    "import sys, json, os\n",
    "import difflib \n",
    "import uuid\n",
    "import spacy\n",
    "import ast\n",
    "from statistics import mean, median\n",
    "from collections import Counter\n",
    "import itertools\n",
    "import traceback\n",
    "import json\n",
    "import gc\n",
    "from typing import List\n",
    "from spacy.tokens import Doc\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readRawCandidates( list_NCT, label_type=None ):\n",
    "\n",
    "    nct_ids = []\n",
    "    tokens = []\n",
    "    labels = []\n",
    "    pos = []\n",
    "\n",
    "    with open(list_NCT, 'r', encoding='latin1') as NCT_ids_file:\n",
    "\n",
    "        for i, eachLine in enumerate(NCT_ids_file):\n",
    "            annot = json.loads(eachLine)\n",
    "            id_ = annot['id']\n",
    "\n",
    "            for target_key, target in annot.items():\n",
    "\n",
    "                if 'id' not in target_key:\n",
    "                    for sentence_key, sentence in target.items():\n",
    "\n",
    "                        if set(sentence['tokens'])!={0}:\n",
    "                            tokens.append( sentence['tokens'] )\n",
    "                            labels.append( sentence['annotation'] )\n",
    "                            nct_ids.append( id_ )\n",
    "\n",
    "                            # Generate dummy POS items\n",
    "                            pos_i = [0] * len( sentence['tokens'] )\n",
    "                            pos.append( pos_i )\n",
    "                        else:\n",
    "                            print('All the labels are nil')\n",
    "\n",
    "    corpus_df = pd.DataFrame(\n",
    "        {'ids': nct_ids,\n",
    "        'tokens': tokens,\n",
    "        'labels': labels,\n",
    "        'pos': pos\n",
    "        })\n",
    "\n",
    "    df = corpus_df.sample(frac=1).reset_index(drop=True) # Shuffles the dataframe after creation\n",
    "    \n",
    "    # can delete this one (corpusDf)\n",
    "    del corpus_df\n",
    "    gc.collect() # mark if for garbage collection\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect outcomes from the groundtruth "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "groundTruth_filepath = '/mnt/nas2/data/systematicReview/clinical_trials_gov/Weak_PICO/groundtruth/ebm_nlp/o/sentences.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.vocab import Vocab\n",
    "\n",
    "import pandas as pd\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tokens_vocab = []\n",
    "\n",
    "with open(groundTruth_filepath, 'r') as of:\n",
    "\n",
    "    for eachLabelFile in of:\n",
    "        data = json.loads(eachLabelFile)\n",
    "        \n",
    "        for k,v in data.items():\n",
    "            tokens = v[0]\n",
    "            for token in tokens:\n",
    "                all_tokens_vocab.append( token )\n",
    "                \n",
    "                \n",
    "vocab = Vocab(strings=all_tokens_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(groundTruth_filepath, 'r') as of:\n",
    "    text_all = []\n",
    "    text_pos_all = []\n",
    "    text_posfine_all = []\n",
    "    tokens_all = []\n",
    "    labels_all = []\n",
    "    for eachLabelFile in of:\n",
    "        data = json.loads(eachLabelFile)\n",
    "        \n",
    "        for k,v in data.items():\n",
    "            tokens = v[0]\n",
    "            labels = v[1]\n",
    "\n",
    "            posss = [ nlp(token)[0].pos_  for token in tokens]\n",
    "            pos_fine =[ nlp(token)[0].tag_  for token in tokens]    \n",
    "            \n",
    "            text_all.append( ' '.join( tokens ) )\n",
    "            text_pos_all.append( posss )\n",
    "            text_posfine_all.append( pos_fine )\n",
    "            tokens_all.append(tokens)\n",
    "            labels_all.append(labels)\n",
    "            \n",
    "            assert len(tokens) == len(labels) == len( posss ) == len( pos_fine )\n",
    "\n",
    "    df_x = pd.DataFrame(\n",
    "        {'text': text_all,\n",
    "         'tokens': tokens_all,\n",
    "         'labels': labels_all,\n",
    "         'pos': text_pos_all,\n",
    "         'pos_fine': text_posfine_all\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>labels</th>\n",
       "      <th>pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Anxiety disorders in typically developing yout...</td>\n",
       "      <td>[Anxiety, disorders, in, typically, developing...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[NOUN, NOUN, ADP, ADV, VERB, NOUN, PUNCT, NOUN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Parent satisfaction in a multi-site acute tria...</td>\n",
       "      <td>[Parent, satisfaction, in, a, multi-site, acut...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[PROPN, NOUN, ADP, DET, ADJ, ADJ, NOUN, ADP, N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The effects of chewing versus caffeine on aler...</td>\n",
       "      <td>[The, effects, of, chewing, versus, caffeine, ...</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[DET, NOUN, ADP, VERB, ADP, NOUN, ADP, VERB, P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Relaxation and imagery and cognitive-behaviora...</td>\n",
       "      <td>[Relaxation, and, imagery, and, cognitive-beha...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[NOUN, CCONJ, NOUN, CCONJ, ADJ, NOUN, VERB, NO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Oral ribavirin treatment of influenza A and B ...</td>\n",
       "      <td>[Oral, ribavirin, treatment, of, influenza, A,...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[ADJ, NOUN, NOUN, ADP, NOUN, DET, CCONJ, NOUN,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  Anxiety disorders in typically developing yout...   \n",
       "1  Parent satisfaction in a multi-site acute tria...   \n",
       "2  The effects of chewing versus caffeine on aler...   \n",
       "3  Relaxation and imagery and cognitive-behaviora...   \n",
       "4  Oral ribavirin treatment of influenza A and B ...   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [Anxiety, disorders, in, typically, developing...   \n",
       "1  [Parent, satisfaction, in, a, multi-site, acut...   \n",
       "2  [The, effects, of, chewing, versus, caffeine, ...   \n",
       "3  [Relaxation, and, imagery, and, cognitive-beha...   \n",
       "4  [Oral, ribavirin, treatment, of, influenza, A,...   \n",
       "\n",
       "                                              labels  \\\n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2  [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "3  [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                                                 pos  \n",
       "0  [NOUN, NOUN, ADP, ADV, VERB, NOUN, PUNCT, NOUN...  \n",
       "1  [PROPN, NOUN, ADP, DET, ADJ, ADJ, NOUN, ADP, N...  \n",
       "2  [DET, NOUN, ADP, VERB, ADP, NOUN, ADP, VERB, P...  \n",
       "3  [NOUN, CCONJ, NOUN, CCONJ, ADJ, NOUN, VERB, NO...  \n",
       "4  [ADJ, NOUN, NOUN, ADP, NOUN, DET, CCONJ, NOUN,...  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "writeFile = '/mnt/nas2/data/systematicReview/clinical_trials_gov/Weak_PICO/groundtruth/inspection/outcomes/outcomes_pos.csv'\n",
    "\n",
    "df_x.to_csv(writeFile, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_outcome_pos = []\n",
    "all_outcome_tokens = []\n",
    "\n",
    "for eachTokenlist, eachLabList, eachPosList in zip(df_x['tokens'], df_x['labels'], df_x['pos']):\n",
    "    for t, l, p in zip(eachTokenlist, eachLabList, eachPosList):\n",
    "        if l == '1':\n",
    "            all_outcome_pos.append( p )\n",
    "            all_outcome_tokens.append( t )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################################################################\n",
      "[('NOUN', 68637), ('PUNCT', 19628), ('ADJ', 19102), ('VERB', 11658), ('ADP', 11375), ('CCONJ', 8233), ('PROPN', 6001), ('DET', 3200), ('ADV', 2837), ('NUM', 2045), ('INTJ', 1059), ('X', 819), ('AUX', 633), ('PRON', 212), ('SCONJ', 175), ('PART', 99), ('SYM', 9)]\n",
      "####################################################################\n",
      "[('and', 7165), (',', 6768), ('of', 5875), ('.', 4976), (')', 3457), ('(', 3228), ('the', 2152), ('in', 1680), ('rate', 1143), ('or', 940), ('blood', 916), ('to', 900), ('pain', 860), ('levels', 768), ('survival', 767), ('time', 688), ('pressure', 653), ('efficacy', 602), ('response', 586), ('effects', 573), ('for', 530), ('mean', 501), ('rates', 491), ('scores', 479), ('symptoms', 473), ('plasma', 465), ('with', 452), ('total', 427), ('function', 425), ('adverse', 420), ('serum', 403), ('a', 393), ('safety', 392), ('events', 389), ('score', 383), ('activity', 375), ('on', 366), ('overall', 352), ('quality', 338), ('number', 334), (';', 318), ('clinical', 308), ('effect', 306), ('risk', 301), ('concentrations', 300), ('incidence', 285), ('level', 285), ('duration', 284), ('weight', 275), ('heart', 268)]\n"
     ]
    }
   ],
   "source": [
    "print('####################################################################')\n",
    "pos_counter = Counter(all_outcome_pos)\n",
    "print( pos_counter.most_common(50) )\n",
    "print('####################################################################')\n",
    "term_counter = Counter(all_outcome_tokens)\n",
    "print( term_counter.most_common(50) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=.99\n",
      "€73,359\n",
      "€80,000\n",
      "=0.61\n",
      "$\n",
      "=8\n",
      "/\n",
      "+dP/dt\n",
      "=220\n"
     ]
    }
   ],
   "source": [
    "for t, p in zip(all_outcome_tokens, all_outcome_pos):\n",
    "    if p == 'SYM':\n",
    "        print(t) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the groundtruth outcomes from local file\n",
    "import pandas as pd\n",
    "df_x = pd.read_csv('/mnt/nas2/data/systematicReview/clinical_trials_gov/Weak_PICO/groundtruth/inspection/outcomes/outcomes_pos.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>labels</th>\n",
       "      <th>pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Anxiety disorders in typically developing yout...</td>\n",
       "      <td>['Anxiety', 'disorders', 'in', 'typically', 'd...</td>\n",
       "      <td>['0', '0', '0', '0', '0', '0', '0', '0', '0', ...</td>\n",
       "      <td>['NOUN', 'NOUN', 'ADP', 'ADV', 'VERB', 'NOUN',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Parent satisfaction in a multi-site acute tria...</td>\n",
       "      <td>['Parent', 'satisfaction', 'in', 'a', 'multi-s...</td>\n",
       "      <td>['0', '0', '0', '0', '0', '0', '0', '0', '0', ...</td>\n",
       "      <td>['PROPN', 'NOUN', 'ADP', 'DET', 'ADJ', 'ADJ', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>The effects of chewing versus caffeine on aler...</td>\n",
       "      <td>['The', 'effects', 'of', 'chewing', 'versus', ...</td>\n",
       "      <td>['0', '1', '0', '0', '0', '0', '0', '0', '0', ...</td>\n",
       "      <td>['DET', 'NOUN', 'ADP', 'VERB', 'ADP', 'NOUN', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Relaxation and imagery and cognitive-behaviora...</td>\n",
       "      <td>['Relaxation', 'and', 'imagery', 'and', 'cogni...</td>\n",
       "      <td>['0', '0', '0', '0', '0', '0', '0', '1', '0', ...</td>\n",
       "      <td>['NOUN', 'CCONJ', 'NOUN', 'CCONJ', 'ADJ', 'NOU...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Oral ribavirin treatment of influenza A and B ...</td>\n",
       "      <td>['Oral', 'ribavirin', 'treatment', 'of', 'infl...</td>\n",
       "      <td>['0', '0', '0', '0', '0', '0', '0', '0', '0', ...</td>\n",
       "      <td>['ADJ', 'NOUN', 'NOUN', 'ADP', 'NOUN', 'DET', ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               text  \\\n",
       "0           0  Anxiety disorders in typically developing yout...   \n",
       "1           1  Parent satisfaction in a multi-site acute tria...   \n",
       "2           2  The effects of chewing versus caffeine on aler...   \n",
       "3           3  Relaxation and imagery and cognitive-behaviora...   \n",
       "4           4  Oral ribavirin treatment of influenza A and B ...   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  ['Anxiety', 'disorders', 'in', 'typically', 'd...   \n",
       "1  ['Parent', 'satisfaction', 'in', 'a', 'multi-s...   \n",
       "2  ['The', 'effects', 'of', 'chewing', 'versus', ...   \n",
       "3  ['Relaxation', 'and', 'imagery', 'and', 'cogni...   \n",
       "4  ['Oral', 'ribavirin', 'treatment', 'of', 'infl...   \n",
       "\n",
       "                                              labels  \\\n",
       "0  ['0', '0', '0', '0', '0', '0', '0', '0', '0', ...   \n",
       "1  ['0', '0', '0', '0', '0', '0', '0', '0', '0', ...   \n",
       "2  ['0', '1', '0', '0', '0', '0', '0', '0', '0', ...   \n",
       "3  ['0', '0', '0', '0', '0', '0', '0', '1', '0', ...   \n",
       "4  ['0', '0', '0', '0', '0', '0', '0', '0', '0', ...   \n",
       "\n",
       "                                                 pos  \n",
       "0  ['NOUN', 'NOUN', 'ADP', 'ADV', 'VERB', 'NOUN',...  \n",
       "1  ['PROPN', 'NOUN', 'ADP', 'DET', 'ADJ', 'ADJ', ...  \n",
       "2  ['DET', 'NOUN', 'ADP', 'VERB', 'ADP', 'NOUN', ...  \n",
       "3  ['NOUN', 'CCONJ', 'NOUN', 'CCONJ', 'ADJ', 'NOU...  \n",
       "4  ['ADJ', 'NOUN', 'NOUN', 'ADP', 'NOUN', 'DET', ...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_x.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect outcome targets from CTO "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "forbidden_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/mnt/nas2/data/systematicReview/clinical_trials_gov/Weak_PICO/groundtruth/inspection/outcomes/outcome_targets.txt','r') as rf:\n",
    "    \n",
    "    text_all = []\n",
    "    tokens_all = []\n",
    "    text_pos_all = []\n",
    "    text_posfine_all = []\n",
    "    tokens_sw_removed = []\n",
    "    \n",
    "    for i, eachLine in enumerate(rf):\n",
    "                \n",
    "        tokens = nlp(eachLine)\n",
    "        \n",
    "        tok_i = [token.text for token in tokens]\n",
    "        pos_i = [token.pos_ for token in tokens]\n",
    "        pos_fine_i = [token.tag_ for token in tokens]\n",
    "        tokens_sw_removed_i = [token.text for token in tokens if token.text.lower() not in forbidden_words]\n",
    "\n",
    "\n",
    "        text_all.append( eachLine )\n",
    "        tokens_all.append( tok_i )\n",
    "        text_pos_all.append( pos_i )\n",
    "        text_posfine_all.append( pos_fine_i )\n",
    "        tokens_sw_removed.append( tokens_sw_removed_i )\n",
    "            \n",
    "        #if i == 10:\n",
    "        #    break\n",
    "            \n",
    "            \n",
    "    target_outcomes_df = pd.DataFrame(\n",
    "        {'text': text_all,\n",
    "         'tokens': tokens_all,\n",
    "         'pos': text_pos_all,\n",
    "         'pos_fine': text_posfine_all,\n",
    "         'no_sw_tokens': tokens_sw_removed\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>pos</th>\n",
       "      <th>pos_fine</th>\n",
       "      <th>no_sw_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>On study day one, recombinant-hCG (r-hCG) will...</td>\n",
       "      <td>[On, study, day, one, ,, recombinant, -, hCG, ...</td>\n",
       "      <td>[ADP, NOUN, NOUN, NUM, PUNCT, ADJ, PUNCT, PROP...</td>\n",
       "      <td>[IN, NN, NN, CD, ,, JJ, HYPH, NNP, -LRB-, NN, ...</td>\n",
       "      <td>[study, day, one, ,, recombinant, -, hCG, (, r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The percentage of participants with serious ad...</td>\n",
       "      <td>[The, percentage, of, participants, with, seri...</td>\n",
       "      <td>[DET, NOUN, ADP, NOUN, ADP, ADJ, ADJ, NOUN, CC...</td>\n",
       "      <td>[DT, NN, IN, NNS, IN, JJ, JJ, NNS, CC, JJ, JJ,...</td>\n",
       "      <td>[percentage, participants, serious, adverse, e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The weekly itch severity score is the sum of t...</td>\n",
       "      <td>[The, weekly, itch, severity, score, is, the, ...</td>\n",
       "      <td>[DET, ADJ, NOUN, NOUN, NOUN, AUX, DET, NOUN, A...</td>\n",
       "      <td>[DT, JJ, NN, NN, NN, VBZ, DT, NN, IN, DT, JJ, ...</td>\n",
       "      <td>[weekly, itch, severity, score, sum, daily, it...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The UAS7 is the sum of the daily urticarial ac...</td>\n",
       "      <td>[The, UAS7, is, the, sum, of, the, daily, urti...</td>\n",
       "      <td>[DET, PROPN, AUX, DET, NOUN, ADP, DET, ADJ, AD...</td>\n",
       "      <td>[DT, NNP, VBZ, DT, NN, IN, DT, JJ, JJ, NN, NNS...</td>\n",
       "      <td>[UAS7, sum, daily, urticarial, activity, score...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The weekly hives score is the sum of the daily...</td>\n",
       "      <td>[The, weekly, hives, score, is, the, sum, of, ...</td>\n",
       "      <td>[DET, ADJ, NOUN, NOUN, AUX, DET, NOUN, ADP, DE...</td>\n",
       "      <td>[DT, JJ, NNS, NN, VBZ, DT, NN, IN, DT, JJ, NNS...</td>\n",
       "      <td>[weekly, hives, score, sum, daily, hives, scor...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  On study day one, recombinant-hCG (r-hCG) will...   \n",
       "1  The percentage of participants with serious ad...   \n",
       "2  The weekly itch severity score is the sum of t...   \n",
       "3  The UAS7 is the sum of the daily urticarial ac...   \n",
       "4  The weekly hives score is the sum of the daily...   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [On, study, day, one, ,, recombinant, -, hCG, ...   \n",
       "1  [The, percentage, of, participants, with, seri...   \n",
       "2  [The, weekly, itch, severity, score, is, the, ...   \n",
       "3  [The, UAS7, is, the, sum, of, the, daily, urti...   \n",
       "4  [The, weekly, hives, score, is, the, sum, of, ...   \n",
       "\n",
       "                                                 pos  \\\n",
       "0  [ADP, NOUN, NOUN, NUM, PUNCT, ADJ, PUNCT, PROP...   \n",
       "1  [DET, NOUN, ADP, NOUN, ADP, ADJ, ADJ, NOUN, CC...   \n",
       "2  [DET, ADJ, NOUN, NOUN, NOUN, AUX, DET, NOUN, A...   \n",
       "3  [DET, PROPN, AUX, DET, NOUN, ADP, DET, ADJ, AD...   \n",
       "4  [DET, ADJ, NOUN, NOUN, AUX, DET, NOUN, ADP, DE...   \n",
       "\n",
       "                                            pos_fine  \\\n",
       "0  [IN, NN, NN, CD, ,, JJ, HYPH, NNP, -LRB-, NN, ...   \n",
       "1  [DT, NN, IN, NNS, IN, JJ, JJ, NNS, CC, JJ, JJ,...   \n",
       "2  [DT, JJ, NN, NN, NN, VBZ, DT, NN, IN, DT, JJ, ...   \n",
       "3  [DT, NNP, VBZ, DT, NN, IN, DT, JJ, JJ, NN, NNS...   \n",
       "4  [DT, JJ, NNS, NN, VBZ, DT, NN, IN, DT, JJ, NNS...   \n",
       "\n",
       "                                        no_sw_tokens  \n",
       "0  [study, day, one, ,, recombinant, -, hCG, (, r...  \n",
       "1  [percentage, participants, serious, adverse, e...  \n",
       "2  [weekly, itch, severity, score, sum, daily, it...  \n",
       "3  [UAS7, sum, daily, urticarial, activity, score...  \n",
       "4  [weekly, hives, score, sum, daily, hives, scor...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_outcomes_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "writeFile = '/mnt/nas2/data/systematicReview/clinical_trials_gov/Weak_PICO/groundtruth/inspection/outcomes/outcome_targets_pos.csv'\n",
    "\n",
    "target_outcomes_df.to_csv(writeFile, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_outcomes_df = pd.read_csv(writeFile, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>pos</th>\n",
       "      <th>pos_fine</th>\n",
       "      <th>no_sw_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>On study day one, recombinant-hCG (r-hCG) will...</td>\n",
       "      <td>['On', 'study', 'day', 'one', ',', 'recombinan...</td>\n",
       "      <td>['ADP', 'NOUN', 'NOUN', 'NUM', 'PUNCT', 'ADJ',...</td>\n",
       "      <td>['IN', 'NN', 'NN', 'CD', ',', 'JJ', 'HYPH', 'N...</td>\n",
       "      <td>['study', 'day', 'one', ',', 'recombinant', '-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>The percentage of participants with serious ad...</td>\n",
       "      <td>['The', 'percentage', 'of', 'participants', 'w...</td>\n",
       "      <td>['DET', 'NOUN', 'ADP', 'NOUN', 'ADP', 'ADJ', '...</td>\n",
       "      <td>['DT', 'NN', 'IN', 'NNS', 'IN', 'JJ', 'JJ', 'N...</td>\n",
       "      <td>['percentage', 'participants', 'serious', 'adv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>The weekly itch severity score is the sum of t...</td>\n",
       "      <td>['The', 'weekly', 'itch', 'severity', 'score',...</td>\n",
       "      <td>['DET', 'ADJ', 'NOUN', 'NOUN', 'NOUN', 'AUX', ...</td>\n",
       "      <td>['DT', 'JJ', 'NN', 'NN', 'NN', 'VBZ', 'DT', 'N...</td>\n",
       "      <td>['weekly', 'itch', 'severity', 'score', 'sum',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>The UAS7 is the sum of the daily urticarial ac...</td>\n",
       "      <td>['The', 'UAS7', 'is', 'the', 'sum', 'of', 'the...</td>\n",
       "      <td>['DET', 'PROPN', 'AUX', 'DET', 'NOUN', 'ADP', ...</td>\n",
       "      <td>['DT', 'NNP', 'VBZ', 'DT', 'NN', 'IN', 'DT', '...</td>\n",
       "      <td>['UAS7', 'sum', 'daily', 'urticarial', 'activi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>The weekly hives score is the sum of the daily...</td>\n",
       "      <td>['The', 'weekly', 'hives', 'score', 'is', 'the...</td>\n",
       "      <td>['DET', 'ADJ', 'NOUN', 'NOUN', 'AUX', 'DET', '...</td>\n",
       "      <td>['DT', 'JJ', 'NNS', 'NN', 'VBZ', 'DT', 'NN', '...</td>\n",
       "      <td>['weekly', 'hives', 'score', 'sum', 'daily', '...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               text  \\\n",
       "0           0  On study day one, recombinant-hCG (r-hCG) will...   \n",
       "1           1  The percentage of participants with serious ad...   \n",
       "2           2  The weekly itch severity score is the sum of t...   \n",
       "3           3  The UAS7 is the sum of the daily urticarial ac...   \n",
       "4           4  The weekly hives score is the sum of the daily...   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  ['On', 'study', 'day', 'one', ',', 'recombinan...   \n",
       "1  ['The', 'percentage', 'of', 'participants', 'w...   \n",
       "2  ['The', 'weekly', 'itch', 'severity', 'score',...   \n",
       "3  ['The', 'UAS7', 'is', 'the', 'sum', 'of', 'the...   \n",
       "4  ['The', 'weekly', 'hives', 'score', 'is', 'the...   \n",
       "\n",
       "                                                 pos  \\\n",
       "0  ['ADP', 'NOUN', 'NOUN', 'NUM', 'PUNCT', 'ADJ',...   \n",
       "1  ['DET', 'NOUN', 'ADP', 'NOUN', 'ADP', 'ADJ', '...   \n",
       "2  ['DET', 'ADJ', 'NOUN', 'NOUN', 'NOUN', 'AUX', ...   \n",
       "3  ['DET', 'PROPN', 'AUX', 'DET', 'NOUN', 'ADP', ...   \n",
       "4  ['DET', 'ADJ', 'NOUN', 'NOUN', 'AUX', 'DET', '...   \n",
       "\n",
       "                                            pos_fine  \\\n",
       "0  ['IN', 'NN', 'NN', 'CD', ',', 'JJ', 'HYPH', 'N...   \n",
       "1  ['DT', 'NN', 'IN', 'NNS', 'IN', 'JJ', 'JJ', 'N...   \n",
       "2  ['DT', 'JJ', 'NN', 'NN', 'NN', 'VBZ', 'DT', 'N...   \n",
       "3  ['DT', 'NNP', 'VBZ', 'DT', 'NN', 'IN', 'DT', '...   \n",
       "4  ['DT', 'JJ', 'NNS', 'NN', 'VBZ', 'DT', 'NN', '...   \n",
       "\n",
       "                                        no_sw_tokens  \n",
       "0  ['study', 'day', 'one', ',', 'recombinant', '-...  \n",
       "1  ['percentage', 'participants', 'serious', 'adv...  \n",
       "2  ['weekly', 'itch', 'severity', 'score', 'sum',...  \n",
       "3  ['UAS7', 'sum', 'daily', 'urticarial', 'activi...  \n",
       "4  ['weekly', 'hives', 'score', 'sum', 'daily', '...  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_outcomes_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Majority and minority labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data = '/mnt/nas2/data/systematicReview/clinical_trials_gov/Weak_PICO/PICOS_data_preprocessed/merged_1_0.txt'\n",
    "\n",
    "df = readRawCandidates( merged_data, label_type=None )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_collection = []\n",
    "\n",
    "for eachTokenList in df['labels']:\n",
    "    token_collection.extend( eachTokenList )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_counted = Counter(token_collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "percent_minor = ( (labels_counted[1] + labels_counted[2] + labels_counted[3] + labels_counted[4]) / labels_counted[0] * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The percentage of minority labels:  10.577408759933324\n"
     ]
    }
   ],
   "source": [
    "print('The percentage of minority labels: ', percent_minor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "464037\n",
      "464037\n",
      "Longest outcome term:  68\n",
      "Longest outcome term:  1\n",
      "Mean outcome term:  10.124744363057257\n",
      "Median outcome term:  8\n",
      "####################################################################\n",
      "[('NOUN', 1589426), ('PROPN', 744440), ('ADP', 718375), ('PUNCT', 510399), ('ADJ', 389293), ('VERB', 212547), ('DET', 168427), ('NUM', 144452), ('CCONJ', 118636), ('PART', 49679), ('ADV', 19831), ('PRON', 11321), ('AUX', 6121), ('X', 5819), ('SCONJ', 5440), ('SYM', 3718), ('INTJ', 332)]\n",
      "####################################################################\n",
      "[('NN', 1332428), ('IN', 722014), ('NNP', 686128), ('JJ', 380177), ('NNS', 257011), ('-RRB-', 176226), ('-LRB-', 169869), ('DT', 164240), ('CD', 144452), ('CC', 118636), ('VBN', 89007), (',', 68176), ('NNPS', 58312), ('VBG', 47613), ('.', 44736), ('TO', 42760), ('VB', 38053), (':', 31667), ('RB', 17871), ('HYPH', 15538), ('VBD', 15028), ('VBP', 13895), ('VBZ', 8951), ('WP', 8099), ('MD', 6121), ('POS', 5858), ('JJR', 5088), ('JJS', 4028), ('WDT', 3841), ('SYM', 3605), ('FW', 3495), ('WRB', 2428), ('``', 2150), ('PRP$', 2077), (\"''\", 1809), ('RP', 1801), ('XX', 1477), ('PRP', 971), ('LS', 813), ('RBR', 442), ('UH', 332), ('WP$', 250), ('NFP', 228), ('EX', 161), ('RBS', 151), ('$', 113), ('PDT', 96), ('ADD', 34)]\n",
      "####################################################################\n",
      "Total number of tokens:  4698256\n",
      "of \t 251263\n",
      ") \t 168958\n",
      "( \t 165230\n",
      "in \t 125575\n",
      "the \t 125026\n",
      "and \t 88071\n",
      ", \t 68112\n",
      "change \t 66907\n",
      "to \t 64649\n",
      "with \t 55520\n"
     ]
    }
   ],
   "source": [
    "prim_outcomes = '/mnt/nas2/data/systematicReview/clinical_trials_gov/distant_pico_pre/primary_outcomes.txt'\n",
    "#prim_outcomes = '/mnt/nas2/data/systematicReview/clinical_trials_gov/distant_pico_pre/secondary_outcomes.txt'\n",
    "counter = 0\n",
    "\n",
    "outcome_names = []\n",
    "outcome_tokens = []\n",
    "pos_all = []\n",
    "posfine_all = []\n",
    "outcome_tokens_all = []\n",
    "\n",
    "with open(prim_outcomes, 'r') as pof:\n",
    "    try:\n",
    "        \n",
    "        for eachOutcome in pof:\n",
    "            counter = counter + 1\n",
    "            #rint(counter)\n",
    "            j = json.loads(eachOutcome)\n",
    "\n",
    "            if j:\n",
    "                for key, value in j.items():\n",
    "                    for eachOne in value:\n",
    "                        if 'text' in eachOne:\n",
    "                            outcome_names.append( eachOne['text'] )\n",
    "                        if 'tokens' in eachOne:\n",
    "                            outcome_tokens.append( eachOne['tokens'] )\n",
    "                            outcome_tokens_all.extend( list(map(lambda x: x.lower(), eachOne['tokens'])) ) \n",
    "                        if 'pos' in eachOne:\n",
    "                            pos_all.extend( eachOne['pos'] )\n",
    "                        if 'pos_fine' in eachOne:\n",
    "                            posfine_all.extend( eachOne['pos_fine'] )\n",
    "\n",
    "            #f counter == 10:\n",
    "            #  break\n",
    "    except:\n",
    "        print('something strange happened')\n",
    "\n",
    "print( len(outcome_names) )\n",
    "print( len(outcome_tokens) )\n",
    "\n",
    "\n",
    "longest_outcome = max(map(len, outcome_tokens))\n",
    "print('Longest outcome term: ', longest_outcome)\n",
    "\n",
    "shortest_outcome = min(map(len, outcome_tokens))\n",
    "print('Longest outcome term: ', shortest_outcome)\n",
    "\n",
    "mean_outcome = mean(map(len, outcome_tokens))\n",
    "print('Mean outcome term: ', mean_outcome)\n",
    "\n",
    "median_outcome = median(map(len, outcome_tokens))\n",
    "print('Median outcome term: ', median_outcome)\n",
    "print('####################################################################')\n",
    "pos_counter = Counter(pos_all)\n",
    "print( pos_counter.most_common(50) )\n",
    "print('####################################################################')\n",
    "posfine_counter = Counter(posfine_all)\n",
    "print( posfine_counter.most_common(50) )\n",
    "\n",
    "print('####################################################################')\n",
    "# Most common words\n",
    "print('Total number of tokens: ', len(outcome_tokens_all))\n",
    "outcometerms_counter = Counter(outcome_tokens_all)\n",
    "most_common_outcome_terms = outcometerms_counter.most_common(10)\n",
    "\n",
    "for tuple_i in most_common_outcome_terms:\n",
    "    print(tuple_i[0], '\\t', tuple_i[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare term distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_outTerms_CTO = set( outcome_tokens_all )\n",
    "unique_outTerms_ebm = set( all_outcome_tokens )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total outcome terms  4853978\n",
      "Total number of unique outcome terms  109705\n"
     ]
    }
   ],
   "source": [
    "print('Total outcome terms ', len( outcome_tokens_all ) + len( all_outcome_tokens ))\n",
    "print('Total number of unique outcome terms ', len( unique_outTerms_CTO ) + len( unique_outTerms_ebm ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Terms unique to either of the outcome lists:  8608\n"
     ]
    }
   ],
   "source": [
    "common_outTerms = list(unique_outTerms_CTO.intersection(unique_outTerms_ebm))\n",
    "print('Terms unique to either of the outcome lists: ', len(common_outTerms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF POC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ifidf_for_words(text):\n",
    "    tfidf_matrix= vectorizer.transform([text]).todense()\n",
    "    feature_index = tfidf_matrix[0,:].nonzero()[1]\n",
    "    tfidf_scores = zip([feature_names[i] for i in feature_index], [tfidf_matrix[0, x] for x in feature_index])\n",
    "    sorted_dict = {k: v for k, v in sorted(dict(tfidf_scores).items(), key=lambda item: item[1])}\n",
    "    return sorted_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcome_tfidf = vectorizer.fit_transform(outcome_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_string = 'Flexion knees measured goniometer side side difference expressed degrees.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'measured': 0.168605292180929,\n",
       " 'difference': 0.2244409287049211,\n",
       " 'expressed': 0.3000135047712927,\n",
       " 'flexion': 0.3118107683732015,\n",
       " 'degrees': 0.3191784079340699,\n",
       " 'goniometer': 0.38741566434403935,\n",
       " 'knees': 0.41333903188241167,\n",
       " 'side': 0.5578078148467132}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_ifidf_for_words(input_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine overlapping spans in PICOS weak annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['p', 'ic', 'o', 's']\n",
    "label_combinations = itertools.combinations(labels, 2)\n",
    "label_combinations = list(label_combinations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('p', 'ic'), ('p', 'o'), ('p', 's'), ('ic', 'o'), ('ic', 's'), ('o', 's')]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage overlap between  p  and  o  is:  13.003077294394497\n"
     ]
    }
   ],
   "source": [
    "l1 = label_combinations[1][0]\n",
    "l2 =  label_combinations[1][1]\n",
    "\n",
    "overlaps = []\n",
    "non_overlaps = []\n",
    "\n",
    "annotations_global = '/home/anjani/distant-PICO/CandidateGeneration/ResultInspection/pico_multiclass.txt'\n",
    "#annotations_global = '/home/anjani/distant-PICO/CandidateGeneration/ResultInspection/label_overlap_inspection.txt'\n",
    "\n",
    "counter = 0\n",
    "with open(annotations_global, 'r', encoding='latin1') as af:\n",
    "\n",
    "        for annot in af: # Each annotation file\n",
    "            try:\n",
    "                counter = counter + 1\n",
    "                j = json.loads( annot )\n",
    "                for k,v in j.items(): # target\n",
    "                    if 'id' not in k:\n",
    "                        for k_i, v_i in v.items(): # each sentence\n",
    "                            if l1 in v_i and l2 in v_i:\n",
    "                                phrase = []\n",
    "                                non_o_phrase = []\n",
    "                                list1 = v_i[l1]\n",
    "                                list2 = v_i[l2]\n",
    "                                for n, (a1, a2) in enumerate( zip(list1, list2) ):\n",
    "                                    if a1 != 0 and a2 != 0:\n",
    "                                        phrase.append( v_i['tokens'][n] )\n",
    "                                    if a1 != 0 or a2 != 0:\n",
    "                                        non_o_phrase.append( v_i['tokens'][n] )\n",
    "                                if phrase:\n",
    "                                    overlaps.append( ' '.join(phrase) )\n",
    "                                if non_o_phrase:\n",
    "                                    non_overlaps.append( ' '.join(non_o_phrase) )\n",
    "            except Exception as ex:\n",
    "                pass\n",
    "                template = \"An exception of type {0} occurred. Arguments:{1!r}\"\n",
    "                message = template.format(type(ex).__name__, ex.args)\n",
    "                #print( message )\n",
    "\n",
    "                exc_type, exc_obj, exc_tb = sys.exc_info()\n",
    "                fname = os.path.split(exc_tb.tb_frame.f_code.co_filename)[1]\n",
    "                #print(exc_type, fname, exc_tb.tb_lineno)\n",
    "\n",
    "                #print(traceback.format_exc())\n",
    "\n",
    "print('Percentage overlap between ', l1, ' and ', l2, ' is: ', (len( set( overlaps ) ) / len( list(non_overlaps) ) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore \"outcome\" sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of non-null outcome sources retrieved 473893\n"
     ]
    }
   ],
   "source": [
    "outcomes_file = '/mnt/nas2/data/systematicReview/clinical_trials_gov/distant_pico_pre/temp.txt'\n",
    "\n",
    "outcomes = dict()\n",
    "\n",
    "counter = 0\n",
    "with open(outcomes_file, 'r') as rf:\n",
    "    for eachOutcome in rf:\n",
    "        j = json.loads( eachOutcome )\n",
    "        if j:\n",
    "            counter = counter + 1\n",
    "            outcomes[counter] = j\n",
    "            \n",
    "            \n",
    "print('The number of non-null outcome sources retrieved', len( outcomes ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PrimaryOutcome_0': [{'text': '( 0 - 10) Itching scale',\n",
       "   'tokens': ['(', '0', '-', '10', ')', 'Itching', 'scale'],\n",
       "   'lemma': ['(', '0', '-', '10', ')', 'itching', 'scale'],\n",
       "   'pos': ['PUNCT', 'NUM', 'PUNCT', 'NUM', 'PUNCT', 'NOUN', 'NOUN'],\n",
       "   'pos_fine': ['-LRB-', 'CD', 'HYPH', 'CD', '-RRB-', 'NN', 'NN']}]}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outcomes[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = []\n",
    "tokens = []\n",
    "pos = []\n",
    "pos_fine = []\n",
    "tokens_lengths = []\n",
    "\n",
    "counter_i = 0\n",
    "for key, value in outcomes.items():\n",
    "    for a_key, a_value in value.items():\n",
    "        text.append( a_value[0]['text'] )\n",
    "        tokens.append( a_value[0]['tokens'] )\n",
    "        pos.append( a_value[0]['pos'] )\n",
    "        pos_fine.append( a_value[0]['pos_fine'] )\n",
    "        tokens_lengths.append( len(a_value[0]['tokens']) )\n",
    "        counter_i = counter_i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'text' : text, 'tokens' : tokens, 'pos' : pos, 'pos_fine' : pos_fine })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>pos</th>\n",
       "      <th>pos_fine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1564619</th>\n",
       "      <td>Oswestry Disability Index</td>\n",
       "      <td>[Oswestry, Disability, Index]</td>\n",
       "      <td>[PROPN, PROPN, PROPN]</td>\n",
       "      <td>[NNP, NNP, NNP]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1564620</th>\n",
       "      <td>Numeric Rating Scale</td>\n",
       "      <td>[Numeric, Rating, Scale]</td>\n",
       "      <td>[PROPN, PROPN, PROPN]</td>\n",
       "      <td>[NNP, NNP, NNP]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1564621</th>\n",
       "      <td>Medical Outcomes Study Short-Form Health Surve...</td>\n",
       "      <td>[Medical, Outcomes, Study, Short-Form, Health,...</td>\n",
       "      <td>[PROPN, PROPN, PROPN, PROPN, PROPN, PROPN, NOU...</td>\n",
       "      <td>[NNP, NNP, NNP, NNP, NNP, NNP, NN, CD, -LRB-, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1564622</th>\n",
       "      <td>Centre for Epidemiological Studies Depression ...</td>\n",
       "      <td>[Centre, for, Epidemiological, Studies, Depres...</td>\n",
       "      <td>[NOUN, ADP, PROPN, PROPN, PROPN, PROPN]</td>\n",
       "      <td>[NN, IN, NNP, NNPS, NNP, NNP]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1564623</th>\n",
       "      <td>Zurich claudification Scale, Numeric Rating Sc...</td>\n",
       "      <td>[Zurich, claudification, Scale, ,, Numeric, Ra...</td>\n",
       "      <td>[ADJ, NOUN, PROPN, PUNCT, PROPN, PROPN, PROPN,...</td>\n",
       "      <td>[JJ, NN, NNP, ,, NNP, NNP, NNP, IN, NN, NN, ,,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      text  \\\n",
       "1564619                          Oswestry Disability Index   \n",
       "1564620                               Numeric Rating Scale   \n",
       "1564621  Medical Outcomes Study Short-Form Health Surve...   \n",
       "1564622  Centre for Epidemiological Studies Depression ...   \n",
       "1564623  Zurich claudification Scale, Numeric Rating Sc...   \n",
       "\n",
       "                                                    tokens  \\\n",
       "1564619                      [Oswestry, Disability, Index]   \n",
       "1564620                           [Numeric, Rating, Scale]   \n",
       "1564621  [Medical, Outcomes, Study, Short-Form, Health,...   \n",
       "1564622  [Centre, for, Epidemiological, Studies, Depres...   \n",
       "1564623  [Zurich, claudification, Scale, ,, Numeric, Ra...   \n",
       "\n",
       "                                                       pos  \\\n",
       "1564619                              [PROPN, PROPN, PROPN]   \n",
       "1564620                              [PROPN, PROPN, PROPN]   \n",
       "1564621  [PROPN, PROPN, PROPN, PROPN, PROPN, PROPN, NOU...   \n",
       "1564622            [NOUN, ADP, PROPN, PROPN, PROPN, PROPN]   \n",
       "1564623  [ADJ, NOUN, PROPN, PUNCT, PROPN, PROPN, PROPN,...   \n",
       "\n",
       "                                                  pos_fine  \n",
       "1564619                                    [NNP, NNP, NNP]  \n",
       "1564620                                    [NNP, NNP, NNP]  \n",
       "1564621  [NNP, NNP, NNP, NNP, NNP, NNP, NN, CD, -LRB-, ...  \n",
       "1564622                      [NN, IN, NNP, NNPS, NNP, NNP]  \n",
       "1564623  [JJ, NN, NNP, ,, NNP, NNP, NNP, IN, NN, NN, ,,...  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_percents = dict()\n",
    "\n",
    "for i in range(min(tokens_lengths), max(tokens_lengths)):\n",
    "    #print('Percentage of the outcome mentions with token length ', str(i) , ' : ', ( tokens_lengths.count( i ) / len(tokens_lengths) ) * 100 )\n",
    "    token_percents[i] = ( tokens_lengths.count( i ) / len(tokens_lengths) ) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
